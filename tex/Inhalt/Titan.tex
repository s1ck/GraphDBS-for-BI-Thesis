\section{Titan}

Titan ist das vierte System, welches im Rahmen der Evaluation betrachtet wird, es ist ein quelloffenes, unter Apache 2.0 lizenziertes GDBMS. Es wird von der Firma Aurelius\footnote{\url{http://thinkaurelius.com/}} entwickelt und ist im Vergleich zu den bisher betrachteten Systemen ein sehr junges Projekt. Die erste Veröffentlichung erfolgte im September 2012, seit Mai 2013 ist die stabile Version 0.3.2 aktuell. Das Unternehmen Aurelius arbeitet eng mit dem TinkerPop-Projekt zusammen und implementiert die darin definierte Blueprints API. Titan selbst ist ausschließlich in Java umgesetzt, somit ist die Ausführung auf kompatiblen Plattformen möglich. Es handelt sich um ein GDBMS, in welchem Modellierung und Verwendung der Daten nativ sind, Speicherung und Verarbeitung sind hingegen nicht-nativ, der Graph wird auf ein Key-Column-Value-Datenmodell abgebildet. Das hierfür verwendete Speichersystem ist austauschbar, Titan unterstützt aktuell die spaltenorientierten, verteilten Datenbanken Apache Cassandra\footnote{\url{http://cassandra.apache.org/}} und Apache HBase\footnote{\url{http://hbase.apache.org/}} sowie die zentrale Key-Value-Datenbank BerkeleyDB Java Edition. Die genannten Speichersysteme sind disk-orientiert, Titan bietet jedoch auch eine hauptspeicher-zentrierte Implementierung für Testzwecke an. Die Verwendung des GDBMS erfolgt entweder eingebettet innerhalb von Java-Anwendungen oder im Client-Server-Betrieb.

Im Gegensatz zu den bisher betrachteten Systemen wird Titan primär für den Einsatz als verteiltes GDBMS  zur Verwaltung umfangreicher Graphen entwickelt. Dabei nutzt es die Vorteile vorhandener Speichertechnologien, um eine horizontale Skalierbarkeit paralleler Zugriffe und Datenvolumen zu gewährleisten. Aurelius definiert Graphen als umfangreich, wenn diese mehrere Milliarden Knoten und Kanten aufweisen.\footnote{Im Mai 2013 veröffentlichte Aurelius einen beeindruckenden Benchmark in dem die Performance paralleler Zugriffe auf einen Graph mit ca. 6 Milliarden Knoten und 121 Milliarden Kanten auf einem Titan-Cassandra-Cluster gemessen wurde. Die Ergebnisse können unter \cite{titan_bench:2013} eingesehen werden.} Entsprechend der vorgestellten Kategorisierung handelt es sich somit um eine Kombination aus Graphdatenbanksystem und Graph Processing System, welche Zugriffe mit lokalem Bezug auf umfangreichen Graphen ermöglicht. Eine weitere Besonderheit von Titan ist die Verwendung von Indizes an Knoten. Diese versprechen einen effizienteren Zugriff auf inzidente Kanten bei Knoten mit hohem Grad.

Die nachfolgenden Erläuterungen beziehen sich auf Version 0.3.2 des GDBMS in Verbindung mit BerkeleyDB und Apache Cassandra. Die Informationen stammen vorrangig aus der offiziellen Dokumentation zu Titan\cite{titan_doku:2013} und Gremlin\cite{gremlin_doku:2013} sowie aus der Mailing-Liste\cite{titan_mail:2013} des Herstellers.

\subsection{Datenmodell und Typsystem}

Titan implementiert das Property-Graph-Modell: Attribute können an Knoten und Kanten gespeichert werden, Kanten besitzen grundsätzlich eine Richtung und einen Bezeichner. Attributschlüssel sind vom Typ \texttt{String} während für Attributwerte sämtliche primitiven Java-Datentypen sowie Arrays, Collections und Maps zulässig sind.\footnote{Titan verwendet die Java-Bibliothek Kryo für die (De-)Serialisierung von Objekten. Eine vollständige Liste der unterstützten Datentypen kann unter \url{https://code.google.com/p/kryo/} eingesehen werden.} Abgesehen von Kantenbezeichnern ist die Definition eines festen Knoten- bzw. Kantenschemas nicht möglich. Ungeachtet dessen lassen sich verschiedene Einschränkungen festlegen, die zum Teil auf das Modellieren einer Anwendungsdomäne, in erster Linie jedoch auf das effizientere Verwalten des Graphen ausgerichtet sind.

Das GDBMS verwendet als spezielle Datentypen für Attributschlüssel und Kantenbezeichner \texttt{TitanKey} und \texttt{TitanLabel}. Diese lassen sich entweder manuell festlegen oder bei erstmaliger Verwendung eines Schlüssels oder Bezeichners automatisch durch das System erzeugen. Das manuelle Vorgehen bietet mehrere Vorteile: Die Möglichkeit zur Definition von Integritätsbedingungen, eine verbesserte Speichereffizienz sowie eine erhöhte Performance. Die genannten Typen definieren kein Knoten- oder Kantenschema, weist jedoch eine Instanz ein typisiertes Attribut oder Label auf, so müssen die geforderten Integritätsbedingungen eingehalten werden.

Typen besitzen einen systemweit eindeutigen Namen, dieser entspricht dem Attributschlüssel bzw. dem Kantenbezeichner. Instanzen von \texttt{TitanKey} und \texttt{TitanLabel} können als \texttt{UNIQUE} deklariert werden; für Attributschlüssel lässt sich die Bedingung entweder auf einen einzelnen Knoten bzw. eine einzelne Kante oder auf den gesamten Graphen anwenden. Im ersten Fall darf dem entsprechend typisierten Attributschlüssel an einer Knoten- oder Kanteninstanz höchstens ein Wert zugeordnet sein, im zweiten Fall gilt die Einmaligkeit eines Schlüssel-Wert-Paares systemweit und ermöglicht folglich die Definition anwendungsbezogener Primärschlüssel. Standardmäßig kann ein Attributschlüssel mehrfach an einem Knoten vorkommen.\\
Für Kantenbezeichner hingegen legt die \texttt{UNIQUE}-Bedingung fest, dass zugehörige Instanzen innerhalb der Nachbarschaft eines Knotens höchstens einmal vorkommen dürfen. Hierbei kann zwischen eingehenden und ausgehenden Kanten unterschieden werden.\footnote{Der Name eines Mitarbeiters ist ein Beispiel für ein einmaliges Attribut an einem Knoten, während die Personalnummer innerhalb der gesamten Knotenmenge eindeutig sein muss. Ein Beispiel für eine einmalige Kante ist die Beziehung vom Angestellten zum Vorgesetzten.} Folglich lassen sich die Kardinalitäten der an einer Beziehung beteiligten Entitäten festlegen: Das Weglassen der \texttt{UNIQUE}-Bedingung definiert eine $n:m$-Beziehung, dies entspricht dem Standard im PGM. Gilt die Bedingung in ausgehender Richtung, modelliert dies eine $1:n$-, in eingehender Richtung eine $n:1$-Beziehung. Gilt die \texttt{UNIQUE}-Bedingung in beiden Richtungen, so entspricht dies einer $1:1$-Beziehung. Sowohl Typen für Attributschlüssel als auch für Kantenbezeichner lassen sich in Gruppentypen zusammenfassen, was ein effizienteres Abfragen ermöglicht.\footnote{Zum Beispiel lassen sich die Attributschlüssel \texttt{name} und \texttt{age} zu einem Gruppentyp \texttt{personal\_data} zusammenfassen und gemeinsam abfragen.}

Neben dem Namen und der Eindeutigkeit definiert ein \texttt{TitanKey} den Datentyp des zugeordneten Attributwertes, was dessen Wertebereich festlegt und die effizientere Speicherung ermöglicht. Des Weiteren können Attributschlüssel indexiert und somit der direkte, effiziente Zugriff auf die zugehörigen Instanzen unter Angabe von Schlüssel-Wert-Paaren realisiert werden.\\
Im Gegensatz dazu lässt sich an einem \texttt{TitanLabel} ein Primärschlüssel festlegen. Weist eine Kante das entsprechende Attribut auf, erlaubt dies das effizientere Auslesen inzidenter Kanten unter Angabe eines Wertes oder Wertebereiches.\footnote{Besitzt eine Beziehung vom Mitarbeiter zum Projekt einen Zeitstempel, welcher den Beitritt des Mitarbeiters datiert, und ist dieser Zeitstempel ein Primärschlüssel, dann lassen sich Anfragen wie zum Beispiel \textit{An welchen Projekten hat Mitarbeiter x im Mai 2013 mitgearbeitet?} effizient beantworten. Ohne einen entsprechenden Index müssen alle inzidenten Kanten eines Knotens durchsucht werden.} Dies ist ein Alleinstellungsmerkmal von Titan und verspricht eine höhere Performance beim Traversieren des Graphen. Der Hersteller bezeichnet dieses Konzept als \textit{vertex-centric indices}. Neben dem Primärschlüssel kann ein Kantenbezeichner eine Signatur definieren, die angibt, welche Attribute die zugehörigen Kanteninstanzen besitzen bzw. voraussichtlich besitzen. Dies verspricht ein effizienteres Speichern und Laden von Attributen.\\
Kanten sind gerichtet und können standardmäßig in beide Richtungen traversiert werden, Titan erlaubt aber auch das Definieren uni-direktionaler Kanten, welche sich nur vom Start- zum Zielknoten traversieren lassen. Hierdurch kann Speicherplatz am Zielknoten gespart werden. Zu beachten ist dabei jedoch, dass ein Löschen des Zielknotens nicht das Löschen der Kante erfordert und das Einhalten der referentiellen Integrität damit in der Verantwortung der Anwendung liegt.

% Identität
Die Identität von Knoteninstanzen wird durch eine 64-Bit-Ganzzahl repräsentiert,\footnote{Nachzuvollziehen unter \url{https://github.com/thinkaurelius/titan/blob/0.3.2/titan-core/src/main/java/com/thinkaurelius/titan/core/TitanElement.java\#L52}.} die vom GDBMS vergeben und nach dem Löschen von Instanzen nicht wiederverwendet wird. Kanten besitzen ebenfalls eine Identität, auf diese wird im Zusammenhang mit der Persistenzverwaltung eingegangen. Unter Angabe einer Identität lässt sich auf die zugehörige Instanz zugreifen, dies entspricht der Definition eines Primärschlüssels.

% Anzahl der Datenbanken (wie Partitionierung)
Titan verwaltet genau eine Graphdatenbank, dieser sind alle Knoten und Kanten zugeordnet. Eine anwendungsseitige Partitionierung der Knoten- und Kantenmenge zur unabhängigen Verwaltung von Teilgraphen ist ausschließlich unter Verwendung dedizierter Attribute möglich.

% Flexiblität
Es wird deutlich, dass Titan sehr flexibel bezüglich der Definition, Änderung und Verwendung eines Schemas ist. Wie bei Neo4j ist die Definition von Kantenbezeichnern obligatorisch, ihre Berücksichtigung innerhalb hingegen nicht. Die hinterlegten Nutzdaten sind semi-strukturiert und lassen sich dynamisch zur Laufzeit manipulieren. Einem Attributschlüssel können Attributwerte verschiedenen Datentyps zugeordnet sein, wenn auf auf das manuelle Erzeugen von \texttt{TitanKeys} verzichtet wird. Wie die bisher betrachteten GDBMS empfiehlt auch Titan die manuelle Typ-Definition.

\subsection{Zugriffsmechanismen, Transaktionen und Indexverwaltung}

Titan implementiert ebenfalls die Blueprints API und stellt hinsichtlich CRUD-Operationen den gleichen Funktionsumfang wie OrientDB zur Verfügung. Auch Titan erweitert die API um Funktionen zum Erzeugen von Typen, diese sind Instanzen von \texttt{TitanKey} bzw. \texttt{TitanLabel} und lassen sich unter Anwendung der beschriebenen Einschränkungen definieren.%, ein Beispiel hierfür findet sich in Anhang \ref{anh:titan_blueprints_api}. 
Aufgrund der Implementierung der Blueprints API können alle im Rahmen des TinkerPop-Projektes angebotenen Werkzeuge in Titan verwendet werden. Neben der bereits im Zusammenhang mit OrientDB beschrieben Algorithmensammlung Furnace ist dies u.a. Gremlin.

\paragraph*{CRUD-Operationen via Gremlin}

Gremlin ist eine imperative, graphenorientierte Anfragesprache für den lesenden und schreibenden Zugriff auf die Datenbasis. Das TinkerPop-Projekt bietet Gremlin für verschiedene JVM-Sprachen an, in den nachfolgenden Beispielen wird die Groovy-Syntax verwendet.\footnote{Groovy ist eine dynamische Programmiersprache für die Java-Plattform: \url{http://groovy.codehaus.org/}.} Gremlin wird aufgrund ihrer Kernfunktion, dem Beschreiben abstrakter Wege zur Traversierung des Graphen, als  \textit{graph traversal language} bezeichnet, das Finden von Mustern innerhalb der Datenbasis ist ebenfalls möglich. Analog zu Cypher handelt es sich um eine nicht standardisierte Sprache, sie kann jedoch in allen GDBMS eingesetzt werden, welche die Blueprints API implementieren und wird von Titan als primäre Anfragesprache angeboten. Nachfolgend werden die grundlegenden Komponenten erläutert, die vollständige Beschreibung der Sprache kann der offiziellen Dokumentation entnommen werden\cite{gremlin_doku:2013}.
	
\begin{figure}[h] 
	\centering
		\includegraphics[scale=1]{titan_example.pdf}
	\caption[Titan: Beispielgraph]{Erweitertes Beispiel eines Property-Graphen. Kanten mit ausgefüllter Spitze modellieren eine $n:m$- Beziehung und können mehrfach innerhalb der Nachbarschaft eines Knotens vorkommen. Kanten mit leerer Spitze modellieren eine $1:n$-, Kanten mit einem Karo am Startknoten eine $n:1$-Beziehung. Mitarbeiter können folglich mit beliebig vielen Kollegen zusammenarbeiten, jedoch nur an einem Projekt mitwirken. Nur ein Mitarbeiter darf für ein Projekt verantwortlich sein, dieser darf jedoch nicht die Verantwortung über weitere Projekte übernehmen. Hervorgehobene Attributschlüssel sind indexiert, Knoten können unter Angabe eines entsprechenden Schlüssel-Wert-Paares direkt gelesen werden.}
	\label{fig:titan_example}
\end{figure}	

% Manipulation (Einfügen Knoten / Kante)

Abbildung \ref{fig:titan_example} zeigt eine mögliche Realisierung des Mitarbeiter-Projekt-Beispiels in Titan. Zu beachten sind dabei die zusätzlichen Einschränkungen der einzelnen Beziehungsarten. Zur Definition von Typen für Attributschlüssel und Kantenbezeichner erweitert Titan die Sprache um Hilfsfunktionen.  Zum Beispiel lässt sich ein \texttt{TitanKey} für den Attributschlüssel \texttt{name} wie folgt definieren:

\texttt{g.makeType().name('name').unique(OUT).indexed(Vertex.class)}\newline
\texttt{.dataType(String.class).makePropertyKey();}

In Gremlin werden Befehle durch die Verkettung bzw. Komposition von Funktionen gebildet, ein Befehl wird immer von links nach rechts gelesen. Im Beispiel ist \texttt{g} eine Referenz auf den verwalteten Graphen, die Funktion \texttt{name('name')} definiert den global eindeutigen Attributschlüssel, \texttt{unique(OUT)} legt die Eindeutigkeit des Attributes auf Instanzebene fest, die Funktion \texttt{indexed(Vertex.class)} erzeugt einen Index für Knoteninstanzen mit dem entsprechenden Attribut, \texttt{dataType(String.class)} legt den Datentyp des Attributwertes fest und \texttt{makePropertyKey()} erzeugt den Typen innerhalb der Datenbasis.

Ein \texttt{TitanLabel} lässt sich auch durch die Verkettung der benötigten Funktionen definieren. Soll zum Beispiel der Kantenbezeichner \texttt{WORKS\_IN} für die zugehörige $n:1$-Beziehung zwischen Mitarbeiter und Projekt erzeugt werden, so erfolgt dies mit der Anweisung:

\texttt{g.makeType().name('WORKS\_IN').unique(OUT).makeEdgeLabel();}

Für Kantenbezeichner legt die Funktion \texttt{unique(OUT)} fest, dass eine entsprechend deklarierte Kanteninstanz in der Menge ausgehender Kanten eines Startknotens höchstens einmal vorkommen darf, \texttt{makeEdgeLabel()} erzeugt den Typen innerhalb der Datenbasis. Anzumerken ist, dass bei der Definition eines Kantenbezeichners keine Festlegung auf bestimmte Knotentypen für Start- oder Zielknoten erfolgt.

Gremlin ermöglicht die Manipulation der Datenbasis und stellt Funktionen für das Anlegen und Löschen von Knoten und Kanten zur Verfügung. Nachfolgend wird beispielhaft eine Knoteninstanz für den Mitarbeiter \texttt{Eve} angelegt und an eine Variable gebunden:

\texttt{eve = g.addVertex([type:\string'Employee',name:'Eve',age:27]);}

Titan unterstützt keine Knotenbezeichner, ist eine Unterscheidung der Instanzen erforderlich, muss hierfür ein dediziertes Attribut definiert werden. Im gezeigten Beispiel ist dies der Attributschlüssel \texttt{type}. Das Aktualisieren von Knoten- und Kantenattributen ist ebenfalls möglich und erfolgt direkt an der Instanz.

Beim Erzeugen einer Kante gibt die Reihenfolge der Parameter die Richtung vor, der Kantenbezeichner wird als Zeichenkette an die Funktion übergeben. Existiert keine zugehörige \texttt{TitanLabel}-Instanz, erzeugt das GDBMS diese mit Standardeinstellungen. Der Befehl

\texttt{g.addEdge(eve,projectX,'WORKS\_IN');}

fügt der Datenbasis eine gerichtete Kante von \texttt{Eve} nach \texttt{ProjectX} hinzu. Kantenattribute können, wie bereits für Knoten gezeigt, ebenfalls an die Funktion übergeben werden.

\paragraph*{Traversierung via Gremlin}
% Selektion von Instanzen
Gremlin ermöglicht das algorithmische Durchlaufen des Graphen ausgehend entweder von einer einzelnen Knoten- bzw. Kanteninstanz oder von einer Instanzmenge. Dabei erlaubt eine Referenz auf den Graphen mit der Anweisung \texttt{g.V} bzw. \texttt{g.E} den Zugriff auf die gesamte Knoten- bzw. Kantenmenge. Die Auswahl einzelner oder mehrerer Instanzen erfolgt entweder explizit unter Angabe einer Identität oder mengenorientiert anhand eines Schlüssel-Wert-Paares:

\texttt{bob = g.v(23) // direct access via ID 23} \newline 
\texttt{employees = g.V('type','Employee') // set oriented access} 

Die erste Anweisung bindet die Knoteninstanz mit der Identität 23 an die Variable \texttt{bob}, während in der zweiten Anweisung die Menge aller Mitarbeiter der Variable \texttt{employees} zugewiesen wird. Das Auslesen der Attributwerte erfolgt entweder durch die direkte Verkettung mit dem Attributschlüssel (z.B. \texttt{bob.name}) oder durch Anwendung der \texttt{map}-Funktion (z.B. \texttt{bob.map('name','age')}).

% Traversierung = Funktionsverkettung
Das Konzept der Komposition wird in Gremlin zur Definition abstrakter Wege innerhalb des Graphen genutzt. Hierfür stellt die Sprache entsprechende Funktionen, sog. \texttt{steps}, zur Verfügung.\footnote{Eine Übersicht über alle verfügbaren Funktionen findet sich unter \url{https://github.com/tinkerpop/gremlin/wiki/Gremlin-Steps}.} Jede Funktion innerhalb der Komposition ist somit ein Schritt innerhalb des abstrakten Weges. Eingabeparameter der Funktion ist die jeweilige Ergebnismenge des vorhergehenden Schrittes. Sollen beispielsweise die ausgehenden Kanten des Mitarbeiters \texttt{Bob} traversiert werden, ist dies mit folgender Verkettung möglich:

\texttt{bob.out}

Das Ergebnis dieser einfachen Traversierung ist eine Menge von Knoten-Identitäten, welche über eine ausgehende Kante mit \texttt{Bob} verbunden sind, was durch die Richtungsfunktion \texttt{out} formuliert wird. Soll direkt auf Attributwerte der adjazenten Knoten zugegriffen werden, erfordert dies das Anfügen des entsprechenden Attributschlüssels\footnote{Die Ausgabe berücksichtigt nur die Knoten, welche das entsprechende Attribut aufweisen.} (z.B. \texttt{bob.out.name}). Aus Sicht eines Knotens lässt sich darüber hinaus mit Hilfe der Richtungsfunktion \texttt{in} bzw. \texttt{both} auf adjazente Knoten zugreifen, die über eine eingehende Kante bzw. über eine Kante beliebiger Richtung mit einem Knoten verbunden sind. Die Funktionen \texttt{outE}, \texttt{inE} und \texttt{bothE} ermitteln die zu einem Knoten inzidenten Kanten, welche wiederum mittels \texttt{outV} bzw. \texttt{inV} das Abrufen ihres jeweiligen Start- bzw. Zielknotens erlauben. Die Traversierungen \texttt{bob.out} und \texttt{bob.outE.inV} sind folglich äquivalent.

% Einschränkung Kantenbezeichner
Die Einschränkung zu traversierender Kanten ist durch die Angabe von Kantenbezeichnern möglich. Diese werden als Parameter an die entsprechende Richtungsfunktion übergeben. Sollen zum Beispiel die Namen der Mitarbeiter bestimmt werden, die an einem Projekt arbeiten, für das \texttt{Bob} verantwortlich ist, so lässt sich dies mit folgender Anweisung realisieren:

\texttt{bob.out('RESPONSIBLE\_FOR').in('WORKS\_IN').name}

Dabei werden im ersten Schritt die Projekte traversiert, für welche \texttt{Bob} direkt verantwortlich ist. Im zweiten Schritt werden ausgehend von jedem Projekt die eingehenden Kanten vom Typ \texttt{WORKS\_IN} traversiert, um zu den entsprechenden Mitarbeitern zu gelangen.

% Einschränkung Attribute
Neben der Einschränkung der Kantenbezeichner kann in Gremlin auch auf Grundlage der Attribute entschieden werden, ob eine Instanz bei der Traversierung berücksichtigt wird. Die Sprache bietet hierfür die Funktion \texttt{filter}, die das Definieren eines sog. Closure ermöglicht. Anhand dessen lässt sich für jedes Element einer Ergebnismenge entscheiden, ob es im nächsten Schritt berücksichtigt wird. Sollen zum Beispiel alle Kollegen von \texttt{Bob} selektiert werden, welche seit 2012 mit ihm zusammenarbeiten und die älter als 25 sind, so ist dies wie folgt möglich:

\texttt{bob.bothE('WORKS\_WITH').filter\{it.since > 2011\}.bothV.filter\{it.age > 25\}}

Ausgehend vom Startknoten werden zunächst unter Verwendung von \texttt{bothE} aus- und eingehende Kanten mit dem Bezeichner \texttt{WORKS\_WITH} traversiert. Aus der Menge der inzidenten Kanten werden mittels \texttt{filter\{it.since > 2011\}} jene Instanzen ausgewählt, die das Prädikat erfüllen. Die Variable \texttt{it} referenziert dabei ein Element in der Ergebnismenge des vorhergehenden Schrittes. Anschließend liest \texttt{bothV} Start- und Zielknoten der Kante aus und filtert jene, die älter als 25 sind. Knoten- und Kanteninstanzen werden in Gremlin standardmäßig mehrfach besucht. Bei genauer Betrachtung des Beispiels wird deutlich, dass ein Berücksichtigen von Start- und Zielknoten auch \texttt{Bob} in die Ergebnismenge der Traversierung einschließt. Dies lässt sich mit der Funktion \texttt{except} vermeiden:

\texttt{bob.bothE('WORKS\_WITH').filter\{it.since > 2011\}.bothV.except([bob])}\newline
\texttt{.filter\{it.age > 25\}}

Innerhalb des Closure können verschiedene mathematische, boolesche und string-basierte Funktionen verwendet und kombiniert werden. Entscheidend ist dabei nur, dass der Rückgabewert ein Wahrheitswert ist.
	
% feste / variable Pfadlängen (Erreichbarkeit)
Die bisher betrachteten abstrakten Wege sind statisch definiert und besitzen eine feste Länge. Für das Traversieren von Wegen beliebiger Länge bietet Gremlin die \texttt{loop}-Funktion, die es erlaubt, definierte Abschnitte innerhalb eines Weges zu wiederholen. Soll zum Beispiel bestimmt werden, welche Mitarbeiter höchstens zwei Schritte von \texttt{Bob} entfernt sind, so ist dies mit folgender Anweisung realisierbar:

\texttt{bob.as('b').out('WORKS\_WITH').loop('b')\{it.loops < 3\}\{true\}}

Dabei legt die Funktion \texttt{as('b')} den Beginn des zu wiederholenden Abschnittes fest, während \texttt{loop('b')} das Ende markiert. Der erste Parameter der \texttt{loop}-Funktion ist ein \texttt{while}-Closure, welches die Abbruchbedingung für die Traversierung definiert. Die Laufvariable \texttt{it.loops} speichert den Abstand zum Startknoten innerhalb einer konkreten Pfadinstanz. Das zweite Closure ist optional und legt fest, ob eine besuchte Instanz der Ergebnismenge hinzugefügt werden soll, im Beispiel gilt dies für alle besuchten Knoten. Durch Weglassen dieser Filterbedingung werden nur die Endknoten der gefundenen Pfadinstanzen ausgegeben.\\
Alternativ können durch Anfügen der Funktion \texttt{path} die Pfadinstanzen der Ergebnismenge hinzugefügt werden. In Verbindung mit einer Einschränkung an der \texttt{loop}-Funktion ermöglicht dies das Berechnen von Pfaden zwischen zwei Instanzen:

\texttt{alice.as('a').out.loop('a')\{it.loops < 4\}\{it.object.name == 'ProjectX'\}.path}

Durch das zweite Closure werden ausschließlich jene Knoten ausgegeben, welche das entsprechende Prädikat erfüllen. Die Funktion \texttt{path} gibt für jeden dieser Knoten die Pfadinstanz aus, welche zu diesem Knoten geführt hat. Das Ergebnis ist folglich eine Menge von Pfaden mit einer maximalen Länge von drei zwischen \texttt{Alice} und \texttt{ProjectX}. Das Auswählen des kürzesten Pfades ist durch anschließendes Sortieren nach Pfadlänge und Einschränken der Ergebnismenge auf ein Element möglich.

% Aggregation
Analog zu Cypher und OrientDB-SQL unterstützt Gremlin das Gruppieren und Aggregieren von Ergebnismengen. Da Gremlin die Verwendung von Java erlaubt, lassen sich beliebige Berechnungen durchführen. Nachfolgend wird das Alter des ältesten Mitarbeiters bestimmt:

\texttt{oldest = Integer.MIN\_VALUE;}\newline
\texttt{g.V('type','Employee').sideEffect\{oldest=(oldest<it.age)?it.age:oldest\};}

Die Funktion \texttt{sideEffect} lässt sich dazu verwenden, den Zustand globaler Variablen zu verändern. Im Beispiel führt der ternäre Ausdruck genau dann zur Aktualisierung der Variable \texttt{oldest}, wenn der aktuelle Mitarbeiter älter als die bisher betrachteten ist.\\
Die Ergebnismenge wird durch die Angabe eines Intervalls eingeschränkt. Beispielsweise lässt sich das Alter der zwei jüngsten Mitarbeiter wie folgt bestimmen:

\texttt{g.V('type','Employee').age.order[0..1]}

Dabei sortiert die \texttt{order}-Funktion die entsprechenden Attributwerte in natürlicher Ordnung, das Intervall \texttt{[0..1]} schränkt die Ergebnismenge auf die ersten beiden Elemente ein.
	
\paragraph*{Mustersuche via Gremlin} 

In den bisherigen Beispielen wurden entweder Knoten- oder Kanteninstanzen am Ende eines abstrakten Weges, deren Attribute oder aber komplette Pfadinstanzen als Ergebnis einer Traversierung ausgegeben. Zusätzlich erlaubt Gremlin das Suchen und Extrahieren von Teilgraphen innerhalb der Datenbasis. Abbildung \ref{fig:titan_pattern} zeigt den bereits für die Evaluation von Cypher verwendeten Mustergraphen.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=1]{titan_pattern.pdf}
	\caption[Titan: Mustergraph]{Beispiel für einen Mustergraphen: Der grau hinterlegte Knoten ist eine Konstante und stellt die Bindung zur Datenbasis her, weiß hinterlegte Knoten sind Variablen, welche während der Mustersuche gebunden werden.}
	\label{fig:titan_pattern}
\end{figure}

Da sich dieses Muster nicht als lineare Sequenz von Knoten und Kanten darstellen lässt, wurde es in Cypher in zwei abstrakte Wege geteilt. Gremlin begegnet dieser Situation mit dem sog. \textit{Backtracking}. Mit Hilfe der \texttt{back}-Funktion lässt sich an einem beliebigen Punkt innerhalb des abstrakten Weges entweder eine feste Anzahl von Schritten oder direkt zu einem definierten Punkt zurückgehen. Das folgende einfache Beispiel soll dies verdeutlichen, es werden alle Kollegen von Alice gesucht, die mit Kollegen zusammenarbeiten, welche älter als 25 sind:

\texttt{alice.out('WORKS\_WITH').as('a').out('WORKS\_WITH').filter\{it.age>25\}.back('a')}

Dabei werden die adjazenten Knoten von \texttt{Alice} mit \texttt{as('a')} markiert, anschließend werden wiederum deren adjazente Knoten dem geforderten Prädikat entsprechend eingeschränkt. Erfüllt ein Nachbar das Prädikat, springt die Traversierung auf den vorher besuchten Knoten zurück und gibt ihn aus.\\
Dieses Konzept kann für die Mustersuche genutzt werden. In Abbildung \ref{fig:titan_pattern} ist \texttt{Alice} die Konstante innerhalb des Musters mit der Bindung an die Datenbasis, die Variablen sind \texttt{b}, \texttt{c} und \texttt{d}. Für Kanten- und Knoteninstanzen sind Einschränkungen hinsichtlich ihres Typs bzw. ihres Bezeichners festgelegt. Die nachfolgende Anfrage sucht alle Teilgraphen innerhalb der Datenbasis und bindet die Variablen an die gefundenen Knoteninstanzen:

\texttt{t = new Table('a','b','c','d'); // stores results}\newline
\texttt{alice.as('a') // 1}\newline
\texttt{.out('WORKS\_WITH').has('type','Employee').as('b') // 2}\newline
\texttt{.out('RESPONSIBLE\_FOR').has('type','Project').as('d') // 3}\newline
\texttt{.back('b') // 4}\newline
\texttt{.out('WORKS\_WITH').has('type','Employee').except('a').as('c') // 5}\newline
\texttt{.both.has('type','Employee').retain('a') // 6}\newline
\texttt{.table(t); // store results into t}

Zunächst wird eine \texttt{Table}-Datenstruktur erzeugt, welche die gefundenen Instanzen aufnimmt. In Schritt 1 wird die Konstante \texttt{Alice} an den Bezeichner \texttt{a} gebunden, anschließend werden die ausgehenden \texttt{WORKS\_WITH}-Beziehungen traversiert und die Menge der Zielknoten auf jene eingeschränkt, die vom Typ \texttt{Employee} sind.\footnote{Die Funktion \texttt{has(key, value)} ist eine Kurzform der \texttt{filter}-Funktion und liefert \texttt{true}, wenn die entsprechende Instanz das Schlüssel-Wert-Paar aufweist, andernfalls \texttt{false}.} Die Menge der Knoten wird der Variable \texttt{b} zugewiesen. Anschließend werden in Schritt 3 deren Projekte selektiert und an die Variable \texttt{d} gebunden. Mittels Backtracking wird in Schritt 4 zurück zu den Projektleitern gegangen. Von diesen ausgehend erfolgt anschließend das Traversieren der ausgehenden \texttt{WORKS\_WITH}-Beziehungen. Die Menge der Zielknoten wird entsprechend ihres Typs gefiltert und der Variable \texttt{c} zugewiesen. Dabei wird eine eventuell existierende Kante zu \texttt{a} nicht berücksichtigt. In Schritt 6 werden alle inzidenten Kanten der Elemente in \texttt{c} traversiert und dabei mittels \texttt{retain} nur jene Start- bzw. Zielknoten berücksichtigt, die \texttt{a} entsprechen. Im letzten Schritt werden die gefundenen Instanzen in die vorher definierte Tabelle eingefügt. Jede Zeile innerhalb dieser Tabelle entspricht einem gefundenen Teilgraph innerhalb der Datenbasis.

Die gezeigten Beispiele gewähren einen ersten Einblick in die Ausdrucksstärke der Sprache. Durch die Universalität in Bezug auf Programmierbarkeit ist Gremlin ein mächtiges Werkzeug in der Verarbeitung von Graphen. Optimierungen in der Anfrageausführung sind in erster Linie von der Implementierung des jeweiligen GDBMS abhängig. Gremlin selbst nutzt, wenn vorhanden, globale Indexstrukturen für das effiziente Auffinden von Knoten und Kanten anhand ihrer Attribute, sowie die bereits erwähnten knoten-zentrierten Indizes. Der Ausführungsplan lässt sich ebenfalls ausgeben, was eine manuelle Optimierung zulässt. Auf konkrete Optimierungsmechanismen wird in \cite{gremlin_doku:2013} eingegangen.
	
\paragraph*{Transaktionen}

Lese- und Schreibzugriffe erfolgen in Titan grundsätzlich im Kontext einer Transaktion, die beim ersten Zugriff automatisch gestartet wird und an den erzeugenden Thread gebunden ist. Alle nachfolgenden Operationen nutzen die aktive Transaktion bis diese explizit beendet wird, hierfür stehen Funktionen für Commit und Rollback zur Verfügung. Änderungen an der Datenbasis werden zunächst ausschließlich isoliert im Kontext einer Transaktion ausgeführt. Wird die Transaktion zurückgesetzt, werden alle bisherigen Änderungen verworfen. Kommt es während der Transaktionsausführung oder beim Beenden zu einem Fehler, wird dieser an die Anwendung weitergegeben. Titan unterscheidet zwischen temporären und dauerhaften Fehlern: Ein temporärer Fehler zum Beispiel ist der kurzzeitige Verbindungsabbruch im Client-Server-Betrieb, das GDBMS bietet die Option, entsprechend abgebrochene Transaktionen automatisch zu wiederholen. Als dauerhafte Fehler klassifiziert Titan zum Beispiel System- oder Hardwarefehler, bei denen das GDBMS gestoppt wurde. 

Neben den thread-gebundenen unterstützt Titan auch thread-unabhängige Transaktionen. Diese müssen explizit gestartet werden und ermöglichen es, mehrere Threads innerhalb einer Transaktion auszuführen. Hierdurch lässt sich zum Einen parallele Hardware in Graphalgorithmen effizienter nutzen, zum Anderen ermöglicht es die Schachtelung von Transaktionen. Dabei ist jedoch zu beachten, dass Änderungen untergeordneter Transaktionen nicht im Kontext der übergeordneten Transaktion erfolgen und somit nach erfolgreichem Commit global sichtbar sind. Ein Zurücksetzen der übergeordneten Transaktion wird nicht rekursiv auf die eingebetteten Transaktionen angewendet.

Die Verantwortung für die Einhaltung der ACID-Eigenschaften innerhalb des Speichersystems bei der Ausführung nebenläufiger Commits wird an die entsprechende Speicherschicht übergeben. BerkeleyDB wird in Titan mit Standardeinstellungen verwendet, d.h. die Isolationsebene entspricht \texttt{REPEATABLE READ} und es werden somit alle Mehrbenutzeranomalien außer dem Phantom Problem vermieden. Im Gegensatz zu HyperGraphDB werden logische Änderungsoperationen am verwalteten B-Baum beim Commit persistiert und sind somit dauerhaft gespeichert. 

% Die transaktionalen Eigenschaften von Apache Cassandra können in \cite nachvollzogen werden.
Ungeachtet dessen muss die Konsistenz innerhalb des Graphen sichergestellt werden: Sind Attributschlüssel oder Kantenbezeichner als \texttt{UNIQUE} deklariert, dürfen diese nicht von parallel ausgeführten Transaktionen geändert werden. Titan implementiert hierfür ein Sperrverfahren um den exklusiven Zugriff auf die entsprechenden Attribute bzw. Kanten zu garantieren. Beim Zugriff wird durch das GDBMS eine entsprechende Sperre gesetzt und bis zum Ende der Transaktion gehalten. Sperrkonflikte, welche durch das parallele Aktualisieren eindeutiger Attributschlüssel oder Kantenbezeichner entstehen, zählen zu den dauerhaften Fehlern und müssen von der Anwendung behandelt werden.

\subsection{Persistenz-, Index- und Cacheverwaltung}

Titan bildet den Graphen auf ein Datenmodell ab, das nicht für die native Verarbeitung vernetzter Informationen konzipiert ist. Es handelt sich um das Key-Column-Value-Modell (KCV), welches von Google entwickelt wurde und im Datenbanksystem BigTable Verwendung findet\cite{Chang:2006:BDS:1267308.1267323}. Es wird u.a. von Apache Cassandra und Apache HBase implementiert und erweitert das Key-Value-Modell um eine zusätzliche Dimension:  Jedem Key ist eine Menge von Einträgen zugeordnet, wobei jeder Eintrag aus einem eigenen Bezeichner (Column) und einem zugeordneten Wert (Value) besteht. Das Modell ist folglich mit einer Tabelle im relationalen Datenmodell vergleichbar, wobei jede Zeile individuell verschiedene Attribute besitzen kann.\\
Eine Beschreibung der Persistenzverwaltung ist bisher nicht Teil der offiziellen Dokumentation des GDBMS\footnote{Laut Mailing-Liste ist eine entsprechende Dokumentation für Version 0.4.0 des GDBMS geplant: \url{https://groups.google.com/forum/?hl=de\#!topic/aureliusgraphs/ixPXcG4UvSQ}.}. Die nachfolgenden, vereinfachten Erläuterungen basieren auf den Resultaten eines Reverse Engineering\cite{github_delft:2013} mit Stand Juni 2013 und einer teilweisen Untersuchung des Quelltextes. Die Persistenzverwaltung lässt sich in zwei Schichten unterteilen: Eine Speicherschicht, welche für die Verwaltung der Informationen innerhalb des KCV-Modells verantwortlich ist und eine Datenbankschicht, welche die Informationen in das Property-Graph-Modell überführt und für die Anwendung zur Verfügung stellt. Nachfolgend wird die Abbildung innerhalb der Speicherschicht erläutert. 

Titan verwendet mehrere KCV-Datenbanken für die Speicherung der Datenbasis und interner Indexstrukturen. Der \texttt{EdgeStore} beinhaltet die Topologie des Graphen sowie die an Knoten und Kanten hinterlegten Nutzdaten, wie in OrientDB werden diese in Titan nicht getrennt voneinander  gespeichert. Abbildung \ref{fig:titan_edgestore_row} zeigt die vereinfachte Darstellung eines Knotens im KCV-Modell am Beispiel des Mitarbeiters \texttt{Alice}.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.8]{titan_edgestore_record.pdf}
	\caption[Titan: Datensatz eines Knotens]{Vereinfachte Darstellung der Repräsentation eines Datensatzes im \texttt{EdgeStore}. Grau hinterlegte Bereiche dienen der Beschreibung der einzelnen Komponenten innerhalb des Datensatzes.}
	\label{fig:titan_edgestore_row}
\end{figure}

Die Speicherung erfolgt knoten-zentriert: Unter Angabe einer Knoten-Identität kann auf den zugehörigen Datensatz zugegriffen werden. Ein Eintrag innerhalb des Datensatzes repräsentiert entweder die Werte eines Knotenattributes oder die Kanteninstanzen zu einem Kantenbezeichner. Die Unterscheidung erfolgt anhand der Column eines Eintrages, die entweder ein \texttt{TitanKey} oder ein \texttt{TitanLabel} ist. In der Abbildung wird der Typ durch seinen global eindeutigen Namen dargestellt (z.B. \texttt{age}).\footnote{Instanzen von \texttt{TitanKey} und \texttt{TitanLabel} werden ebenfalls innerhalb des \texttt{EdgeStore} gespeichert, ihre Attribute setzen sich aus dem Namen und den definierten Integritätsbedingungen zusammen.}\\
Handelt es sich um einen als \texttt{UNIQUE} deklarierten Typ, so ist dem Eintrag genau ein Wert zugeordnet, was im Beispiel auf alle Attributschlüssel des Knotens zutrifft. Im Gegensatz dazu werden die Werte gewöhnlicher Typen zusammen gespeichert. Die Abbildung verdeutlicht dies am Beispiel der \texttt{WORKS\_WITH}-Beziehung: Alle Kanteninstanzen mit dem entsprechenden Bezeichner sind einer Column zugeordnet. Jede Instanz wird dabei durch einen eigenen Eintrag repräsentiert. Dieser besitzt eine eindeutige Identität, im Beispiel sind dies die Werte \texttt{1} und \texttt{2}. Wird beim manuellen Erzeugen eines \texttt{TitanLabel} ein Primärschlüssel angegeben, so wird der entsprechende Attributwert als Identität verwendet. Die Einträge einer Column werden sortiert nach dieser Identität gespeichert, was bedeutet, dass bei entsprechender Werteinschränkung ein effizientes Suchen innerhalb der Einträge möglich ist.\footnote{An dieser Stelle wird deutlich, warum Aurelius die manuelle Typisierung von Attributwerten empfiehlt: Durch die Vergabe eines Datentyps besitzt jeder Eintrag eine feste Länge und die Berechnung der absoluten Position innerhalb der serialisierten Wertemenge ist effizient möglich. Werden hingegen beliebige Datentypen als Attributwert zugelassen, erfordert dies die gemeinsame Speicherung von Typ-Information und Wert. Ein Eintrag besitzt somit eine variable Länge, was die effiziente Berechnung absoluter Positionen unmöglich macht.}\\
Die \texttt{WORKS\_WITH}-Beziehung ist keine unidirektionale Kante und lässt sich somit in beiden Richtungen traversieren. Die entsprechenden Kanteninformationen sind demzufolge an Start- und Zielknoten gespeichert. Im Beispiel ist dies die ausgehende Kante zu Bob (ID 23) und die eingehende Kante von Eve (ID 31). Kantenattribute werden als assoziatives Array innerhalb des Wertes redundant hinterlegt.

Der Aufwand, die Nachbarschaft eines Knotens abzufragen, ist wesentlich vom eingesetzten Speichersystem abhängig. Apache Cassandra basiert auf einer verteilten Hashtabelle und erlaubt den Zugriff auf einen Eintrag im Datensatz in konstanter Zeit\cite{Lakshman:2009:CSS:1582716.1582722}, während in BerkeleyDB der Aufwand in einem logarithmischen Verhältnis zur Anzahl der Einträge steht. Ein Defizit bei Verwendung von BerkeleyDB ist die fehlende Unterstützung der beschriebenen knoten-zentrierten Speicherung: Titan bildet das KCV-Modell auf das von BerkeleyDB verwendete Key-Value-Modell ab, indem es für jedes Column-Value-Paar innerhalb eines Datensatzes ein eigenes Key-Value-Paar erzeugt und in das Speichersystem einfügt.\footnote{Dies lässt sich im Quelltext unter \url{https://github.com/thinkaurelius/titan/blob/0.3.2/titan-core/src/main/java/com/thinkaurelius/titan/diskstorage/keycolumnvalue/keyvalue/OrderedKeyValueStoreAdapter.java\#L73} nachvollziehen.} Daraus ergibt sich, dass der Umfang der hinterlegten Einträge in BerkeleyDB der Anzahl der Einträge in allen Datensätzen einer äquivalenten KCV-Repräsentation entspricht.\footnote{Diese Vermutung wurde auf der Mailing-Liste durch die Entwickler bestätigt: \url{https://groups.google.com/forum/?hl=de\#!topic/aureliusgraphs/ixPXcG4UvSQ}.}

\paragraph*{Indexverwaltung}

Sind die Identitäten der Knoten und Kanten nicht bekannt, bietet das GDBMS mit internen und externen Indexstrukturen zwei Mechanismen für den performanten Zugriff auf die hinterlegten Informationen. Die internen Indexstrukturen sind der \texttt{VertexIndex} und der \texttt{EdgeIndex}, die den Zugriff auf Knoten- bzw. Kanteninstanzen unter Angabe eines Schlüssel-Wert-Paares erlauben. Beide Indizes werden jeweils durch eine KCV-Datenbank repräsentiert, die Identifikation eines Datensatzes erfolgt unter Angabe eines Attributwertes. Die Einträge in der entsprechenden Zeile bestehen aus dem Attributschlüssel als Column, den Wert bildet die Menge der Knoten- bzw. Kanten-Identitäten, welche das zugehörige Schlüssel-Wert-Paar aufweisen. Abbildung \ref{fig:titan_vertexindex_row} verdeutlicht dies am Beispiel des Attributwertes \texttt{Employee}. Die Syntax für das Anlegen eines Index wurde bereits im Zusammenhang mit Gremlin gezeigt.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.8]{titan_vertexindex_record.pdf}
	\caption[Titan: Datensatz im Knotenindex]{Vereinfachte Darstellung der Repräsentation eines Datensatzes im \texttt{VertexIndex}. Grau hinterlegte Bereiche dienen lediglich der Beschreibung der einzelnen Komponenten innerhalb des Datensatzes.}
	\label{fig:titan_vertexindex_row}
\end{figure}

Im Beispiel sind dem Schlüssel-Wert-Paar \texttt{(\string"type\string",\string"Employee\string")} die Knoten-Identitäten der drei Mitarbeiter (\texttt{23}, \texttt{31} und \texttt{42}) zugeordnet. Der Aufbau des \texttt{EdgeIndex} ist analog.\footnote{Die Identität einer Kante setzt sich aus der Identität ihres Startknotens, dem Bezeichner und der ID des entsprechenden Eintrages im Datensatz des Knotens zusammen.} Die Indexstrukturen werden vom GDBMS in Anfragen berücksichtigt und bei der Manipulation der Datenbasis automatisch aktualisiert.

Die internen Indexstrukturen erlauben lediglich die Suche nach exakten Übereinstimmungen mit definierten Attributwerten. Sollen darüber hinaus komplexere Anfragen durch einen Index unterstützt werden, ist dies über das Einbinden eines externen Index möglich. Titan bietet aktuell zwei Implementierungen an: ElasticSearch\footnote{\url{http://www.elasticsearch.org/}} und Apache Lucene, die beide volltext-basierte und räumliche Anfragen sowie Bereichsanfragen unterstützen. ElasticSearch wird von Aurelius für den Einsatz in einer verteilten Konfiguration empfohlen, während Lucene vorrangig für kleinere, zentrale Installationen des GDBMS genutzt werden soll.

\paragraph*{Cacheverwaltung}

Titan setzt Caches ausschließlich bei der Transaktionsausführung ein:\footnote{BerkeleyDB, Apache Cassandra und HBase bieten darüber hinaus eigene Caching-Mechanismen an, welche jedoch nicht im Rahmen der Arbeit erläutert werden.} Jeder Transaktion ist dabei ein dedizierter Object-Cache zur Zwischenspeicherung von Objektrepräsentationen deserialisierter Knoteninstanzen zugeordnet. Der Cache wird durch eine Hashtabelle mit fester initialer Größe realisiert und sieht keine Verdrängung von Objekten vor.\footnote{Nachzuvollziehen unter \url{https://github.com/thinkaurelius/titan/blob/0.3.2/titan-core/src/main/java/com/thinkaurelius/titan/graphdb/transaction/vertexcache/SimpleVertexCache.java\#L20}.} Ein Eintrag innerhalb des Caches entspricht der Repräsentation eines Knotens innerhalb des KCV-Modells, d.h. alle Attribute und inzidente Kanten eines Knotens werden einem Java-Objekt zugeordnet. Bei einer Leseoperation wird zunächst geprüft, ob sich die angeforderte Information bereits im Cache befindet. Ist dies nicht der Fall, wird auf das jeweilige Speichersystem zugegriffen und das Ergebnis im Cache abgelegt. Alle nachfolgenden Zugriffe auf das gleiche Objekt werden für die Dauer der Transaktion aus dem Cache beantwortet. Wird nur auf einzelne Attribute oder Kanten eines Knotens zugegriffen, werden auch nur diese aus dem Speichersystem geladen. Daraus geht hervor, dass sich Teile der Knoteninformation im Cache oder im Speichersystem befinden können, folglich werden alle Zugriffe mit den Informationen aus dem Cache integriert. Analog zu den bisher betrachteten GDBMS erfolgen alle Änderungen einer Transaktion zunächst innerhalb des Caches und werden erst beim Commit an das Speichersystem übergeben.\\
Nach Abschluss der Transaktion wird der Cache verworfen und die referenzierten Objekte durch den Garbage Collector verdrängt. Titan 0.3.2 eignet sich demnach weniger für die Verwaltung umfangreicher Ergebnismengen, da alle gelesenen Objektinstanzen bis zum Transaktionsende im Cache gehalten werden. Dies ist insbesondere für den eingebetteten Betrieb relevant, da sich hier GDBMS und Anwendung den Heap-Speicher der JVM teilen.\footnote{Das Problem wurde auch von Aurelius erkannt, der Cache wird in der nachfolgenden Version um eine LRU-Verdrängungsstrategie erweitert (siehe \url{https://github.com/thinkaurelius/titan/issues/335}).}

\subsection{Verteilung und Skalierbarkeit}
\label{subsec:titan_verteilung}

Das GDBMS implementiert selbst keine Verteilungsmechanismen, sondern überlässt Replikation und Partitionierung dem eingesetzten Speichersystem. Stellvertretend wird nachfolgend der Verteilungsmechanismus von Apache Cassandra kurz vorgestellt.

Durch die Unterstützung einer fragmentierten Replikation, bietet Apache Cassandra neben der horizontalen Skalierbarkeit von Lese- und Schreibzugriffen sowie des Datenvolumens auch eine Toleranz gegenüber Systemausfällen. Die Zuweisung der Daten zu den Rechnern im Cluster erfolgt durch die Partitionierung des Wertebereiches einer Hash-Funktion, wobei jedem Rechner ein Abschnitt des Wertebereiches zugewiesen ist. Unter Angabe des Zeilenschlüssels wird der Hash-Wert berechnet und die zugehörige Zeile der entsprechenden Partition zugeordnet. Ein Replikations-Faktor legt fest, auf welche Anzahl von Rechnern ein Teilbereich der Datenbasis redundant abgelegt ist. Die Verteilungsinformationen liegen an allen Rechnern im Cluster vor, jeder Rechner kann folglich Lese- und Schreibzugriffe entgegennehmen und als Koordinator fungieren.

Schreibzugriffe werden vom Koordinator an alle Replikate eines Teilbereiches weitergeleitet. Ein anwendungsseitig definiertes Konsistenz-Level legt fest, auf wie vielen Replikaten der Schreibzugriff erfolgreich sein muss, bevor eine Bestätigung an die Anwendung gesendet wird.\footnote{Beispiele für Konsistenz-Level sind \texttt{ONE}, \texttt{QUORUM} und \texttt{ALL} mit denen sich der Anteil zu berücksichtigender Replikate definieren lässt.} Cassandra stellt sicher, dass alle Replikate letztendlich konsistent sind. Das Konsistenz-Level bildet folglich den Kompromiss zwischen Schreibperformance und Fehlertoleranz.\\
Bei lesenden Zugriffen wird ebenfalls ein Konsistenz-Level definiert. Es legt fest, an wie viele Replikate eine Anfrage vom Koordinator weitergeleitet wird. Werden mehrere Replikate angefragt, prüft der Koordinator die Konsistenz der gelesenen Informationen. Sind diese nicht konsistent, wird der aktuelle Wert auf Basis eines Zeitstempels ermittelt und an die Anwendung zurückgegeben. Das Konsistenz-Level stellt bei Lesezugriffen folglich den Kompromiss zwischen Leseperformance und Aktualität der Daten dar.\\
Die eingesetzte Hash-Funktion garantiert eine gleichmäßige Verteilung der Datenbasis auf das Cluster, folglich können logisch benachbarte Knoten physisch getrennt gespeichert sein. Die Dokumentation von Titan beschreibt nicht, inwieweit die Verteilung beeinflusst werden kann. In \cite{titan_bench:2013} erwähnt Aurelius die Verwendung einer domänenspezifischen Partitionierung des Graphen, geht dabei jedoch nicht auf Details ein. Das Konsistenz-Level für lesende und schreibende Zugriffe lässt sich, neben weiteren Einstellungen, im GDBMS konfigurieren und ist standardmäßig auf die Mehrheit der Replikate festgelegt. Damit wird gewährleistet, dass gelesene Daten immer aktuell sind.	