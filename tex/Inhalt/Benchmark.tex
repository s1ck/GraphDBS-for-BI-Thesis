\chapter{Benchmark von Graphdatenbanksystemen}
\label{cha:benchmark}

In diesem Kapitel soll die Leistungsfähigkeit von Neo4j und Titan bei der Ausführung graphenspezifischer Operationen bewertet werden. Dabei ist es von besonderem Interesse, ob sich die im vorhergehenden Kapitel aufgeführten funktionalen Unterschiede auf die Performance der GDBMS auswirken. Zusätzlich soll beurteilt werden, inwieweit sich Cypher und Gremlin für die Formulierung analytischer Anfragen eignen. Zunächst werden Testgraphen, Operationen und das Testsystem vorgestellt, anschließend wird auf die Konfiguration der einzelnen GDBMS sowie auf die Methodik bei der Durchführung der Messungen eingegangen. Im zweiten, abschließenden Teil des Kapitels werden die Ergebnisse vorgestellt und bewertet.

\section{Testumgebung}

Bei der Analyse verwandter Arbeiten wurde festgestellt, dass aktuell - Stand Oktober 2013 - kein standardisierter Benchmark für GDBMS existiert. Die Herangehensweise fußt auf den Empfehlungen von Dominguez-Sal et al.\cite{Dominguez-Sal2011}, da diese bereits in den verwandten Arbeiten von Ciglan et al.\cite{Ciglan:2012} und Gehrels\cite{Gehrels:2013} berücksichtigt wurden und somit als Quasi-Standard gewertet werden.

\subsection{Datengrundlage}

In Absprache mit dem Projektverantwortlichen wurde vereinbart, reale Datensätze als Datengrundlage zu verwenden. Für das in Abschnitt \ref{sec:anforderungen} beschriebene Forschungsvorhaben ist vorgesehen, Informationsnetzwerke aus unterschiedlichen Geschäftsinformationssystemen zu integrieren und den daraus resultierenden Graphen zu analysieren. Die Netzwerke in den Quellsystemen können dabei unterschiedliche topologische Eigenschaften aufweisen und die in ihnen gespeicherten Informationen verschiedenen Klassen zugeordnet sein. Ein ERP-System verwaltet zum Beispiel Rechnungen, während ein CRM-System vorrangig Kundenaktivitäten speichert. Auf Grund der Wechselwirkungen zwischen den Entitäten innerhalb der einzelnen Quellsysteme entstehen verschiedenartige Beziehungsstrukturen.Folglich ist der integrierte Graph bezogen auf Topologie und Nutzdaten heterogen.\\
Die Algorithmen zur Erzeugung von Zufallsgraphen, welche in den verwandten Arbeiten eingesetzt wurden, bilden ausschließlich homogene Netzwerke ab, in denen alle Klassen einer Domäne zugeordnet sind. In \cite{Vicknair:2010:CGD:1900008.1900067} sind es zum Beispiel Herkunftsinformationen innerhalb eines Entstehungsprozesses, in \cite{Holzschuher:2013:PGQ:2457317.2457351} Personen, Aktivitäten, Organisationen und Nachrichten in einem sozialen Netzwerk, in \cite{Ciglan:2012}, \cite{Dominguez-Sal:2010:SGD:1927585.1927590} und \cite{Gehrels:2013} hingegen wird generell auf eine Klassifizierung der Informationen verzichtet. Das Erzeugen synthetischer, heterogener Graphen ist sehr aufwändig, da jeder Klasse und jeder Beziehungsart hinsichtlich ihrer Erzeugung eine eigene Logik zugeordnet werden muss.

Weil reale Daten aus Geschäftsinformationssystemen nicht frei zur Verfügung stehen, werden stellvertretend für heterogene Netzwerke \texttt{amazon-meta}\cite{snap_amazon:2013} und \texttt{soc-Pokec}\cite{snap_pokec:2013} verwendet, beides Datensätze des Stanford Network Analysis Project\footnote{\url{https://snap.stanford.edu/}}. Das Informationsnetzwerk \texttt{amazon-meta} beinhaltet Produktinformationen des Onlinehändlers Amazon\footnote{\url{http://www.amazon.com}}, wozu u.a. Produktbewertungen und Beziehungen zwischen Produkten zählen.\footnote{Es handelt sich dabei um ähnliche Produkte, die laut Amazon oft zusammen gekauft werden.} Pokec hingegen ist ein slowakisches soziales Online-Netzwerk, in dem Nutzer durch gerichtete Freundschaftsbeziehungen miteinander verbunden sind.\footnote{\url{http://pokec.azet.sk/}} Abbildung \ref{fig:testdata} zeigt das integrierte Schema beider Netzwerke als Property-Graph.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.75]{schema.pdf}
	\caption[Benchmark: Schema Testdaten]{Integriertes Schema aus Amazon- und Pokec-Daten.}
	\label{fig:testdata}
\end{figure}

Beide Datensätze verfügen über eine Klasse \texttt{User}. Deren Instanzen werden innerhalb von\linebreak~\texttt{amazon-meta} durch eine eindeutige Identität repräsentiert und stehen nicht in Beziehung zueinander. In \texttt{soc-Pokec} hingegen weisen die Instanzen eine Vielzahl von Attributen auf und sind durch gerichtete \texttt{FRIEND\_OF}-Beziehungen miteinander verbunden. Die Anzahl der Nutzer stimmt in beiden Datensätzen annähernd überein, \texttt{amazon-meta} weist ca. 1.5 Mio., \texttt{soc-Pokec} etwa 1.6 Mio. Nutzer auf. Im Rahmen der Datenaufbereitung wurden zunächst Pokec-Nutzer pseudozufällig auf Amazon-Nutzer abgebildet, anschließend wurde der durch die ausgewählten Knoten induzierte Teilgraph aus \texttt{soc-Pokec} extrahiert und mit \texttt{amazon-meta} zu einem integrierten Graph zusammengeführt.\\
Die Netzwerke enthalten neben den topologischen Informationen auch Nutzdaten, welche für Gruppen, Produkte und Bewertungen vollständig aus den Rohdaten übernommen wurden, für die Nutzer hingegen wurde eine Auswahl von Attributen unterschiedlichen Datentyps getroffen. Die Rohdaten beider Netzwerke wurden für die weitere Verwendung in das textbasierte Geoff-Format\footnote{\url{http://nigelsmall.com/geoff}} überführt, welches von Neo4j entwickelt wurde.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|l|rl|rl|rl|rl|rl|rl|rl|rl|rl|}
	\hline
   	 & \multicolumn{8}{c|}{\textbf{Knoten}} & \multicolumn{2}{c|}{\textbf{Attribute}} \\ \cline{2-11}
   	\textbf{Graph} & \multicolumn{2}{c|}{\texttt{Group}} & \multicolumn{2}{c|}{\texttt{Product}} & \multicolumn{2}{c|}{\texttt{User}} & \multicolumn{2}{c|}{$\Sigma$} & \multicolumn{2}{c|}{$\Sigma$} \\
   	\hline
   	   	\hline
   	\texttt{orig} & \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{542\,684} & \multicolumn{2}{c|}{1\,555\,124} & \multicolumn{2}{c|}{2\,097\,819} & \multicolumn{2}{c|}{20\,377\,902} \\
   	\hline
   	\hline
	\texttt{p\_100} & 1 & (1) & 126 & (1) & 347\,752 & (1) & 347\,879 & (1) & 1\,874\,907 & (1)\\
	\hline
	\texttt{p\_1K} & 4 & (4) & 1\,089 & (8.64) & 665\,116 & (1.91) & 666\,209 & (1.92) & 3\,710\,473 & (1.98) \\
	\hline
	\texttt{p\_10K} & 4 & (1) & 10\,047 & (9.23) & 976\,985 & (1.47) & 987\,036 & (1.47) & 7\,255\,153 & (1.96) \\
   	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Anzahl Knoten und Attribute]{Anzahl Instanzen der verschiedenen Knotenklassen und Gesamtanzahl der Knoten- und Kantenattribute.}
		\label{tab:datasets_nodes}
\end{table}
\renewcommand{\arraystretch}{1}

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|l|rl|rl|rl|rl|rl|}
	\hline
	& \multicolumn{10}{c|}{\textbf{Kanten}} \\ \cline{2-11}

   	\textbf{Graph} & \multicolumn{2}{c|}{\texttt{BELONGS\_TO}} & \multicolumn{2}{c|}{\texttt{SIMILAR\_TO}} & \multicolumn{2}{c|}{\texttt{REVIEWED\_BY}} & \multicolumn{2}{c|}{\texttt{FRIEND\_OF}} & \multicolumn{2}{c|}{$\Sigma$} \\
   	\hline
   	\hline
   	\texttt{orig} & \multicolumn{2}{c|}{542\,684} & \multicolumn{2}{c|}{1\,231\,400} & \multicolumn{2}{c|}{7\,593\,109} & \multicolumn{2}{c|}{27\,787\,537} & \multicolumn{2}{c|}{37\,154\,730} \\
	\hline
	\hline
	\texttt{p\_100} & 126 & (1) & 396 & (1) & 1\,909 & (1) & 704\,092 & (1) & 706\,523 & (1) \\
	\hline
	\texttt{p\_1K} & 1\,089 & (8.64) & 3\,365 & (8.5) & 29\,848 & (15.64) & 1\,830\,064 & (2.6) & 1\,864\,366 & (2.64) \\
	\hline
	\texttt{p\_10K} & 10\,048 & (9.23) & 27\,976 & (8.31) & 401\,917 & (13.47) & 3\,576\,276 & (1.95) & 4\,016\,216 & (2.15) \\
	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Anzahl Kanten]{Anzahl Instanzen der verschiedenen Kantenbezeichner.}
	\label{tab:datasets_edges}
\end{table}
\renewcommand{\arraystretch}{1}

Ein wichtiges Kriterium bei der Durchführung eines Benchmarks ist das Leistungsverhalten einer Anfrage bei steigendem Datenvolumen. Die Größe synthetisch erzeugter Datensätze lässt sich dem Bedarf entsprechend definieren, reale Datensätze hingegen besitzen eine festgelegte Größe. Mit dem Ziel, die Skalierbarkeit von Anfragen dennoch untersuchen zu können, wurden zusammenhängende Teilgraphen aus dem integrierten Datensatz extrahiert. Die Teilgraphen sind bezüglich der Knoten aus \texttt{amazon-meta} induziert, dies gilt nicht für den Teilgraph, welcher ausschließlich aus Nutzerknoten besteht.\footnote{Der Algorithmus kann unter \url{https://github.com/s1ck/master_thesis/blob/master/benchmark/src/main/java/de/s1ckboy/thesis/tools/SubgraphExtraction.java} eingesehen werden.}

Dominguez-Sal et al. empfehlen die Angabe eines einzelnen Skalierungsfaktors, der die Anzahl der erzeugten Knoten und Kanten bestimmt, dieses Vorgehen lässt sich jedoch bei der Verwendung realer Datensätze nicht umsetzen. Durch die Wahl der Parameter des Extraktionsalgorithmus wurde daher versucht, möglichst konstante Wachstumsfaktoren zu erreichen. Die Tabellen \ref{tab:datasets_nodes} und \ref{tab:datasets_edges} stellen den integrierten Graph (\texttt{orig}) und die extrahierten Teilgraphen bezogen auf die Anzahl der Knoten und Kanten gruppiert nach ihrer jeweiligen Klasse gegenüber. Zusätzlich wird der Wachstumsfaktor für jeden Wert in Relation auf dessen Äquivalent im nächstkleineren Graphen angeben. Ein Nachteil dieser Herangehensweise ist, dass sich die topologischen Eigenschaften der verschiedenen extrahierten Teilgraphen unterscheiden können, was bei der nachfolgenden Bewertung berücksichtigt wird.

\subsection{Operationen}

Stellvertretend für jene Anfragen, welche für die Analyse von Unternehmensdaten im Forschungsvorhaben relevant sind, wurden auf Grundlage des vorgestellten Schemas mehrere Anfragen definiert, die jeweils einzelne oder mehrere der in Abschnitt \ref{subsec:graph_operations} vorgestellten graphenspezifischen Operationen beinhalten. Es handelt sich um lokale Anfragen, die ausgehend von einem Knoten oder einer Knotenmenge einen Teil des Graphen analysieren. Dabei werden seine Topologie und auch Nutzdaten in die Operationen einbezogen. Es wurde bewusst auf rein topologische und globale Anfragen verzichtet, da sie für das Forschungsvorhaben nicht relevant sind, Beispiele hierfür sind das Berechnen der k-Nachbarschaft ohne Berücksichtigung von Kantenbezeichnern oder das Auslesen aller Kanten. Gleiches gilt für Schreibzugriffe, hier ist lediglich die Performance der Bulk-Load-Mechanismen von Interesse. 

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.3cm}|>{\arraybackslash}m{13.45cm}|}
	\hline
   	\multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{c|}{\textbf{Beschreibung (Kategorisierung der Operationen)}} \\
	\hline
	\hline
	\textbf{\texttt{import}} & Importieren der Testgraphen in das jeweilige GDBMS unter Verwendung von Bulk-Load-Mechanismen. (Schreibperformance beim Bulk-Load)\\
	\hline
	\textbf{\texttt{random\_read}} & Zufällige Auswahl einzelner Produkte und Nutzer sowie vollständiges Auslesen ihrer Attribute. (Leseperformance beim Attributzugriff) \\
	\hline
	\textbf{\texttt{sim\_products}} & Zufällige Auswahl eines Produktes und anschließendes Traversieren  ähnlicher Produkte bis Abstand $\leq$ 2, die Kantenrichtung ist nicht relevant. Die Produkttitel sollen ausgegeben werden, jeder Titel soll einmalig in der Ergebnismenge sein. (Lokale Traversierung, Einschränkung) \\
	\hline
	\textbf{\texttt{foaf\_reviews}} & Zufällige Auswahl eines Nutzers und anschließende Selektion der Produkte, für die Freunde oder deren Freunde ein Review geschrieben haben. Das Ergebnis soll nach Produkttitel gruppiert und nach durchschnittlicher Bewertung sortiert werden. (Lokale Traversierung, Einschränkung, Gruppierung, Aggregation)\\
	\hline
	\textbf{\texttt{path\_all}} & Zufällige Auswahl eines Nutzers und eines Produktes und anschließendes Berechnen aller Pfade der Länge $\leq 4$ zwischen beiden Knoten. Dabei sollen nur die Kantenbezeichner \texttt{FRIEND\_OF}, \texttt{REVIEWED\_BY} und \texttt{SIMILAR\_TO} berücksichtigt werden, die Kantenrichtung ist nicht relevant. Im Ergebnis sollen die Pfade gruppiert nach Länge und der jeweiligen Anzahl ausgegeben werden. (Erreichbarkeit, Einschränkung, Gruppierung, Aggregation) \\
	\hline
	\textbf{\texttt{path\_shortest}} & Zufällige Auswahl zweier Nutzer und anschließende Berechnung des kürzesten Pfades unter Berücksichtigung der Kantenbezeichner \texttt{FRIEND\_OF}, \texttt{REVIEWED\_BY} und \texttt{SIMILAR\_TO}. Die maximale Pfadlänge beträgt 4, Kantenrichtungen werden nicht berücksichtigt. Das Ergebnis soll das Attribut \texttt{\_\_id\_\_} der Knoten innerhalb des Pfades beinhalten. (Erreichbarkeit, Einschränkung) \\
	\hline
	\textbf{\texttt{top\_regions}} & Auswahl aller Produkte, welche der Gruppe \texttt{'Books'} angehören und das Prädikat \texttt{salesrank} $\leq$ 500\,000 erfüllen. Das Ergebnis soll nach dem Attribut \texttt{region} jener Nutzer gruppiert werden, welche die Produkte mit einem \texttt{rating} $\geq$ 3 bewertet haben und dies für $\geq$ 5 Nutzer hilfreich war. Darüber hinaus soll das Ergebnis nach der Anzahl der Produkte pro Region sortiert und die oberen 10 Regionen ausgegeben werden. (Lokale Traversierung, Aggregation, Gruppierung, Selektion) \\
	\hline
	\textbf{\texttt{sim\_pattern}} & Zufällige Auswahl eines Nutzers und anschließendes Bestimmen seiner Freunde, die für mindestens ein übereinstimmendes Produkt Reviews geschrieben haben. Das Ergebnis soll den Nutzer selbst, die Freunde des Nutzers und die übereinstimmende Produktmenge beinhalten. (Lokale exakte Mustersuche) \\
	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Beschreibung der einzelnen Anfragen]{Namen und Beschreibungen der durchzuführenden Anfragen.}
	\label{tab:benchmark_queries}
\end{table}
\renewcommand{\arraystretch}{1}

In Tabelle \ref{tab:benchmark_queries} werden die Anfragen beschrieben und entsprechend der verwendeten Operationen kategorisiert. Alle Anfragen wurden mittels Cypher und Gremlin realisiert und sind in Anhang \ref{anh:queries} aufgeführt. Eine Implementierung unter Verwendung der vorhandenen Java APIs wurde nicht durchgeführt, da in dieser Arbeit die Verwendung aktueller graphenspezifischer Anfragesprachen für die Formulierung komplexerer, analytischer Anfragen vordergründig ist. Bereits in \cite{Ciglan:2012}, \cite{Gehrels:2013} und \cite{Holzschuher:2013:PGQ:2457317.2457351} wurde gezeigt, dass sich der Verzicht auf eine zusätzliche Anfrageverarbeitung positiv auf das Leistungsverhalten auswirkt. Eine Eignung der APIs für die Implementierung beliebiger analytischer Algorithmen und Operationen wurde den Systemen bereits im vorhergehenden Kapitel attestiert.
\newpage
\subsection{Systemkonfiguration}

Die verwendete Testumgebung setzt sich wie folgt zusammen:

\begin{itemize}
	\setlength{\parskip}{1pt}
	\item Intel i7-2620M (2x3.4 Ghz)
	\item 8 GB DDR-3 RAM (1333 Mhz)
	\item Crucial M4 SSD (128 GB)
	\item Xubuntu 13.10 64-Bit (Kernel 3.11.0-12-generic, ext4)
	\item Java(TM) SE Runtime Environment (build 1.7.0\_45-b18)
\end{itemize}

\paragraph*{Neo4j}

Das GDBMS wird in einer zentralen, eingebetteten Konfiguration verwendet, Anfragen werden sowohl in Cypher als auch in Gremlin ausgeführt. Für Cypher-Anfragen wird die im vorhergehenden Kapitel betrachtete Version 2.0.0-M04 eingesetzt. Die Berücksichtigung von Gremlin verbessert die Vergleichbarkeit mit Titan, macht es jedoch erforderlich, für die Durchführung auf Version 1.9.4 des GDBMS zurückzugreifen, da Blueprints 2.4.0 und somit auch Gremlin bisher nicht kompatibel zu den Neuerungen in Neo4j 2.0 sind.  Die Ausführung von Cypher erfolgt unter Verwendung der \texttt{ExecutionEngine}\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/tutorials-cypher-java.html}}, für Gremlin wird die in der Dokumentation beschriebene \texttt{GremlinGroovyScriptEngine}\footnote{\texttt{https://github.com/tinkerpop/gremlin/wiki/Using-Gremlin-through-Java\#using-jsr-223-\linebreak~gremlingroovyscriptengine}} genutzt.

Für den Bulk-Load der Testgraphen wird im \texttt{import}-Benchmark der von Neo4j zur Verfügung gestellte \texttt{BatchInserter} entsprechend der Dokumentation\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/batchinsert.html}} eingesetzt. Während des Imports erfolgt das Aktualisieren eines zusätzlichen Lucene-Index auf dem Knotenattribut \texttt{\_\_id\_\_}. Bei der Verwendung von Neo4j 2.0.0-M04 werden darüber hinaus entsprechend der Knotenklasse Knotenbezeichner gesetzt, welche folglich nur in Cypher-Anfragen berücksichtigt werden können.

Die Kernel-Einstellungen\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/kernel-configuration.html}} des GDBMS werden unverändert übernommen. Die Größe des Heap-Speichers der JVM wird entsprechend den Empfehlungen\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/configuration-jvm.html}} auf 4 GB festgelegt, eine Änderung des Stack-Speichers erfolgt nicht. Darüber hinaus wird der Concurrent Mark and Sweep Compactor Garbage Collector\footnote{\url{http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html\#BehavioralOptions}} verwendet.\\
Die Einstellungen des Object-Cache bleiben unverändert, es wird demnach die in Abschnitt \ref{subsec:neo4j_persistency} beschriebene Standard-Implementierung genutzt. Der Filesystem-Cache wurde entsprechend der Größe der Stores angepasst. Mit dem Ziel den Speicherbedarf zu ermitteln, wurde der größte Testgraph (\texttt{p\_10K}) importiert und die Größe der Stores im Dateisystem bestimmt. Für den Knoten-Store sind dies 20 MB, für den Kanten-Store 150 MB.\footnote{Dieser Wert lässt sich ebenfalls aus der Datensatzgröße von 14 bzw. 33 Byte und der Anzahl Knoten bzw. Kanten in Tabelle \ref{tab:datasets_nodes} bzw. \ref{tab:datasets_edges} berechnen.} Interessant ist, dass trotz Verwendung von String- und Array-Properties der Property-Store für primitive Datentypen den größten Speicherbedarf aufweist.\footnote{Für primitive Datentypen werden 150 MB, für Strings 50 MB und für Arrays 10 MB beansprucht.} Neo4j verwendet für Strings und Arrays zusätzliche Kompressionsmethoden\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/short-strings.html} und \url{http://docs.neo4j.org/chunked/2.0.0-M04/short-arrays.html}} und fügt, wenn möglich, die entsprechenden Werte in den Property-Store für primitive Datentypen ein, damit wird eine zusätzliche Indirektion beim Lese- und Schreibzugriff vermieden. Die Anpassung des Filesystem-Cache ermöglicht es die komplette Datenbasis im Hauptspeicher vorzuhalten.

\paragraph*{Titan}

Das GDBMS wird ebenfalls in einer zentralen, eingebetteten Konfiguration verwendet. Anfragen werden ausschließlich in Gremlin ausgeführt, dies erfolgt wie bei Neo4j unter Verwendung der \texttt{GremlinGroovyScriptEngine}. Das verwendete Speichersystem ist BerkeleyDB Java Edition, die Konfiguration erfolgt ausschließlich mit den von Titan zur Verfügung gestellten Parametern.

Für den Import der Testgraphen wird der im TinkerPop-Projekt verfügbare \texttt{BatchGraph} verwendet, eine Wrapper-Klasse, die Bulk-Load-Funktionalität für blueprints-kompatible GDBMS zur Verfügung stellt.\footnote{\url{https://github.com/tinkerpop/blueprints/wiki/Batch-Implementation}} Die Verwendung von \texttt{BatchGraph} wird von Aurelius für Graphen mit bis zu 100 Mio. Kanten empfohlen. Zusätzlich wurde der Konfigurationsparameter \texttt{storage.batch-loading} auf \texttt{true} gesetzt, dies deaktiviert die internen Konsistenzmechanismen und soll den Import beschleunigen.\\
Die Durchführung erfolgt sowohl mit manueller als auch mit systemseitiger Typdefinition, damit soll untersucht werden, inwieweit sich die Festlegung der Datentypen auf die Leistungsfähigkeit des GDBMS auswirkt. Bei der manuellen Vergabe werden Instanzen von \texttt{TitanKey} bzw. \texttt{TitanLabel} vor dem Datenimport erzeugt. Für Instanzen von \texttt{TitanKey} werden Attributschlüssel, Datentyp des Attributwertes und Eindeutigkeit an der Instanz festgelegt, dem Knotenattribut \texttt{\_\_id\_\_} wird, wie bei Neo4j, ein Index zugeordnet. Die Instanzen von \texttt{TitanLabel} werden den vier Beziehungsarten entsprechend bezeichnet, \texttt{BELONGS\_TO}-Kanten werden zusätzlich als $n:1$-Beziehung zwischen Produkt und Gruppe deklariert. 

Entsprechend der Empfehlung von Aurelius werden BerkeleyDB 80\% des Heap-Speichers zur Verfügung gestellt.\footnote{\url{https://github.com/thinkaurelius/titan/wiki/Using-BerkeleyDB}} Auch dieser wird, wie bei Neo4j, auf insgesamt 4 GB festgelegt. Oracle empfiehlt für BerkeleyDB ebenfalls die Verwendung des Concurrent Mark and Sweep Compactor Garbage Collector, welcher folglich bei der Durchführung aktiviert ist.\footnote{\url{http://www.oracle.com/technetwork/database/berkeleydb/je-faq-096044.html\#WhatJVMparametersshouldIconsiderwhentuninganapplicationwithalargecachesize}}

\subsection{Methodik}

% Verweis auf Framework
Für die Durchführung der Messungen wurde im Rahmen der Arbeit ein Java-Framework\footnote{\url{https://github.com/s1ck/master_thesis/tree/master/benchmark}} entwickelt, mit welchem sich individuell konfigurierbare Benchmarks entsprechend einem definierten Protokoll ausführen lassen. Jede der zu messenden Anfragen kann einzeln aktiviert und konfiguriert werden. Dabei lässt sich die Ausführungsreihenfolge beliebig variieren, bei der Durchführung wird die Reihenfolge entsprechend Tabelle \ref{tab:benchmark_queries} beibehalten.

% Import1
Die Testgraphen liegen im Geoff-Format vor und werden unter Verwendung eines Iterators eingelesen. Dieser Ansatz ermöglicht die Verarbeitung umfangreicher Datensätze ohne zusätzliche Inanspruchnahme des Hauptspeichers und gleichzeitig die Messung der unmittelbaren Schreibperformance in Abhängigkeit vom Externspeicher.

% Warmup Caches
Zur Simulation eines realistischen Antwortzeitverhaltens empfehlen Dominguez-Sal et al. ein sog. warmup der Caches. Darunter versteht man die Ausführung von Anfragen vor der eigentlichen Messung, was die Wahrscheinlichkeit eines Cache-Hits während der Messung erhöht. Eine Zielstellung des Forschungsvorhabens ist die Verwendung des GDBMS im Rahmen einer Analyseplattform. Diese soll nicht nur bei Bedarf gestartet werden, sondern permanent in Betrieb sein. Folglich ist davon auszugehen, dass sich entweder der gesamte Graph oder Teilgraphen zum Zeitpunkt der Anfrage in den Caches befinden und somit eine effizientere Ausführung möglich ist.\\ % Darüber hinaus verdeutlichen aktuelle Entwicklungen, wie zum Beispiel SAP HANA\cite{plattner2011memory}, dass die Verwendung mehrerer hundert Gigabyte Hauptspeicher in aktuellen Server-Systemen kosteneffizient ist und auf lange Sicht die Bedeutung der im Vergleich langsamen Externspeichern sinken lässt.\\
Mit dem Ziel, die Vergleichbarkeit der Situation zu gewährleisten, wurde vor der Ausführung einer Messung eine Iteration über die Gesamtheit der Knoten- und auch Kantenmenge durchgeführt.\footnote{In Titan erfolgt in der warmup-Prozedur nach 20\,000 gelesenen Objekten ein Commit, um potentielle Speicherprobleme durch den Transaktionscache zu verhindern.} Zusätzlich wurde das Knotenattribut \texttt{\_\_type\_\_} ausgelesen und die jeweilige Identität nach Typ gruppiert gespeichert, diese Informationen werden für die pseudozufällige Auswahl der Startknoten einer Anfrage genutzt.

% Zeitmessung
Ein Benchmark zu jeder Anfrage wird nach folgendem Protokoll durchgeführt:
\begin{enumerate}
	\setlength{\parskip}{1pt}
	\item Vorbereitung des Benchmarks (GDBMS initialisieren)
	\item Warmup-Prozedur ausführen (außer beim Importieren)
	\item Für $n$ Wiederholungen
		\begin{enumerate}
			\item Vorbereitung der Messung (Auswahl der Startknoten, Anfrage parametrisieren)
			\item Beginn der Zeitmessung
			\item Ausführen der Operation und ggf. vollständiges Auslesen der Ergebnismenge
			\item Ende der Zeitmessung		
		\end{enumerate}
	\item Nachbereitung des Benchmarks (Ressourcen freigeben)
	\item Speichern der Messergebnisse sowie GDBMS- und Benchmark-Konfiguration
\end{enumerate}

% Random Seed
Damit keines der Systeme benachteiligt wird, erfolgt für den Pseudozufallsgenerator die Festlegung eines \texttt{seed}-Wertes, was dazu führt, dass für alle Anfragen in jedem GDBMS die gleichen Knoten ausgewählt werden und die Benchmarks reproduzierbar sind. Die Übereinstimmung der Ergebnismengen wurde für jede Anfrage validiert.

Für den Erhalt statistisch signifikanter Ergebnisse wird die Anzahl der Wiederholungen generell auf $n=1000$ festgelegt, die \texttt{import}-Operation hingegen wird einmalig ausgeführt. Die Zeitmessung bedient sich der statischen Methode \texttt{System.nanoTime()}. Da sowohl die \texttt{ExecutionEngine} als auch die \texttt{GremlinGroovyScriptEngine} einen Cache für die jeweils generierten Ausführungspläne besitzen, ist die erste Anfrage typischerweise deutlich langsamer als alle nachfolgenden Anfragen, daher wird der Messwert der ersten Iteration nicht berücksichtigt. Alle Anfragen werden sequentiell ausgeführt, es findet kein konkurrierender Zugriff auf die Datenbasis statt. Für die Messung \texttt{import} sind die Messgrößen Importdauer und Speicherverbrauch der Datenbank inklusive aller Indexstrukturen auf dem Hintergrundspeicher, für alle anderen Operationen wird die Ausführungszeit gemessen. Die erhaltenen Messwerte werden gespeichert und mittels LibreOffice Calc und R weiterverarbeitet.

\section{Ergebnisse}

Im nachfolgenden Abschnitt werden die Ergebnisse der einzelnen Messungen vorgestellt und diskutiert. Hierfür werden entweder der Durchschnittswert in einem Säulendiagramm oder alle Werte in einem Boxplot visualisiert. Das Säulendiagramm wird für Anfragen verwendet, in denen die Ergebnismengen eine konstante oder zumindest annähernd konstante Größe aufweisen, was auf \texttt{import}, \texttt{random\_read} und \texttt{top\_regions} zutrifft. Für die Veranschaulichung der übrigen Messergebnisse wurde die Boxplot-Darstellung gewählt, da sich die Ergebnismengen je nach Grad zu berücksichtigender Knoten zum Teil stark unterscheiden und die Messwerte keiner Normalverteilung unterliegen. Ein Durchschnittswert spiegelt in diesem Fall das Antwortzeitverhalten der einzelnen Systeme nicht exakt wider und ermöglicht keine Beurteilung des generellen Leistungsverhaltens.

\paragraph*{\texttt{import}} Die Abbildungen \ref{fig:import_time} und \ref{fig:import_space} veranschaulichen die Ergebnisse des Datenimports. Es wird deutlich, dass Neo4j für beide Messgrößen annähernd lineares Verhalten in Abhängigkeit zur Datenmenge zeigt. In Titan trifft dies für den Speicherverbrauch zu, die Importdauer hingegen skaliert mit zunehmender Datenmenge schlechter. Wahrscheinlich besteht ein Zusammenhang mit der Anzahl verwalteter Key-Value-Datenbanken: Eine KV-Datenbank speichert Topologie und Nutzdaten, zwei KV-Datenbanken verwalten den Knoten- bzw. Kantenindex. Es ist festzuhalten, dass Neo4j grundsätzlich weniger Zeit für den Bulk-Import beansprucht und eine kompaktere physische Repräsentation des Graphen aufweist. 

\begin{figure}[htb]
	\centering	
	\subfigure[Importdauer]{\label{fig:import_time}\includegraphics[scale=.5]{import_time.pdf}}\qquad	
	\subfigure[Speicherverbrauch]{\label{fig:import_space}\includegraphics[scale=.5]{import_space.pdf}}	
	\caption[Benchmark: \texttt{import}]{Ergebnisse der \texttt{import}-Messung. Titan (auto) bezeichnet die automatische Typisierung von Attributschlüsseln und Kantenbezeichner, während Titan(manual) die manuelle Typisierung repräsentiert.}
\end{figure}

\paragraph*{\texttt{random\_read}} Diese Anfrage greift unter Verwendung der systemseitigen Identitäten auf Knoteninstanzen zu und liest deren Attribute vollständig aus, Abbildung \ref{fig:random_read} zeigt hierfür die logarithmisch skalierte durchschnittliche Antwortzeit beider GDBMS. % inklusive der Standardabweichung innerhalb der Messreihe. 
Auffällig ist der deutliche Zeitunterschied zwischen der Verwendung von Cypher und Gremlin: Cypher ist um einen Faktor von ca. 20 bis 30 langsamer als eine gleichwertige Gremlin-Anfrage, was mit den Beobachtungen in \cite{Gehrels:2013} und \cite{Holzschuher:2013:PGQ:2457317.2457351} konform geht.  %Weiter lässt sich für Cypher-Anfragen eine deutlich höhere Standardabweichung der Messergebnisse feststellen. 
Anzumerken ist, dass Neo4j in Verbindung mit Gremlin generell leicht kürzere Antwortzeiten erreicht als Titan, dabei muss berücksichtigt werden, dass die in Titan indexierte Datenmenge nicht nur Knoten, sondern auch Kanten und Attribute umfasst.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{random_read.pdf}
	\caption[Benchmark: \texttt{random\_read}]{Durchschnittliche Antwortzeit der \texttt{random\_read}-Messung.}
	\label{fig:random_read}
\end{figure}

Eine manuelle Typisierung führt in Titan beim vollständigen Auslesen der Attribute zu keiner messbaren Leistungssteigerung, es fällt jedoch auf, dass die Antwortzeiten bei steigendem Datenvolumen annähernd konstant bleiben, während sie bei Neo4j 2.0 leicht ansteigen. Dies ist insofern interessant, als dass beim Warmup lediglich auf das \texttt{\_\_type\_\_}-Attribut zugegriffen wurde und somit in Titan alle Attribute beim Zugriff aus BerkeleyDB geladen werden müssen. In Neo4j werden einfache Properties satzweise geladen und sollten sich daher beim Benchmark im Object-Cache befinden. Dies spricht für die Leistungsfähigkeit von BerkeleyDB.

\paragraph*{\texttt{sim\_products}} Die Anfrage ermittelt alle Knoten mit Abstand zwei zu einem ausgewählten Startknoten und bezieht folglich die Struktur des Graphen ein, die Menge zu berücksichtigender Kantenbezeichner wird eingeschränkt. Da die Anzahl ähnlicher Produkte je nach ausgewähltem Produkt verschieden sein kann, wurde sich in Abbildung \ref{fig:sim_products} für das Boxplot-Diagramm entschieden, die Antwortzeit ist dabei logarithmisch skaliert.

Analog zu \texttt{random\_read} zeigt sich für Neo4j auch in dieser Messung ein deutlicher Zeitunterschied zwischen der Ausführung mit Cypher und Gremlin, wobei letztere um einen Faktor von ca. 20 schneller ist. Für beide Systeme bleiben die Antwortzeiten bei steigendem Datenvolumen konstant, allein bei Neo4j 2.0 lassen sich ein geringer Anstieg und eine Verschiebung der statistischen Ausreißer feststellen. Das auffällige Antwortzeitverhalten von Cypher-Anfragen in \texttt{p\_100} könnte mit der geringen Produktanzahl (126) zusammenhängen. Einzelne Produkte werden mehrfach abgefragt, vermutlich wird dabei von Caching-Mechanismen des Betriebssystems und der CPU profitiert.\\
Die Anfrage erfordert eine Auflistung der Produkttitel und somit direkten Zugriff auf das entsprechende Knotenattribut. Ein manuelles Festlegen der Datentypen in Titan erzielte dabei keine deutliche Verbesserung. Generell liefert auch in dieser Anfrage Neo4j in Verbindung mit Gremlin die beste Performance.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{sim_products.pdf}
	\caption[Benchmark: \texttt{sim\_products}]{Ergebnisse der \texttt{sim\_products}-Messung.}
	\label{fig:sim_products}
\end{figure}

\paragraph*{\texttt{foaf\_reviews}} Diese Anfrage beinhaltet neben einer lokalen Traversierung des Graphen eine Gruppierung nach Knotenattributen sowie das Berechnen von Aggregaten anhand eines Kantenattributs. Die Ergebnismenge wird sortiert ausgegeben. Abbildung \ref{fig:foaf_reviews} zeigt die Messergebnisse als Boxplot, auch hier wird die Antwortzeit logarithmisch skaliert.

Erneut lässt sich ein deutlicher Unterschied zwischen den Antwortzeiten von Cypher- und Gremlin-Anfragen in Neo4j feststellen, Cypher-Anfragen sind um einen Faktor von ca. 80 langsamer. Bei alleiniger Betrachtung der Systeme wird deutlich, dass die Antwortzeiten unabhängig von der Datenmenge konstant sind. Insbesondere die Antwortzeiten der cypher-basierten Ausführung variieren im Vergleich zu den Gremlin-Anfragen in Neo4j und Titan nur wenig, was auf eine effizientere Anfrageausführung schließen lässt. Auch hier weist Neo4j in Verbindung mit Gremlin das im Vergleich beste Leistungsverhalten auf. 

\begin{figure}[!htbp] 
	\centering
		\includegraphics[scale=.55]{foaf_reviews.pdf}
	\caption[Benchmark: \texttt{foaf\_reviews}]{Ergebnisse der \texttt{foaf\_reviews}-Messung.}
	\label{fig:foaf_reviews}
\end{figure}

Anders als in den bisher betrachteten Anfragen wird in dieser auf Kantenattribute zugegriffen. Dabei führt die Verwendung von typisierten Attributschlüsseln in allen Testgraphen zu niedrigeren Antwortzeiten als eine automatische Vergabe, die Differenz ist jedoch sehr gering. Deutlicher hingegen sind die in beiden Systemen höheren Antwortzeiten bei steigendem Datenvolumen, dabei fallen insbesondere die Ausreißer von ca. 10s im größten Datensatz auf. Eine genauere Betrachtung der Daten ergab, dass eine Ergebnismenge durchschnittlich 37 Produkttitel enthält. Die Ergebnismenge, die diesen Ausreißer verursachte, umfasst hingegen 3\,599 Einträge. Dabei fällt auf, dass Neo4j mit Cypher für diesen Wert ein besseres Ergebnis erzielt, als die ebenfalls in Neo4j ausgeführte Gremlin-Anfrage. Die Ursache wird entweder in der Implementierung der Anfrageausführung von Gremlin oder einer suboptimalen Formulierung der Anfrage vermutet.

\paragraph*{\texttt{path\_all}} Die Anfrage berechnet alle existierenden Pfadinstanzen zwischen zwei Knoten, die maximale Pfadlänge ist begrenzt und die Menge zu besuchender Knoten wird durch die Definition zulässiger Kantenbezeichner eingeschränkt. Wie in Abschnitt \ref{sec:operations} im Zusammenhang mit der Traversierung erläutert, bedarf die Pfadsuche eine Betrachtung aller Knoten, welche sich im definierten maximalen Abstand zum Startknoten befinden und erfordert gleichzeitig das Zwischenspeichern besuchter Knoten und berechneter Pfadinstanzen. Je nach Knotengrad kann folglich schon bei geringer Pfadlänge ein großer Teil des Graphen traversiert werden. Während der Ausführung wurde bei einigen Messreihen festgestellt, dass der zur Verfügung stehende Hauptspeicher für die Berechnung nicht ausreicht und der Swap-Bereich des Betriebssystems beansprucht wurde. Die daraus resultierenden Ergebnisse sind für eine allgemeingültige Bewertung folglich nicht verwendbar und es musste auf die Messreihe Neo4j 2.0 im Datensatz \texttt{p\_1K} sowie auf alle Messreihen im Datensatz \texttt{p\_10K} verzichtet werden. Abbildung \ref{fig:path_all} zeigt die Ergebnisse für die durchgeführten Messungen.

\begin{figure}[!htbp] 
	\centering
		\includegraphics[scale=.55]{path_all.pdf}
	\caption[Benchmark: \texttt{path\_all}]{Ergebnisse der \texttt{path\_all}-Messung.}
	\label{fig:path_all}
\end{figure}

Das Prüfen der Erreichbarkeit in beiden GDBMS in Verbindung mit der verwendeten Hardware liefert ausschließlich auf dem kleinsten Datensatz akzeptable Werte. Eine Verdopplung der Datenmenge führt zu deutlich mehr Ausreißern mit einem Maximalwert von 777 Sekunden für Titan (auto). Neo4j erreicht unter Verwendung von Gremlin die besten Ergebnisse und ist im kleinsten Datensatz um etwa den Faktor 10 schneller als die Ausführung mit Cypher. Knoten- und Kantenattribute wurden in dieser Anfrage nicht berücksichtigt, eine Auswirkung der manuellen Typisierung von Kantenbezeichnern in Titan konnte nicht festgestellt werden.

\paragraph*{\texttt{path\_shortest}} Die Anfrage berechnet den kürzesten Pfad zwischen zwei Knoten unter Berücksichtigung definierter Kantenbezeichner und einer gleichzeitigen Beschränkung der maximalen Pfadlänge. Auch hier musste aufgrund begrenzter Hardware-Ressourcen auf die Ausführung der Gremlin-Anfragen in den Testgraphen \texttt{p\_1K} und \texttt{p\_10K} verzichtet werden. Abbildung \ref{fig:path_shortest} stellt die Ergebnisse logarithmisch skaliert in einem Boxplot dar.

\begin{figure}[!htbp] 
	\centering
		\includegraphics[scale=.55]{path_shortest.pdf}
	\caption[Benchmark: \texttt{path\_shortest}]{Ergebnisse der \texttt{path\_shortest}-Messung. In den Datensätzen \texttt{p\_1K} und \texttt{p\_10K} wird ausschließlich Neo4j 2.0 berücksichtigt.}
	\label{fig:path_shortest}
\end{figure}

Bei der Formulierung der Cypher-Anfrage wurde die sprachinhärente \texttt{shortestPath}-Funktion verwendet. Wie aus der Abbildung hervorgeht, erzielt deren Implementierung im Vergleich die niedrigsten Antwortzeiten, die sich auch bei steigendem Datenvolumen nur geringfügig verschlechtern. Die manuelle Umsetzung der Anfrage in Gremlin führt hingegen in beiden GDBMS zu deutlich höheren Ausführungszeiten und resultiert bereits im kleinsten Datensatz in Ausreißern von bis zu 150 Sekunden.

\paragraph*{\texttt{top\_regions}} Die Anfrage berücksichtigt sowohl die Topologie des Graphen als auch eine Einschränkung der Nutzdaten, die Ergebnisse werden gruppiert und aggregiert sowie anschließend sortiert und limitiert. Für die Darstellung der Messergebnisse wurde das Säulendiagramm gewählt; für jede Messreihe werden Durchschnittswert und Standardabweichung der Messwerte visualisiert (Abbildung \ref{fig:top_regions}).

\begin{figure}[!htbp]
	\centering
		\includegraphics[scale=.5]{top_regions.pdf}
	\caption[Benchmark: \texttt{top\_regions}]{Durchschnittliche Antwortzeit und Standardabweichung der \texttt{top\_regions}-Messung.}
	\label{fig:top_regions}
\end{figure}


In der Messung erreicht Neo4j die besten Ergebnisse, in Verbindung mit Cypher sind die Antwortzeiten sogar kürzer als bei Verwendung von Gremlin. Dies lässt auf eine effizientere Anfrageausführung in Verbindung mit Aggregation und Sortierung schließen. Es lässt sich feststellen, dass die Antwortzeiten in Neo4j linear mit der Datenmenge skalieren. Die Anzahl zu berücksichtigender Produkte entspricht 1\,852 (\texttt{p\_100}), 12\,831 (\texttt{p\_1K}) und 242\,354 (\texttt{p\_10K}). Am Beispiel von \texttt{p\_1K} und \texttt{p\_10K} entspricht dies einem Faktor von ca. 18, die durchschnittliche Antwortzeit der Anfrage in Neo4j 2.0 steigt von 60 auf 1\,110 Millisekunden (Faktor 18) und in Neo4j 1.9.4 von 80 auf 1\,370 Millisekunden (Faktor 18).\\
Gleiches gilt für Titan, hier sind die Antwortzeiten jedoch generell länger, was in diesem Fall auf das GDBMS zurückzuführen ist, da eine identische Gremlin-Anfrage in Neo4j kürzere Antwortzeiten erzielt. Die Anfrage berücksichtigt Attribute sowohl für die Einschränkung der Produktmenge als auch für die Gruppierung der Ergebnisse. Eine manuelle Typdefinition in Titan führte hierbei nicht zu messbaren Leistungsunterschieden.

%p\_100 1852
%p\_1K	12831 (*7)
%p\_10K 	242354 (*18)
%
%60 -> 1110 (18)
%80 -> 1370 (18)
%
%68 -> 470 (*7)
%68 -> 463 (*7)

\paragraph*{\texttt{sim\_pattern}} Die letzte Anfrage repräsentiert eine komplexe Mustersuche innerhalb des Graphen bei der eine Überlappung der Nachbarschaft einzelner Knoten berechnet werden muss. Wie Anhang \ref{anh:queries} zu entnehmen ist, sind die Anfragen in beiden Sprachen im Vergleich zu den bisherigen Anfragen deutlich umfangreicher. Da sich die Ergebnismengen je nach ausgewähltem Startknoten unterscheiden können, wurde zur Darstellung der Resultate wurde auch hier die Boxplot-Visualisierung gewählt (Abbildung \ref{fig:sim_pattern}).

\begin{figure}[!htbp] 
	\centering
		\includegraphics[scale=.55]{sim_pattern.pdf}
	\caption[Benchmark: \texttt{sim\_pattern}]{Ergebnisse der \texttt{sim\_pattern}-Messung.}
	\label{fig:sim_pattern}
\end{figure}

Es wird deutlich, dass die Antwortzeiten mit steigender Datenmenge in beiden GDBMS konstant bleiben. Die Antwortzeiten unter Verwendung von Cypher sind hierbei um einen Faktor von ca. $10^3$ langsamer als die Ausführung mittels Gremlin. Bei der Messung im größten Datensatz treten in beiden Systemen Ausreißer auf, was folglich auf die Anfrageverarbeitung von Gremlin bzw. auf eine suboptimale Anfrageformulierung zurückzuführen ist. Ein Leistungsunterschied bei der Verwendung manuell typisierter Attributschlüssel und Kantenbezeichner konnte nicht festgestellt werden. Insgesamt betrachtet ist dies die einzige Anfrage, bei der Titan minimal besser abschneidet als Neo4j.

\paragraph*{Gesamtergebnis}

Beide GDBMS erzielen Antwortzeiten, die sie für das Forschungsprojekt geeignet erscheinen lassen. Für fast alle Anfragen erreicht Neo4j in Verbindung mit Gremlin die besten Ergebnisse, der Vorsprung zu Titan ist dabei jedoch oft nur minimal. Hervorzuheben ist die lineare Skalierbarkeit beider Systeme bei steigendem Datenvolumen, wobei sich Neo4j für größere Datenmengen besser zu eignen scheint, da die Messwerte bei Anfragen auf dem größten Datensatz näher zusammenliegen und Extremwerte in den Messungen im Vergleich seltener auftreten und generell niedriger sind. Bei Titan ist dies auf die Verwendung von BerkeleyDB als Speichersystem zurückzuführen, die Ergebnisse können folglich für andere Speichersysteme abweichen.\\
Das Prüfen der Erreichbarkeit ist in beiden Systemen grundsätzlich möglich, erfordert aber je nach Datenumfang entsprechende Hardware-Ressourcen. Generell sollte die Nutzung systemseitiger Funktionen, wie z.B. \texttt{shortestPath}, einer eigenen Implementierung vorgezogen werden, da sich hierdurch - wie auch gezeigt wurde - deutlich geringere Antwortzeiten erreichen lassen. Die Suche nach dem kürzesten Pfad ist die Grundlage für komplexere, analytische Graphalgorithmen, Cypher weist durch die Integration der Funktion einen wesentlichen Vorteil gegenüber Gremlin auf.

Neben der Suche nach dem kürzesten Pfad erzielte Cypher jedoch nur noch bei der Ausführung von \texttt{top\_region} bessere Ergebnisse als Gremlin, allgemein betrachtet ist die gremlin-basierte Ausführung insgesamt deutlich performanter, die Messwerte unterscheiden sich dabei um einen Faktor von ca. 20 bis $10^3$. Das im Vergleich schlechtere Antwortzeitverhalten von Cypher gegenüber Gremlin wurde bereits in den verwandten Arbeiten thematisiert und ist noch immer aktuell. Laut Neo Technology sind nach der Veröffentlichung von Version 2.0 umfangreiche Optimierungen für Cypher geplant.\footnote{Dies ergab eine Rückfrage im November 2013 per Email an Philip Rathle, dem Senior Director of Products von Neo Technology (siehe Anhang \ref{anh:mail_neo}).}\\
Titan erreicht im Vergleich ebenfalls akzeptable Werte, erzielte aber insbesondere bei topologischen Anfragen auf dem größten Datensatz schlechtere Ergebnisse als Neo4j und dies mit teilweise deutlichen Ausreißern. Der Grund dafür lässt sich nicht eindeutig feststellen, als mögliche Ursachen kommen in Frage: suboptimale Anfrageformulierung, Anfrageausführung in Gremlin, Anfrageausführung in Titan oder BerkeleyDB. Eine manuelle Typisierung von Attributschlüsseln und Kantenbezeichnern führte in nur einer Anfrage zu messbaren Verbesserungen, diese waren jedoch minimal. Die Vermutung liegt nahe, dass sich die manuelle Typisierung bei Verwendung eines KCV-Speichersystems eher auswirkt, da hier alle Attribute und Kanteninformationen innerhalb eines Datensatzes und nicht voneinander getrennt gespeichert sind, wie es bei der Verwendung von BerkeleyDB der Fall ist.

Neben der reinen Leistungsfähigkeit bei der Ausführung analytischer Anfragen sollte auch die Anfrageformulierung in Cypher und Gremlin bewertet werden. Alle Anfragen konnten in beiden Sprachen umgesetzt und dabei eine annähernd identische Struktur der Ergebnismenge erreicht werden, unter ausschließlicher Berücksichtigung der formulierten Anfragen sind die Sprachen somit gleich mächtig. Subjektiv betrachtet lässt sich feststellen, dass das Formulieren graphenspezifischer Anfragen in einer deklarativen Sprache wie Cypher im Vergleich zu einer imperativen Sprache wie Gremlin einfacher ist. Durch die Kombination aus graphenspezifischer Musterdefinition und SQL-ähnlichen Filterkriterien lassen sich in Cypher sowohl einfache Traversierungen als auch komplexere Mustersuchen, Aggregationen und Transformationen realisieren. Gremlin eignet sich ebenfalls sehr gut für die Beschreibung abstrakter Wege, erfordert hingegen bei komplexeren Anfragen zusätzliche Datenstrukturen zur Zwischenspeicherung und bedarf der Formulierung mehrerer Anweisungen in einem Gremlin-Skript, um identische Informationen abfragen zu können. Die Lesbarkeit der Anfragen und deren Wartbarkeit bei eingebetteter Verwendung  wird hierdurch stark eingeschränkt. Für Programmierer eigenen sich beide Sprachen zur Analyse von Graphen, Analysten hingegen mit SQL- aber wenig Programmiererfahrung werden vermutlich Cypher bevorzugen. Zu beachten ist auch, dass das Formulieren von Anfragen in Gremlin ein hohes Maß an manueller Optimierung erfordert, während eine deklarative Sprache wie Cypher es dem Datenbanksystem überlässt, wie die Anfrage letztendlich ausgeführt wird und somit Raum für Anfrageoptimierung bietet.

In diesem Kapitel wurde eine technische Analyse von Neo4j und Titan durchgeführt. Nach der Vorstellung der Testumgebung, der verwendeten Datensätze und der beispielhaften analytischen Anfragen wurde näher auf die Methodik bei der Durchführung des Benchmarks eingegangen. Anschließend wurden die Ergebnisse der Einzelmessungen veranschaulicht und ausgewertet. Der letzte Abschnitt fasste die Ergebnisse aus allen Messungen zusammen, dabei wurden sowohl die Leistungsfähigkeit der GDBMS als auch die Anfrageformulierung in Cypher und Gremlin bewertet.\\
Im letzten Kapitel wird das Fazit der Arbeit gezogen, dazu werden die Ergebnisse der funktionalen Evaluation in Verbindung mit den Ergebnissen des Benchmarks ausgewertet und ein Ausblick auf die weitere Bearbeitung der Thematik rundet die Arbeit ab.