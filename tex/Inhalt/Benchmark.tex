\chapter{Benchmark von Graphdatenbanksystemen}
\label{cha:benchmark}

Dieses Kapitel dient der Bewertung von Neo4j und Titan hinsichtlich ihrer Leistungsfähigkeit bei der Ausführung verschiedener graphenspezifischer Operationen. Dabei ist es von besonderem Interesse, ob sich die im vorhergehenden Kapitel aufgeführten funktionalen Unterschiede auf die Performance auswirken. Zusätzlich soll beurteilt werden, inwieweit sich Cypher und Gremlin zur Formulierung analytischer Anfragen eignen. Zunächst werden Testgraphen, Operationen und das Testsystem vorgestellt. Es wird weiterhin auf die Konfiguration der einzelnen GDBMS sowie auf die Methodik bei der Durchführung der Messungen eingegangen. Im zweiten Teil des Kapitels werden die Ergebnisse vorgestellt und bewertet.

\section{Testumgebung}

Bei der Analyse verwandter Arbeiten wurde festgestellt, dass aktuell - Stand Oktober 2013 - kein standardisierter Benchmark für GDBMS existiert. Daher wurde sich bei der Vorbereitung und Durchführung an den Empfehlungen von Dominguez-Sal et al.\cite{Dominguez-Sal2011} orientiert, da diese u.a. auch in den verwandten Arbeiten von Ciglan et al.\cite{Ciglan:2012} und Gehrels\cite{Gehrels:2013} berücksichtigt werden.

\subsection{Datengrundlage}

Bei der Vorbereitung des Benchmarks wurde sich dafür entschieden, reale Datensätze als Datengrundlage zu verwenden. Das in Abschnitt \ref{sec:anforderungen} beschriebene Forschungsvorhaben sieht vor, Informationsnetzwerke aus unterschiedlichen Geschäftsinformationssystemen zu integrieren und den daraus resultierenden Graphen zu analysieren. Die Netzwerke in den Quellsystemen können dabei verschiedene topologische Eigenschaften aufweisen und die in ihnen gespeicherten Informationen unterschiedlichen Klassen zugeordnet sein. Ein ERP-System verwaltet zum Beispiel Rechnungen, während ein CRM-System vorrangig Kundenaktivitäten speichert. Durch die unterschiedlichen Wechselwirkungen zwischen den Entitäten innerhalb der einzelnen Quellsysteme entstehen verschiedenartige Beziehungsstrukturen. Der integrierte Graph ist folglich hinsichtlich Topologie und Nutzdaten heterogen.\\
Die in den verwandten Arbeiten eingesetzten Algorithmen zur Erzeugung von Zufallsgraphen bilden ausschließlich homogene Netzwerke ab, in denen alle Knoten einer Klasse zugeordnet sind. In \cite{Vicknair:2010:CGD:1900008.1900067} sind es zum Beispiel Schritte innerhalb eines Herstellungsprozesses, in \cite{Ciglan:2012}, \cite{Dominguez-Sal:2010:SGD:1927585.1927590} und \cite{Gehrels:2013} wird generell auf eine Klassifizierung der Informationen verzichtet. Das Erzeugen synthetischer, heterogener Graphen hingegen ist sehr aufwändig, da jeder Klasse und jeder Beziehungsart eine eigene Logik hinsichtlich ihrer Erzeugung zugeordnet werden muss.

Da reale Daten aus Geschäftsinformationssystemen nicht frei zur Verfügung stehen, werden stellvertretend für heterogene Netzwerke \texttt{amazon-meta}\cite{snap_amazon:2013} und \texttt{sec-Pokec}\cite{snap_pokec:2013} verwendet, beides Datensätze des Stanford Network Analysis Project\footnote{\url{https://snap.stanford.edu/}}. \texttt{amazon-meta} beinhaltet Produktinformationen des Onlinehändlers Amazon\footnote{\url{http://www.amazon.com}}, dazu zählen u.a. Produktbewertungen und Beziehungen zwischen Produkten\footnote{Es handelt sich dabei um ähnliche Produkte, die laut Amazon oft zusammen gekauft werden.}. Pokec\footnote{\url{http://pokec.azet.sk/}} hingegen ist ein slowakisches, soziales Online-Netzwerk in dem Nutzer durch gerichtete Freundschaftsbeziehungen miteinander verbunden sind. Abbildung \ref{fig:testdata} zeigt das integrierte Schema beider Netzwerke als Property-Graph.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.75]{schema.pdf}
	\caption[Benchmark: Schema Testdaten]{Integriertes Schema aus Amazon- und Pokec-Daten.}
	\label{fig:testdata}
\end{figure}

Beide Datensätze verfügen über eine Klasse \texttt{User}. Deren Instanzen werden innerhalb von \texttt{amazon-meta} durch eine eindeutige Identität repräsentiert und besitzen keine Beziehungen zueinander. In \texttt{soc-Pokec} hingegen weisen die Instanzen eine Vielzahl von Attributen auf und sind durch gerichtete \texttt{FRIEND\_OF}-Beziehungen miteinander verbunden. Die Anzahl der Nutzer stimmt in beiden Datensätzen annähernd überein, \texttt{amazon-meta} weist ca. 1.5 Mio., \texttt{soc-Pokec} etwa 1.6 Mio. Nutzer auf. Im Rahmen der Vorverarbeitung wurden zunächst Pokec-Nutzer pseudozufällig auf Amazon-Nutzer abgebildet, anschließend wurde der durch die ausgewählten Knoten induzierte Teilgraph aus \texttt{soc-Pokec} extrahiert und mit \texttt{amazon-meta} zu einem integrierten Graph zusammengeführt.\\
Die Netzwerke enthalten neben den topologischen Informationen auch Nutzdaten, diese wurden für Gruppen, Produkte und Bewertungen vollständig aus den Rohdaten übernommen, für die Nutzer hingegen wurde eine Auswahl von Attributen unterschiedlichen Datentyps getroffen. Die Rohdaten beider Netzwerke wurden für die weitere Verwendung in das von Neo4j entwickelte textbasierte Geoff-Format\footnote{\url{http://nigelsmall.com/geoff}} überführt.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|l|rl|rl|rl|rl|rl|rl|rl|rl|rl|}
	\hline
   	 & \multicolumn{8}{c|}{\textbf{Knoten}} & \multicolumn{2}{c|}{\textbf{Attribute}} \\ \cline{2-11}
   	\textbf{Graph} & \multicolumn{2}{c|}{\texttt{Group}} & \multicolumn{2}{c|}{\texttt{Product}} & \multicolumn{2}{c|}{\texttt{User}} & \multicolumn{2}{c|}{$\Sigma$} & \multicolumn{2}{c|}{$\Sigma$} \\
   	\hline
   	   	\hline
   	\texttt{orig} & \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{542\,684} & \multicolumn{2}{c|}{1\,555\,124} & \multicolumn{2}{c|}{2\,097\,819} & \multicolumn{2}{c|}{20\,377\,902} \\
   	\hline
   	\hline
	\texttt{p\_100} & 1 & (1) & 126 & (1) & 347\,752 & (1) & 347\,879 & (1) & 1\,874\,907 & (1)\\
	\hline
	\texttt{p\_1K} & 4 & (4) & 1\,089 & (8.64) & 665\,116 & (1.91) & 666\,209 & (1.92) & 3\,710\,473 & (1.98) \\
	\hline
	\texttt{p\_10K} & 4 & (1) & 10\,047 & (9.23) & 976\,985 & (1.47) & 987\,036 & (1.47) & 7\,255\,153 & (1.96) \\
   	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Anzahl Knoten und Attribute]{Anzahl Instanzen der verschiedenen Knotenklassen und Gesamtanzahl der Knoten- und Kantenattribute.}
		\label{tab:datasets_nodes}
\end{table}
\renewcommand{\arraystretch}{1}

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|l|rl|rl|rl|rl|rl|}
	\hline
	& \multicolumn{10}{c|}{\textbf{Kanten}} \\ \cline{2-11}

   	\textbf{Graph} & \multicolumn{2}{c|}{\texttt{BELONGS\_TO}} & \multicolumn{2}{c|}{\texttt{SIMILAR\_TO}} & \multicolumn{2}{c|}{\texttt{REVIEWED\_BY}} & \multicolumn{2}{c|}{\texttt{FRIEND\_OF}} & \multicolumn{2}{c|}{$\Sigma$} \\
   	\hline
   	\hline
   	\texttt{orig} & \multicolumn{2}{c|}{542\,684} & \multicolumn{2}{c|}{1\,231\,400} & \multicolumn{2}{c|}{7\,593\,109} & \multicolumn{2}{c|}{27\,787\,537} & \multicolumn{2}{c|}{37\,154\,730} \\
	\hline
	\hline
	\texttt{p\_100} & 126 & (1) & 396 & (1) & 1\,909 & (1) & 704\,092 & (1) & 706\,523 & (1) \\
	\hline
	\texttt{p\_1K} & 1\,089 & (8.64) & 3\,365 & (8.5) & 29\,848 & (15.64) & 1\,830\,064 & (2.6) & 1\,864\,366 & (2.64) \\
	\hline
	\texttt{p\_10K} & 10\,048 & (9.23) & 27\,976 & (8.31) & 401\,917 & (13.47) & 3\,576\,276 & (1.95) & 4\,016\,216 & (2.15) \\
	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Anzahl Kanten]{Anzahl Instanzen der verschiedenen Kantenbezeichner.}
	\label{tab:datasets_edges}
\end{table}
\renewcommand{\arraystretch}{1}

Ein wichtiges Kriterium bei der Durchführung eines Benchmarks ist das Leistungsverhalten einer Anfrage bei steigendem Datenvolumen. Synthetische Datensätze lassen sich entsprechend erzeugen, reale Datensätze hingegen besitzen eine festgelegte Größe. Mit dem Ziel, die Skalierbarkeit von Anfragen dennoch untersuchen zu können, wurden zusammenhängende Teilgraphen aus dem integrierten Datensatz extrahiert. Die Teilgraphen sind bezüglich der Knoten aus \texttt{amazon-meta} induziert, dies gilt nicht für den Teilgraph, der ausschließlich aus Nutzerknoten besteht. Der Algorithmus wird in Anhang \ref{anh:extraction} beschrieben.


Dominguez-Sal et al. empfehlen die Angabe eines einzelnen Skalierungsfaktors, von welchem die Anzahl der erzeugten Knoten und Kanten abhängig ist, dies lässt sich jedoch bei der Verwendung realer Datensätze nicht umsetzen. Durch die Parameterwahl des Extraktionsalgorithmus wurde daher versucht, möglichst konstante Wachstumsfaktoren zu erreichen. Die Tabellen \ref{tab:datasets_nodes} und \ref{tab:datasets_edges} stellen den integrierten Graph (\texttt{orig}) und die extrahierten Teilgraphen hinsichtlich der Anzahl Knoten und Kanten gruppiert nach ihrer jeweiligen Klasse gegenüber. Zusätzlich wird für jeden Wert der Wachstumsfaktor in Bezug auf den Wert im nächstkleineren Graphen angeben. Ein Nachteil des gewählten Ansatzes ist, dass sich die topologischen Eigenschaften zwischen den verschiedenen, extrahierten Teilgraphen unterscheiden können, dies wird bei der nachfolgenden Bewertung berücksichtigt.

\subsection{Operationen}

Stellvertretend für Anfragen, die für die Analyse von Unternehmensdaten im Forschungsvorhaben relevant sind, wurden auf Grundlage des vorgestellten Schemas mehrere Anfragen definiert. Diese beinhalten jeweils einzelne oder mehrere der in Abschnitt \ref{subsec:graph_operations} vorgestellten graphenspezifischen Operationen. Es handelt sich um lokale Anfragen, die ausgehend von einem Knoten oder einer Knotenmenge einen Teil des Graphen analysieren. Dabei werden sowohl Topologie als auch Nutzdaten in die Operationen einbezogen. Auf rein topologische und globale Anfragen, wie zum Beispiel das Berechnen der k-Nachbarschaft ohne Berücksichtigung von Kantenbezeichnern oder das Auslesen aller Kanten, wurde bewusst verzichtet, da sie für das Forschungsvorhaben nicht relevant sind. Gleiches gilt auch für Schreibzugriffe, hier ist lediglich die Performance der Bulk-Load-Mechanismen von Interesse. 

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.3cm}|>{\arraybackslash}m{13.45cm}|}
	\hline
   	\multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{c|}{\textbf{Beschreibung (Kategorisierung der Operationen)}} \\
	\hline
	\hline
	\textbf{\texttt{import}} & Importieren der Testgraphen in das jeweilige GDBMS unter Verwendung von Bulk-Load-Mechanismen. (Schreibperformance beim Bulk-Load)\\
	\hline
	\textbf{\texttt{random\_read}} & Zufällige Auswahl einzelner Produkte und Nutzer sowie vollständiges Auslesen ihrer Attribute. (Leseperformance beim Attributzugriff) \\
	\hline
	\textbf{\texttt{sim\_products}} & Zufällige Auswahl eines Produktes und anschließendes Traversieren  ähnlicher Produkte bis Abstand $\leq$ 2, die Kantenrichtung ist nicht relevant. Die Produkttitel sollen ausgegeben werden, jeder Titel soll einmalig in der Ergebnismenge sein. (Lokale Traversierung, Einschränkung) \\
	\hline
	\textbf{\texttt{foaf\_reviews}} & Zufällige Auswahl eines Nutzers und anschließende Selektion der Produkte, für die Freunde oder deren Freunde ein Review geschrieben haben. Das Ergebnis soll nach Produkttitel gruppiert und nach durchschnittlicher Bewertung sortiert werden. (Lokale Traversierung, Einschränkung, Gruppierung, Aggregation)\\
	\hline
	\textbf{\texttt{path\_all}} & Zufällige Auswahl eines Nutzers und eines Produktes und anschließendes Berechnen aller Pfade der Länge $\leq 4$ zwischen beiden Knoten. Dabei sollen nur die Kantenbezeichner \texttt{FRIEND\_OF}, \texttt{REVIEWED\_BY} und \texttt{SIMILAR\_TO} berücksichtigt werden, die Kantenrichtung ist nicht relevant. Im Ergebnis sollen die Pfade gruppiert nach Länge und der jeweiligen Anzahl ausgegeben werden. (Erreichbarkeit, Einschränkung, Gruppierung, Aggregation) \\
	\hline
	\textbf{\texttt{path\_shortest}} & Zufällige Auswahl zweier Nutzer und anschließende Berechnung des kürzesten Pfades zwischen ihnen unter Berücksichtigung der Kantenbezeichner \texttt{FRIEND\_OF}, \texttt{REVIEWED\_BY} und \texttt{SIMILAR\_TO}. Die maximale Pfadlänge beträgt 4, Kantenrichtungen werden nicht berücksichtigt. Das Ergebnis soll das Attribut \texttt{\_\_id\_\_} der Knoten innerhalb des Pfades beinhalten. (Erreichbarkeit, Einschränkung) \\
	\hline
	\textbf{\texttt{top\_regions}} & Auswahl aller Produkte, welche der Gruppe \texttt{'Books'} angehören und das Prädikat \texttt{salesrank} $\leq$ 500\,000 erfüllen. Das Ergebnis soll nach dem Attribut \texttt{region} jener Nutzer gruppiert werden, welche die Produkte mit einem \texttt{rating} $\geq$ 3 bewertet haben und dies für $\geq$ 5 Nutzer hilfreich war. Darüber hinaus soll das Ergebnis nach der Anzahl der Produkte pro Region sortiert und die oberen 10 Regionen ausgegeben werden. (Lokale Traversierung, Aggregation, Gruppierung, Selektion) \\
	\hline
	\textbf{\texttt{sim\_pattern}} & Zufällige Auswahl eines Nutzers und anschließendes Bestimmen seiner Freunde, die für mindestens ein übereinstimmendes Produkt Reviews geschrieben haben. Das Ergebnis soll den Nutzer selbst, die Freunde des Nutzers und die übereinstimmende Produktmenge beinhalten. (Lokale exakte Mustersuche) \\
	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Beschreibung der einzelnen Anfragen]{Namen und Beschreibungen der durchzuführenden Anfragen.}
	\label{tab:benchmark_queries}
\end{table}
\renewcommand{\arraystretch}{1}

In Tabelle \ref{tab:benchmark_queries} werden die Anfragen beschrieben und entsprechend der verwendeten Operationen kategorisiert. Alle Anfragen wurden mittels Cypher und Gremlin realisiert und sind in Anhang \ref{anh:queries} aufgeführt. Eine Implementierung unter Verwendung der vorhandenen Java APIs wurde nicht durchgeführt, da zum Einen die Verwendung aktueller graphenspezifischer Anfragesprachen für die Formulierung komplexerer analytischer Anfragen in dieser Arbeit vordergründig ist und zum Anderen bereits in \cite{Ciglan:2012}, \cite{Gehrels:2013} und \cite{Holzschuher:2013:PGQ:2457317.2457351} gezeigt wurde, dass sich der Verzicht auf eine zusätzliche Anfrageverarbeitung positiv auf das Leistungsverhalten auswirkt. Eine Eignung der APIs für die Implementierung beliebiger analytischer Algorithmen und Operationen wurde den Systemen bereits im vorhergehenden Kapitel zugesprochen.

\subsection{Systemkonfiguration}

Die verwendete Testumgebung setzt sich wie folgt zusammen:

\begin{itemize}
	\setlength{\parskip}{1pt}
	\item Intel i7-2620M (2x3.4 Ghz)
	\item 8 GB DDR-3 RAM (1333 Mhz)
	\item Crucial M4 SSD (128 GB)
	\item Xubuntu 13.10 64-Bit (Kernel 3.11.0-12-generic, ext4)
	\item Java(TM) SE Runtime Environment (build 1.7.0\_45-b18)
\end{itemize}

\paragraph*{Neo4j}

Das GDBMS wird in einer zentralen, eingebetteten Konfiguration verwendet, Anfragen werden sowohl in Cypher als auch in Gremlin ausgeführt. Für Cypher-Anfragen wird die im vorhergehenden Kapitel betrachtete Version 2.0.0-M04 eingesetzt. Die Berücksichtigung von Gremlin ermöglicht eine bessere Vergleichbarkeit mit Titan, macht es jedoch erforderlich, für die Durchführung auf Version 1.9.4 des GDBMS zurückzugreifen, da Blueprints 2.4.0 und somit auch Gremlin bisher nicht kompatibel zu den Neuerungen in Neo4j 2.0 sind.  Die Ausführung von Cypher erfolgt unter Verwendung der \texttt{ExecutionEngine}\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/tutorials-cypher-java.html}}, für Gremlin wird die in der Dokumentation beschriebene \texttt{GremlinGroovyScriptEngine} \footnote{\url{https://github.com/tinkerpop/gremlin/wiki/Using-Gremlin-through-Java\#using-jsr-223-gremlingroovyscriptengine}} genutzt.

Für den Bulk-Load der Testgraphen wird im \texttt{import}-Benchmark der von Neo4j zur Verfügung gestellte \texttt{BatchInserter} entsprechend der Dokumentation\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/batchinsert.html}} eingesetzt. Während des Import erfolgt das Aktualisieren eines zusätzlichen Lucene-Index auf dem Knotenattribut \texttt{\_\_id\_\_}. Bei der Verwendung von Neo4j 2.0.0-M04 werden darüber hinaus Knotenbezeichner entsprechend der Knotenklasse gesetzt, diese können folglich nur in Cypher-Anfragen berücksichtigt werden.

Die Kernel-Einstellungen\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/kernel-configuration.html}} des GDBMS werden unverändert übernommen. Die Größe des Heap-Speichers der JVM wird entsprechend den Empfehlungen\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/configuration-jvm.html}} auf 4 GB festgelegt, eine Änderung des Stack-Speichers erfolgt nicht. Darüber hinaus wird der Concurrent Mark and Sweep Compactor Garbage Collector\footnote{\url{http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html\#BehavioralOptions}} verwendet.\\
Die Einstellungen des Object-Cache bleiben unverändert, es wird demnach die in Abschnitt \ref{subsec:neo4j_persistency} beschriebene Standard-Implementierung genutzt. Der Filesystem-Cache wurde entsprechend der Größe der Stores angepasst. Um deren Speicherbedarf zu ermitteln, wurde der größte Testgraph (\texttt{p\_10K}) importiert und die Größe der Stores im Dateisystem bestimmt. Für den Knoten-Store sind dies 20 MB, für den Kanten-Store 150 MB.\footnote{Dieser Wert lässt sich ebenfalls aus der Datensatzgröße von 14 bzw. 33 Byte und der Anzahl Knoten bzw. Kanten in Tabelle \ref{tab:datasets_nodes} bzw. \ref{tab:datasets_edges} berechnen.} Interessant ist, dass trotz der Verwendung von String- und Array-Properties der Property-Store für primitive Datentypen den größten Speicherbedarf aufweist.\footnote{Für primitive Datentypen werden 150 MB, für Strings 50 MB und für Arrays 10 MB beansprucht.} Neo4j verwendet für Strings und Arrays zusätzliche Kompressionsmethoden\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/short-strings.html} und \url{http://docs.neo4j.org/chunked/2.0.0-M04/short-arrays.html}} und fügt, wenn möglich, die entsprechenden Werte in den Property-Store für primitive Datentypen ein und vermeidet damit eine zusätzliche Indirektion beim Lese- und Schreibzugriff. Die Anpassung des Filesystem-Cache ermöglicht es dem GDBMS die komplette Datenbasis im Hauptspeicher vorhalten zu können.

\paragraph*{Titan}

Das GDBMS wird ebenfalls in einer zentralen, eingebetteten Konfiguration verwendet. Anfragen werden ausschließlich in Gremlin ausgeführt, dies erfolgt wie bei Neo4j unter Verwendung der \texttt{GremlinGroovyScriptEngine}. Das verwendete Speichersystem ist BerkeleyDB Java Edition, die Konfiguration erfolgt ausschließlich mit den von Titan zur Verfügung gestellten Parametern.

Für den Import der Testgraphen wird der im TinkerPop-Projekt verfügbare \texttt{BatchGraph} verwendet, eine Wrapper-Klasse, die Bulk-Load-Funktionalität für blueprints-kompatible GDBMS zur Verfügung stellt.\footnote{\url{https://github.com/tinkerpop/blueprints/wiki/Batch-Implementation}} Die Verwendung von \texttt{BatchGraph} wird von Aurelius für Graphen mit bis zu 100 Mio. Kanten empfohlen. Darüber hinaus wurde der Konfigurationsparameter \texttt{storage.batch-loading} auf \texttt{true} gesetzt, was die internen Konsistenzmechanismen von Titan deaktiviert und den Import beschleunigen soll.\\
Vor dem Datenimport werden Instanzen von \texttt{TitanKey} bzw. \texttt{TitanLabel} erzeugt. Für Instanzen von \texttt{TitanKey} werden Attributschlüssel, Datentyp des Attributwertes und Eindeutigkeit an der Instanz festgelegt, dem Knotenattribut \texttt{\_\_id\_\_} wird wie bei Neo4j ein Index zugeordnet. Die Instanzen von \texttt{TitanLabel} werden entsprechend den vier Beziehungsarten bezeichnet, \texttt{BELONGS\_TO}-Kanten werden darüber hinaus als $n:1$-Beziehung zwischen Produkt und Gruppe deklariert. Die Durchführung erfolgt sowohl mit manueller als auch mit systemseitiger Typdefinition, damit soll untersucht werden, inwieweit sich die Festlegung der Datentypen auf die Leistungsfähigkeit des GDBMS auswirkt.

Entsprechend der Empfehlung von Aurelius werden BerkeleyDB 80\% des zur Verfügung stehenden Heap-Speichers zur Verfügung gestellt.\footnote{\url{https://github.com/thinkaurelius/titan/wiki/Using-BerkeleyDB}} Dieser wird wie bei Neo4j auf insgesamt 4 GB festgelegt. Oracle empfiehlt für BerkeleyDB ebenfalls die Verwendung des Concurrent Mark and Sweep Compactor Garbage Collector, welcher folglich bei der Durchführung aktiviert ist.\footnote{\url{http://www.oracle.com/technetwork/database/berkeleydb/je-faq-096044.html\#WhatJVMparametersshouldIconsiderwhentuninganapplicationwithalargecachesize}}

\subsection{Methodik}

% Verweis auf Framework
Für die Durchführung der Messungen wurde ein Java-Framework\footnote{\url{https://github.com/s1ck/master_thesis/tree/master/benchmark}} entwickelt, mit dem sich individuell konfigurierbare Benchmarks nach einem definierten Protokoll ausführen lassen. Jede der zu messenden Anfragen kann einzeln aktiviert und konfiguriert werden. Dabei lässt sich die Ausführungsreihenfolge beliebig variieren, bei der Durchführung wird die Reihenfolge entsprechend Tabelle \ref{tab:benchmark_queries} beibehalten.

% Import
Die Testgraphen liegen im Geoff-Format vor und werden unter Verwendung eines Iterators eingelesen. Dieser Ansatz ermöglicht es, auch umfangreiche Datensätze ohne zusätzliche Inanspruchnahme des Hauptspeichers zu verarbeiten und gleichzeitig die unmittelbare Schreibperformance des GDBMS in Abhängigkeit vom Externspeicher zu messen.

% Warmup Caches
Für die Simulation eines realistischen Antwortzeitverhaltens empfehlen Dominguez-Sal et al. ein sog. \textit{warmup} der Caches. Eine Zielstellung des Forschungsvorhabens ist die Verwendung des GDBMS im Rahmen einer Analyseplattform. Dabei wird angenommen, dass diese nicht nur bei Bedarf gestartet wird, sondern permanent in Betrieb ist. Folglich ist davon auszugehen, dass sich entweder der gesamte Graph oder Teilgraphen zum Zeitpunkt der Anfrage in den Caches befinden und somit eine effizientere Ausführung möglich ist.\\ % Darüber hinaus verdeutlichen aktuelle Entwicklungen, wie zum Beispiel SAP HANA\cite{plattner2011memory}, dass die Verwendung mehrerer hundert Gigabyte Hauptspeicher in aktuellen Server-Systemen kosteneffizient ist und auf lange Sicht die Bedeutung der im Vergleich langsamen Externspeichern sinken lässt.\\
Mit dem Ziel, eine vergleichbare Situation zu schaffen, wurde vor der Ausführung einer Messung eine Iteration sowohl über die gesamte Knotenmenge als auch über die gesamte Kantenmenge durchgeführt.\footnote{In Titan erfolgt in der warmup-Prozedur nach 20\,000 gelesenen Objekten ein Commit um potentielle Speicherprobleme durch den Transaktionscache zu verhindern.} Zusätzlich wurde das Knotenattribut \texttt{\_\_type\_\_} ausgelesen und die jeweilige Identität nach Typ gruppiert gespeichert, diese Informationen werden für die pseudozufällige Auswahl der Startknoten einer Anfrage genutzt.

% Zeitmessung
Ein Benchmark zu jeder Anfrage wird nach folgendem Protokoll durchgeführt:
\begin{enumerate}
	\setlength{\parskip}{1pt}
	\item Vorbereitung des Benchmarks (GDBMS initialisieren)
	\item Warmup-Prozedur ausführen (außer beim Importieren)
	\item Für $n$ Wiederholungen
		\begin{enumerate}
			\item Vorbereitung der Messung (Auswahl der Startknoten, Anfrage parametrisieren)
			\item Beginn der Zeitmessung
			\item Ausführen der Operation und ggf. vollständiges Auslesen der Ergebnismenge
			\item Ende der Zeitmessung		
		\end{enumerate}
	\item Nachbereitung des Benchmarks (Ressourcen freigeben)
	\item Speichern der Messergebnisse sowie GDBMS- und Benchmark-Konfiguration
\end{enumerate}

% Random Seed
Mit dem Ziel, eine Benachteiligung eines GDBMS zu vermeiden, wird für den Pseudozufallsgenerator ein \texttt{seed}-Wert festgelegt. Dies führt dazu, dass für alle Anfragen in jedem GDBMS die gleichen Knoten ausgewählt werden und darüber hinaus die Benchmarks reproduzierbar sind. Die Übereinstimmung der Ergebnismengen wurde für jede Anfrage validiert.

Für den Erhalt signifikanter Ergebnisse wird die Anzahl der Wiederholungen generell auf $n=1000$ festgelegt, die \texttt{import}-Operation hingegen wird einmalig ausgeführt. Die Zeitmessung erfolgt unter Verwendung der statischen Methode \texttt{System.nanoTime()}. Da sowohl die \texttt{ExecutionEngine} als auch die \texttt{GremlinGroovyScriptEngine} einen Cache für die jeweils generierten Ausführungspläne besitzen, ist die erste Anfrage typischerweise deutlich langsamer als alle nachfolgenden Anfragen, infolgedessen wird der Messwert der ersten Iterationen nicht berücksichtigt. Alle Anfragen werden sequentiell ausgeführt, es findet kein konkurrierender Zugriff auf die Datenbasis statt. Die Messgrößen sind für \texttt{import} die Importdauer und der Speicherverbrauch der Datenbank inklusive aller Indexstrukturen auf dem Hintergrundspeicher, für alle anderen Operationen wird die Ausführungszeit gemessen. Die erhaltenen Messwerte werden gespeichert und mittels R und LibreOffice Calc weiterverarbeitet.

\section{Ergebnisse}

Im nachfolgenden Abschnitt werden die Ergebnisse der einzelnen Messungen vorgestellt und diskutiert. Dabei wird entweder der Durchschnittswert der Messergebnisse in einem Säulendiagramm oder alle Werte in einem Boxplot visualisiert. Das Säulendiagramm wird für Anfragen verwendet, in denen die Ergebnismenge konstant oder annähernd konstant ist, dies trifft auf \texttt{import}, \texttt{random\_read} und \texttt{top\_regions} zu. Für die Visualisierung der übrigen Anfragen wurde sich für die Boxplot-Darstellung entschieden, da die Ergebnisse je nach Grad der betroffenen Knoten verschieden sein können und die Berechnung eines durchschnittlichen Wertes wenig Aussagekraft über das Antwortzeitverhalten der einzelnen Systeme liefern würde.

\paragraph*{\texttt{import}} Die Abbildungen \ref{fig:import_time} und \ref{fig:import_space} zeigen die Ergebnisse des Datenimport. Es wird deutlich, dass Neo4j hinsichtlich der Messgrößen annähernd lineares Verhalten in Abhängigkeit zur Datenmenge aufweist. Gleiches gilt auch für den Speicherverbrauch der Datenbasis in Titan, hier skaliert hingegen die Importdauer mit zunehmender Datenmenge schlechter. Es wird vermutet, dass dies mit der Anzahl Key-Value-Datenbanken in Zusammenhang steht, welche von Titan beansprucht werden: Eine KV-Datenbank speichert Topologie und Nutzdaten, zwei KV-Datenbanken verwalten den Knoten- bzw. Kantenindex und der manuell definierte Index erfordert eine weitere KV-Datenbank in BerkeleyDB. Aus der Messung geht somit hervor, dass Neo4j weniger Zeit für den Bulk-Import benötigt und generell eine kompaktere physische Repräsentation des Graphen besitzt. 

\begin{figure}[htb]
	\centering	
	\subfigure[Importdauer]{\label{fig:import_time}\includegraphics[scale=.5]{import_time.pdf}}\qquad	
	\subfigure[Speicherverbrauch]{\label{fig:import_space}\includegraphics[scale=.5]{import_space.pdf}}	
	\caption[Benchmark: \texttt{import}]{Ergebnisse der \texttt{import}-Messung.}
\end{figure}

\paragraph*{\texttt{random\_read}} Diese Anfrage greift unter Verwendung der systemseitigen Identitäten auf Knoteninstanzen zu und liest ihre Attribute vollständig aus, Abbildung \ref{fig:random_read} zeigt die durchschnittliche Antwortzeit der einzelnen Systeme inklusive der Standardabweichung innerhalb der Messreihe. Zunächst fällt der deutliche Leistungsunterschied zwischen der Verwendung von Cypher und Gremlin auf: Cypher ist um einen Faktor von ca. 20 bis 30 langsamer als eine gleichwertige Gremlin-Anfrage, dies deckt sich mit den Beobachtungen in \cite{Holzschuher:2013:PGQ:2457317.2457351}. Auffällig ist auch die wesentlich höhere Standardabweichung der Messergebnisse unter Verwendung von Cypher. Anzumerken ist, dass Neo4j bei der Verwendung mit Gremlin generell leicht bessere Messerergebnisse erzielt als Titan. Dabei ist jedoch zu berücksichtigen, dass die indexierte Datenmenge im Fall von Titan deutlich größer ist.

Hinsichtlich Titan lässt sich feststellen, dass eine manuelle Typisierung beim vollständigen Auslesen der Attribute nicht zu einer Leistungssteigerung führt. Auffällig ist jedoch, dass die Antwortzeit in Titan bei steigendem Datenvolumen annähernd konstant bleibt, während sie bei Neo4j leicht ansteigt. Dies ist insofern interessant, als das beim Warmup lediglich auf das \texttt{\_\_type\_\_}-Attribut zugegriffen wurde und somit in Titan alle Attribute beim Zugriff aus BerkeleyDB geladen werden müssen. In Neo4j werden einfache Properties zusammen mit dem Knoten geladen und sollten sich somit beim Benchmark im Object-Cache befinden.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{random_read.pdf}
	\caption[Benchmark: \texttt{random\_read}]{Ergebnisse der \texttt{random\_read}-Messung.}
	\label{fig:random_read}
\end{figure}

\paragraph*{\texttt{sim\_products}} Durch die Berechnung einer 2-Nachbarschaft ausgewählter Knoten bezieht diese Anfrage die Struktur des Graphen in die Berechnung ein. Da sich die Knotengrade deutlich unterscheiden können, wurde für diese Messung die Boxplot-Darstellung gewählt, die Ergebnisse sind in Abbildung \ref{fig:sim_products} dargestellt.

Auch hier zeigt sich ein ähnliches Leistungsverhalten wie in der vorherigen Anfrage. Erneut ist ein wesentlicher Leistungsunterschied zwischen Cypher und Gremlin zu erkennen, die Antwortzeiten liegen jedoch in einem für das Forschungsprojekt akzeptablen Bereich. Hervorzuheben ist das Antwortzeitverhalten bei steigendem Datenvolumen. Für beide GDBMS sind die Antwortzeiten annähernd konstant. Der sprunghafte Anstieg von Cypher lässt sich mit der geringen Produktmenge im Testgraph \texttt{p\_100} begründen, einzelne Produkte werden mehrfach abgefragt und dabei vermutlich von Caching-Mechanismen profitiert.

Die Anfrage erfordert eine Auflistung der Produkttitel und folglich den direkten Zugriff auf das Knotenattribut. Eine Typisierung von Titan erzielt dabei keinen messbaren Vorteil. Generell erreicht auch in dieser Anfrage Neo4j in Verbindung mit Gremlin die beste Performance.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{sim_products.pdf}
	\caption[Benchmark: \texttt{sim\_products}]{Ergebnisse der \texttt{sim\_products}-Messung.}
	\label{fig:sim_products}
\end{figure}

\paragraph*{\texttt{foaf\_reviews}} Diese Anfrage beinhaltet eine lokale Traversierung des Graphen, die Gruppierung nach Knotenattributen und das Berechnen von Aggregaten anhand von Kantenattributen, die Ergebnismenge wird sortiert. Abbildung \ref{fig:foaf_reviews} zeigt die Messergebnisse als Boxplot, Ausreißer sind ebenfalls abgebildet, da sie, anders als in der vorherigen Anfrage, eine genauere Beurteilung des Leistungsverhaltens ermöglichen. Zu beachten ist die logarithmische Skalierung der Antwortzeit.

Die Ausführungszeiten von Neo4j sind mit Cypher und Gremlin unabhängig von der Datenmenge konstant niedrig und insbesondere die Ausführung mittels Cypher variiert im Vergleich zu den Gremlin-Anfragen in Neo4j und Titan nur wenig. In Verbindung mit Gremlin weist auch hier Neo4j das beste Leistungsverhalten auf. 

Im Gegensatz zu den bisherigen Anfragen wird auf Kantenattribute zugegriffen. Bei dieser Anfrageart scheint die Verwendung von typisierten Attributen in Titan vorteilhaft zu sein. Dennoch zeigt sich bei steigendem Datenvolumen eine leichte Verschlechterung der Antwortzeit, auffallend sind dabei die Ausreißer von ca. 10s im größten Datensatz. Eine genauere Betrachtung hat ergeben, dass die durchschnittliche Ergebnismenge ca. 37 Produkttitel und zugehörige durchschnittliche Bewertungen enthält. Die Ergebnismenge, welche zu diesem Ausreißer führte, umfasst 3599 Einträge. Auffällig ist dabei, dass Neo4j mit Cypher für diesen Wert ein besseres Ergebnis erzielt als die ebenfalls in Neo4j ausgeführte Gremlin-Anfrage. Die Ursache wird somit in der Implementierung von Gremlin bzw. in einer nicht-optimalen Formulierung der Anfrage vermutet.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{foaf_reviews.pdf}
	\caption[Benchmark: \texttt{foaf\_reviews}]{Ergebnisse der \texttt{foaf\_reviews}-Messung.}
	\label{fig:foaf_reviews}
\end{figure}

\paragraph*{\texttt{path\_all}} Diese Anfrage berechnet alle existierenden Pfade zwischen zwei definierten Knoten, die Menge der zu besuchenden Knoten wird durch die Definition erlaubter Kantenbezeichner eingeschränkt. Die Pfadsuche bedarf der Betrachtung aller Knoten, welche sich im definierten maximalen Abstand zum Startknoten befinden und erfordert darüber hinaus das Zwischenspeichern bereits besuchter Knoten. Während der Ausführung wurde für einige Messreihen festgestellt, dass der Swap-Bereich des Betriebssystems genutzt wurde und die resultierenden Ergebnisse für eine allgemeingültige Bewertung folglich nicht verwendbar sind. Durch die begrenzten Hardware-Ressourcen musste für den Datensatz \texttt{p\_1K} auf die Messreihe Neo4j (Cypher) sowie auf alle Messreihen im größten Datensatz verzichtet werden, Abbildung \ref{fig:path_all} zeigt die Ergebnisse für die durchgeführten Messungen.

Es wird deutlich, dass diese Anfrage für beide GDBMS in Verbindung mit der verwendeten Hardware nur auf dem kleinsten Datensatz akzeptable Werte liefert. Eine Verdopplung der Datenmenge führt zu deutlich mehr Ausreißern mit einem Maximalwert von 777 Sekunden (Titan (untyped)). Neo4j erreicht unter Verwendung von Gremlin die besten Ergebnisse und ist im kleinsten Datensatz etwa um Faktor 10 schneller als die Ausführung mit Cypher. Eine Berücksichtigung von Attributen fand nicht statt, eine Auswirkung der Typisierung in Titan konnte folglich nicht festgestellt werden.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{path_all.pdf}
	\caption[Benchmark: \texttt{path\_all}]{Ergebnisse der \texttt{path\_all}-Messung.}
	\label{fig:path_all}
\end{figure}

\paragraph*{\texttt{path\_shortest}} Die Anfrage berechnet den kürzesten Pfad zwischen zwei Knoten unter Berücksichtigung definierter Kantenbezeichner. Auch hier musste auf Grund begrenzter Hardware-Ressourcen auf die Ausführung der Gremlin-Anfragen in den Testgraphen \texttt{p\_1K} und \texttt{p\_10K} verzichtet werden. Abbildung \ref{fig:path_shortest} fasst die Ergebnisse in einem Boxplot zusammen.

Bei der Formulierung der Cypher-Anfrage wurde auf die angebotene \texttt{shortestPath}-Funktion zurückgegriffen. Wie aus der Abbildung hervorgeht, erzielt deren Implementierung selbst bei steigendem Datenvolumen niedrige, konstante Ausführungszeiten. Die manuelle Umsetzung der Anfrage in Gremlin führt hingegen in beiden GDBMS zu deutlich höheren Ausführungszeiten und resultiert bereits im kleinsten Datensatz in Ausreißern von bis zu 150 Sekunden.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{path_shortest.pdf}
	\caption[Benchmark: \texttt{path\_shortest}]{Ergebnisse der \texttt{path\_shortest}-Messung.}
	\label{fig:path_shortest}
\end{figure}

\paragraph*{\texttt{top\_regions}} Die Anfrage berücksichtigt sowohl die Topologie des Graphen als auch eine Einschränkung der Nutzdaten. Die Ergebnismenge wird gruppiert, aggregiert, sortiert und limitiert. Für die Darstellung der Messergebnisse wurde das Säulendiagramm gewählt, welches jeweils den Durchschnittswert und die Standardabweichung der Einzelmessungen einer Messreihe darstellt (Abbildung \ref{fig:top_regions}).

Neo4j erzielt in Verbindung mit Cypher die besten Ergebnisse. Bezüglich der Skalierbarkeit lässt sich feststellen, dass die Antwortzeiten in Neo4j linear mit der Datenmenge skalieren. Die Anzahl zu berücksichtigender Produkte entspricht 1\,852 (\texttt{p\_100}), 12\,831 (\texttt{p\_1K}) und 242\,354 (\texttt{p\_10K}). Am Beispiel von \texttt{p\_1K} und \texttt{p\_10K} entspricht dies einem Faktor von ca. 18. Die durchschnittliche Ausführungszeit der Anfrage in Neo4j (Cypher) steigt von 60 auf 1\,110 Millisekunden (Faktor 18) und in Neo4j (Gremlin) von 80 auf 1\,370 Millisekunden (Faktor 18).\\
Gleiches gilt auch für Titan, hier sind die Antwortzeiten jedoch generell deutlich höher, was jedoch in diesem Fall auf das GDBMS zurückzuführen ist, da die gleiche Anfrage in Neo4j deutlich niedrigere Antwortzeiten erzielt.

%p\_100 	1852
%p\_1K	12831 (*7)
%p\_10K 	242354 (*18)
%
%60 -> 1110 (18)
%80 -> 1370 (18)
%
%68 -> 470 (*7)
%68 -> 463 (*7)

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{top_regions.pdf}
	\caption[Benchmark: \texttt{top\_regions}]{Ergebnisse der \texttt{top\_regions}-Messung.}
	\label{fig:top_regions}
\end{figure}

\paragraph*{\texttt{sim\_pattern}} Die letzte Anfrage stellt eine komplexe Mustersuche innerhalb des Graphen dar. Wie Anhang \ref{anh:queries} zu entnehmen ist, sind sowohl Cypher- als auch Gremlin-Anfrage deutlich komplexer als in den vorhergehenden Anfragen. Da sich die Ergebnismengen verschiedener Knoten stark unterscheiden können, wurde auch hier die Boxplot-Darstellung gewählt (Abbildung \ref{fig:sim_pattern}).

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{sim_pattern.pdf}
	\caption[Benchmark: \texttt{sim\_pattern}]{Ergebnisse der \texttt{sim\_pattern}-Messung.}
	\label{fig:sim_pattern}
\end{figure}

\paragraph*{Gesamtergebnis}

- Anfrageformulierung in Cypher ist intuitiver und einfacher als in Gremlin
- Cypher generell langsamer
- Potenzial für Anfrageoptimierung




