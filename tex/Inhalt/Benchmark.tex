\chapter{Benchmark von Graphdatenbanksystemen}
\label{cha:benchmark}

Dieses Kapitel dient der Bewertung von Neo4j und Titan hinsichtlich ihrer Leistungsfähigkeit bei der Ausführung verschiedener graphenspezifischer Operationen. Dabei ist es von besonderem Interesse, ob sich die im vorhergehenden Kapitel aufgeführten funktionalen Unterschiede auf die Performance auswirken. Zusätzlich soll beurteilt werden, inwieweit sich Cypher und Gremlin zur Formulierung analytischer Anfragen eignen. Zunächst werden Testgraphen, Operationen und das Testsystem vorgestellt. Es wird weiterhin auf die Konfiguration der einzelnen GDBMS sowie auf die Methodik bei der Durchführung der Messungen eingegangen. Im zweiten Teil des Kapitels werden die Ergebnisse vorgestellt und bewertet.

\section{Testumgebung}

Bei der Analyse verwandter Arbeiten wurde festgestellt, dass aktuell - Stand Oktober 2013 - kein standardisierter Benchmark für GDBMS existiert. Daher wurde sich bei der Vorbereitung und Durchführung an den Empfehlungen von Dominguez-Sal et al.\cite{Dominguez-Sal2011} orientiert, da diese u.a. auch in den verwandten Arbeiten von Ciglan et al.\cite{Ciglan:2012} und Gehrels\cite{Gehrels:2013} berücksichtigt werden.

\subsection{Datengrundlage}

Bei der Vorbereitung des Benchmarks wurde sich dafür entschieden, reale Datensätze als Datengrundlage zu verwenden. Das in Abschnitt \ref{sec:anforderungen} beschriebene Forschungsvorhaben sieht vor, Informationsnetzwerke aus unterschiedlichen Geschäftsinformationssystemen zu integrieren und den daraus resultierenden Graphen anschließend zu analysieren. Die Netzwerke in den Quellsystemen können dabei verschiedene topologische Eigenschaften aufweisen und die in ihnen gespeicherten Informationen unterschiedlichen Klassen zugeordnet sein. Ein ERP-System verwaltet zum Beispiel Rechnungen, während ein CRM-System vorrangig Kundenaktivitäten speichert. Durch die unterschiedlichen Wechselwirkungen zwischen den Entitäten innerhalb der einzelnen Quellsysteme entstehen verschiedenartige Beziehungsstrukturen. Der integrierte Graph ist folglich hinsichtlich Topologie und Nutzdaten heterogen.\\
Die in den verwandten Arbeiten eingesetzten Algorithmen zur Erzeugung von Zufallsgraphen bilden ausschließlich homogene Netzwerke ab, in denen alle Knoten einer Klasse zugeordnet sind. In \cite{Holzschuher:2013:PGQ:2457317.2457351} sind es zum Beispiel Nutzer innerhalb eines sozialen Netzwerkes, in \cite{Ciglan:2012} und \cite{Gehrels:2013} wird generell auf eine Klassifizierung der Informationen verzichtet. Das Erzeugen synthetischer, heterogener Graphen hingegen ist sehr aufwändig, da jeder Klasse und jeder Beziehungsart eine eigene Logik hinsichtlich ihrer Erzeugung zugeordnet werden muss.

Da reale Daten aus Geschäftsinformationssystemen nicht frei zur Verfügung stehen, werden stellvertretend für heterogene Netzwerke \texttt{amazon-meta}\cite{snap_amazon:2013} und \texttt{sec-Pokec}\cite{snap_pokec:2013} verwendet, beides Datensätze des Stanford Network Analysis Project\footnote{\url{https://snap.stanford.edu/}}. \texttt{amazon-meta} beinhaltet Produktinformationen des Onlinehändlers Amazon\footnote{\url{http://www.amazon.com}}, dazu zählen u.a. deren Bewertungen und Beziehungen zu anderen Produkten\footnote{Es handelt sich dabei um ähnliche Produkte, die laut Amazon oft zusammen gekauft werden.}. Pokec\footnote{\url{http://pokec.azet.sk/}} ist ein slowakisches, soziales Online-Netzwerk. Abbildung \ref{fig:testdata} zeigt das integrierte Schema beider Netzwerke als Property-Graph.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.75]{schema.pdf}
	\caption[Benchmark: Schema Testdaten]{Integriertes Schema aus Amazon- und Pokec-Daten.}
	\label{fig:testdata}
\end{figure}

Beide Datensätze verfügen über eine Klasse \texttt{User}. Deren Instanzen werden innerhalb von \texttt{amazon-meta} durch eine eindeutige Identität repräsentiert und besitzen keine Beziehungen zueinander. In \texttt{soc-Pokec} hingegen weisen die Instanzen eine Vielzahl von Attributen auf und sind durch gerichtete \texttt{FRIEND\_OF}-Beziehungen miteinander verbunden. Die Anzahl der Nutzer stimmt in beiden Datensätzen annähernd überein, \texttt{amazon-meta} weist ca. 1.5 Mio., \texttt{soc-Pokec} etwa 1.6 Mio. Nutzer auf. Im Rahmen der Vorverarbeitung wurden zunächst Pokec-Nutzer zufallsbasiert auf Amazon-Nutzer abgebildet, anschließend wurde der durch die ausgewählten Knoten induzierte Teilgraph aus \texttt{soc-Pokec} extrahiert und mit \texttt{amazon-meta} zu einem integrierten Graph zusammengeführt.\\
Die Netzwerke enthalten neben den topologischen Informationen auch Nutzdaten, diese wurden für Gruppen, Produkte und Bewertungen vollständig aus den Rohdaten übernommen, für die Nutzer hingegen wurde eine Auswahl von Attributen unterschiedlichen Datentyps getroffen. Die Rohdaten beider Netzwerke wurden für die weitere Verwendung in das von Neo4j entwickelte textbasierte Geoff-Format\footnote{\url{http://nigelsmall.com/geoff}} überführt.

Ein wichtiges Kriterium bei der Durchführung eines Benchmarks ist das Leistungsverhalten einer Anfrage bei steigendem Datenvolumen. Synthetische Datensätze lassen sich entsprechend erzeugen, reale Datensätze hingegen besitzen eine festgelegte Größe. Mit dem Ziel, die Skalierbarkeit von Anfragen dennoch untersuchen zu können, wurden zusammenhängende Teilgraphen aus dem integrierten Datensatz extrahiert. Die Teilgraphen sind bezüglich der Knoten aus \texttt{amazon-meta} induziert, dies gilt nicht für den Teilgraph bestehend aus Nutzerknoten. Der Algorithmus wird in Anhang \ref{anh:extraction} beschrieben.\\
Dominguez-Sal et al. empfehlen die Angabe eines einzelnen Skalierungsfaktors, von welchem die Anzahl der erzeugten Knoten und Kanten abhängig ist, dies lässt sich jedoch bei der Verwendung realer Datensätze nicht umsetzen. Durch die Parameterwahl des Extraktionsalgorithmus wurde daher versucht, möglichst konstante Wachstumsfaktoren zu erreichen. Die Tabellen \ref{tab:datasets_nodes} und \ref{tab:datasets_edges} stellen den integrierten Graph (\texttt{orig}) und die extrahierten Teilgraphen hinsichtlich der Anzahl Knoten und Kanten gruppiert nach ihrer jeweiligen Klasse gegenüber. Zusätzlich wird für jeden Wert der Wachstumsfaktor in Bezug auf den Wert im nächstkleineren Graphen angeben. Ein Nachteil des gewählten Ansatzes ist, dass sich die topologischen Eigenschaften zwischen den verschiedenen, extrahierten Teilgraphen unterscheiden können, dies wird bei der nachfolgenden Bewertung berücksichtigt.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|l|rl|rl|rl|rl|rl|rl|rl|rl|rl|}
	\hline
   	 & \multicolumn{8}{c|}{\textbf{Knoten}} & \multicolumn{2}{c|}{\textbf{Attribute}} \\ \cline{2-11}
   	\textbf{Graph} & \multicolumn{2}{c|}{\texttt{Group}} & \multicolumn{2}{c|}{\texttt{Product}} & \multicolumn{2}{c|}{\texttt{User}} & \multicolumn{2}{c|}{$\Sigma$} & \multicolumn{2}{c|}{$\Sigma$} \\
   	\hline
   	   	\hline
   	\texttt{orig} & \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{542\,684} & \multicolumn{2}{c|}{1\,555\,124} & \multicolumn{2}{c|}{2\,097\,819} & \multicolumn{2}{c|}{20\,377\,902} \\
   	\hline
   	\hline
	\texttt{p\_100} & 1 & (1) & 126 & (1) & 347\,752 & (1) & 347\,879 & (1) & 1\,874\,907 & (1)\\
	\hline
	\texttt{p\_1K} & 4 & (4) & 1\,089 & (8.64) & 665\,116 & (1.91) & 666\,209 & (1.92) & 3\,710\,473 & (1.98) \\
	\hline
	\texttt{p\_10K} & 4 & (1) & 10\,047 & (9.23) & 976\,985 & (1.47) & 987\,036 & (1.47) & 7\,255\,153 & (1.96) \\
   	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Anzahl Knoten und Attribute]{Anzahl Instanzen der verschiedenen Knotenklassen und Gesamtanzahl der Knoten- und Kantenattribute.}
	
	\label{tab:datasets_nodes}
\end{table}
\renewcommand{\arraystretch}{1}

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|l|rl|rl|rl|rl|rl|}
	\hline
	& \multicolumn{10}{c|}{\textbf{Kanten}} \\ \cline{2-11}

   	\textbf{Graph} & \multicolumn{2}{c|}{\texttt{BELONGS\_TO}} & \multicolumn{2}{c|}{\texttt{SIMILAR\_TO}} & \multicolumn{2}{c|}{\texttt{REVIEWED\_BY}} & \multicolumn{2}{c|}{\texttt{FRIEND\_OF}} & \multicolumn{2}{c|}{$\Sigma$} \\
   	\hline
   	\hline
   	\texttt{orig} & \multicolumn{2}{c|}{542\,684} & \multicolumn{2}{c|}{1\,231\,400} & \multicolumn{2}{c|}{7\,593\,109} & \multicolumn{2}{c|}{27\,787\,537} & \multicolumn{2}{c|}{37\,154\,730} \\
	\hline
	\hline
	\texttt{p\_100} & 126 & (1) & 396 & (1) & 1\,909 & (1) & 704\,092 & (1) & 706\,523 & (1) \\
	\hline
	\texttt{p\_1K} & 1\,089 & (8.64) & 3\,365 & (8.5) & 29\,848 & (15.64) & 1\,830\,064 & (2.6) & 1\,864\,366 & (2.64) \\
	\hline
	\texttt{p\_10K} & 10\,048 & (9.23) & 27\,976 & (8.31) & 401\,917 & (13.47) & 3\,576\,276 & (1.95) & 4\,016\,216 & (2.15) \\
	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Anzahl Kanten]{Anzahl Instanzen der verschiedenen Kantenbezeichner.}
	\label{tab:datasets_edges}
\end{table}
\renewcommand{\arraystretch}{1}

\subsection{Operationen}

Stellvertretend für Anfragen, die für die Analyse von Unternehmensdaten im Forschungsvorhaben relevant sind, wurden auf Grundlage des vorgestellten Schemas mehrere Anfragen definiert. Diese beinhalten jeweils einzelne oder mehrere der in Abschnitt \ref{subsec:graph_operations} vorgestellten graphenspezifischen Operationen. Es handelt sich um lokale Anfragen, die ausgehend von einem Knoten oder einer Knotenmenge einen Teil des Graphen analysieren. Dabei werden sowohl Topologie als auch Nutzdaten in die Operationen einbezogen. Auf rein topologische und globale Anfragen, wie zum Beispiel das Berechnen der k-Nachbarschaft ohne Berücksichtigung von Kantenbezeichnern oder das Auslesen aller Kanten, wurde bewusst verzichtet, da sie für das Forschungsvorhaben nicht relevant sind. In Tabelle \ref{tab:benchmark_queries} werden die Anfragen beschrieben und entsprechend der verwendeten Operationen kategorisiert.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.3cm}|>{\arraybackslash}m{13.45cm}|}
	\hline
   	\multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{c|}{\textbf{Beschreibung (Kategorisierung der Operationen)}} \\
	\hline
	\hline
	\textbf{\texttt{import}} & Importieren der Testgraphen in das jeweilige GDBMS unter Verwendung von Bulk-Load-Mechanismen. (Schreibperformance beim Bulk-Load)\\
	\hline
	\textbf{\texttt{random\_read}} & Zufällige Auswahl einzelner Produkte und Nutzer sowie vollständiges Auslesen ihrer Attribute. (Leseperformance beim Attributzugriff) \\
	\hline
	\textbf{\texttt{sim\_products}} & Zufällige Auswahl eines Produktes und anschließendes Traversieren  ähnlicher Produkte bis Abstand $\leq$ 2. Die Produkttitel sollen ausgegeben werden, jeder Titel soll einmalig in der Ergebnismenge sein. (Lokale Traversierung, Einschränkung) \\
	\hline
	\textbf{\texttt{foaf\_reviews}} & Zufällige Auswahl eines Nutzers und anschließende Selektion der Produkte, für die Freunde oder deren Freunde ein Review geschrieben haben. Das Ergebnis soll nach Produkttitel gruppiert und nach durchschnittlicher Bewertung sortiert werden. (Lokale Traversierung, Einschränkung, Gruppierung, Aggregation)\\
	\hline
	\textbf{\texttt{path\_all}} & Zufällige Auswahl eines Nutzers und eines Produktes und anschließendes Berechnen aller Pfade der Länge $\leq 4$ zwischen beiden Knoten. Dabei sollen nur die Kantenbezeichner \texttt{FRIEND\_OF}, \texttt{REVIEWED\_BY} und \texttt{SIMILAR\_TO} berücksichtigt werden, die Kantenrichtung ist nicht relevant. Im Ergebnis sollen die Pfade gruppiert nach Länge und der jeweiligen Anzahl ausgegeben werden. (Erreichbarkeit, Einschränkung, Gruppierung, Aggregation) \\
	\hline
	\textbf{\texttt{path\_shortest}} & Zufällige Auswahl zweier Nutzer und anschließende Berechnung des kürzesten Pfades zwischen ihnen unter Berücksichtigung der Kantenbezeichner \texttt{FRIEND\_OF}, \texttt{REVIEWED\_BY} und \texttt{SIMILAR\_TO}. Die maximale Pfadlänge beträgt 5, Kantenrichtungen werden nicht berücksichtigt. Das Ergebnis soll das Attribut \texttt{\_\_id\_\_} der Knoten innerhalb des Pfades beinhalten. (Erreichbarkeit, Einschränkung) \\
	\hline
	\textbf{\texttt{top\_regions}} & Auswahl aller Produkte, welche der Gruppe \texttt{'Books'} angehören und das Prädikat \texttt{salesrank} $\leq$ 500\,000 erfüllen. Das Ergebnis soll nach dem Attribut \texttt{region} jener Nutzer gruppiert werden, welche die Produkte mit einem \texttt{rating} $\geq$ 3 bewertet haben und dies für $\geq$ 5 Nutzer hilfreich war. Darüber hinaus soll das Ergebnis nach der Anzahl der Produkte pro Region sortiert und die oberen 10 Regionen ausgegeben werden. (Lokale Traversierung, Aggregation, Gruppierung, Selektion) \\
	\hline
	\textbf{\texttt{sim\_pattern}} & Zufällige Auswahl eines Nutzers und anschließendes Bestimmen seiner Freunde, die für 2 übereinstimmende Produkte Reviews geschrieben haben. Das Ergebnis soll den Nutzer selbst, die Freunde des Nutzers, die Reviews und die übereinstimmende Produktmenge beinhalten. (Lokale exakte Mustersuche) \\
	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Beschreibung der einzelnen Anfragen]{Namen und Beschreibungen der durchzuführenden Anfragen.}
	\label{tab:benchmark_queries}
\end{table}
\renewcommand{\arraystretch}{1}

Alle Anfragen wurden mittels Cypher und Gremlin realisiert und sind in Anhang \ref{anh:queries} aufgeführt. Eine Implementierung unter Verwendung der vorhandenen Java APIs wurde nicht durchgeführt, da zum Einen die Verwendung aktueller graphenspezifischer Anfragesprachen für die Formulierung komplexerer analytischer Anfragen in dieser Arbeit vordergründig ist und zum Anderen bereits in \cite{Ciglan:2012}, \cite{Gehrels:2013} und \cite{Holzschuher:2013:PGQ:2457317.2457351} gezeigt wurde, dass sich der Verzicht auf eine zusätzliche Anfrageverarbeitung positiv auf das Leistungsverhalten auswirkt. Eine Eignung der APIs für die Implementierung beliebiger analytischer Algorithmen und Operationen wurde den Systemen bereits im vorhergehenden Kapitel zugesprochen.

\subsection{Systemkonfiguration}

Die verwendete Testumgebung setzt sich wie folgt zusammen:

\begin{itemize}
	\item Intel i7-2620M
	\item 8 GB DDR-3
	\item Crucial M4 SSD
	\item Xubuntu 13.10 64-Bit (Kernel 3.11.0-12-generic)
	\item Java(TM) SE Runtime Environment (build 1.7.0\_45-b18) 
\end{itemize}

\paragraph*{Neo4j}

- eingebettet, zentral
- Cypher und Gremlin
- Verwendung von zwei Versionen: 1.9.4 (Gremlin) und 2.0.0-M06 (Cypher)
- Gremlin für die bessere Vergleichbarkeit mit Titan

- Indexstrukturen
	- Primärschlüsselindex auf \texttt{\_\_id\_\_}

- Verwendung von Knotenbezeichnern in Version 2.0.0-M06

- Bulk-Load-Einstellungen
	

- Caching-Einstellungen
- Kernel-Einstellungen
- JVM Einstellungen
	- Für die Durchführung der Benchmarks wurde die JVM-Heap-Größe auf 6 GB eingestellt.


\paragraph*{Titan}

- Index für id
- eingebettet
- Gremlin
- mit und ohne Typen

\subsection{Methodik}

- Übereinstimmung der Ergebnismengen wurde manuell überprüft

siehe \cite{Dominguez-Sal2011}

- Aufwärmphase ja / nein
- Ausführungsreihenfolge
- random seed statisch
- Ergebnismengen werden komplett ausgelesen (keine
- Messen

\section{Ergebnisse}






