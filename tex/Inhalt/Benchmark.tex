\chapter{Benchmark von Graphdatenbanksystemen}
\label{cha:benchmark}

In diesem Kapitel soll die Leistungsfähigkeit von Neo4j und Titan bei der Ausführung graphenspezifischer Operationen bewertet werden. Dabei ist es von besonderem Interesse, ob sich die im vorhergehenden Kapitel aufgeführten funktionalen Unterschiede auf die Performance der GDBMS auswirken. Zusätzlich soll beurteilt werden, inwieweit sich Cypher und Gremlin für die Formulierung analytischer Anfragen eignen. Zunächst werden Testgraphen, Operationen und das Testsystem vorgestellt, anschließend wird auf die Konfiguration der einzelnen GDBMS sowie auf die Methodik bei der Durchführung der Messungen eingegangen. Im zweiten, abschließenden Teil des Kapitels werden die Ergebnisse vorgestellt und bewertet.

\section{Testumgebung}

Bei der Analyse verwandter Arbeiten wurde festgestellt, dass aktuell - Stand Oktober 2013 - kein standardisierter Benchmark für GDBMS existiert. Die Herangehensweise fußt auf den Empfehlungen von Dominguez-Sal et al.\cite{Dominguez-Sal2011}, da diese bereits in den verwandten Arbeiten von Ciglan et al.\cite{Ciglan:2012} und Gehrels\cite{Gehrels:2013} berücksichtigt wurden und somit als Quasi-Standard gewertet werden.

\subsection{Datengrundlage}

In Absprache mit dem Projektverantwortlichen wurde vereinbart, reale Datensätze als Datengrundlage zu verwenden. Für das in Abschnitt \ref{sec:anforderungen} beschriebene Forschungsvorhaben ist vorgesehen, Informationsnetzwerke aus unterschiedlichen Geschäftsinformationssystemen zu integrieren und den daraus resultierenden Graphen zu analysieren. Die Netzwerke in den Quellsystemen können dabei unterschiedliche topologische Eigenschaften aufweisen und die in ihnen gespeicherten Informationen verschiedenen Klassen zugeordnet sein. Ein ERP-System verwaltet zum Beispiel Rechnungen, während ein CRM-System vorrangig Kundenaktivitäten speichert. Auf Grund der Wechselwirkungen zwischen den Entitäten innerhalb der einzelnen Quellsysteme entstehen verschiedenartige Beziehungsstrukturen.Folglich ist der integrierte Graph bezogen auf Topologie und Nutzdaten heterogen.\\
Die Algorithmen zur Erzeugung von Zufallsgraphen, welche in den verwandten Arbeiten eingesetzt wurden, bilden ausschließlich homogene Netzwerke ab, in denen alle Klassen einer Domäne zugeordnet sind. In \cite{Vicknair:2010:CGD:1900008.1900067} sind es zum Beispiel Herkunftsinformationen innerhalb eines Entstehungsprozesses, in \cite{Holzschuher:2013:PGQ:2457317.2457351} Personen, Aktivitäten, Organisationen und Nachrichten in einem sozialen Netzwerk, in \cite{Ciglan:2012}, \cite{Dominguez-Sal:2010:SGD:1927585.1927590} und \cite{Gehrels:2013} hingegen wird generell auf eine Klassifizierung der Informationen verzichtet. Das Erzeugen synthetischer, heterogener Graphen ist sehr aufwändig, da jeder Klasse und jeder Beziehungsart hinsichtlich ihrer Erzeugung eine eigene Logik zugeordnet werden muss.

Weil reale Daten aus Geschäftsinformationssystemen nicht frei zur Verfügung stehen, werden stellvertretend für heterogene Netzwerke \texttt{amazon-meta}\cite{snap_amazon:2013} und \texttt{soc-Pokec}\cite{snap_pokec:2013} verwendet, beides Datensätze des Stanford Network Analysis Project\footnote{\url{https://snap.stanford.edu/}}. Das Informationsnetzwerk \texttt{amazon-meta} beinhaltet Produktinformationen des Onlinehändlers Amazon\footnote{\url{http://www.amazon.com}}, wozu u.a. Produktbewertungen und Beziehungen zwischen Produkten zählen.\footnote{Es handelt sich dabei um ähnliche Produkte, die laut Amazon oft zusammen gekauft werden.} Pokec hingegen ist ein slowakisches soziales Online-Netzwerk, in dem Nutzer durch gerichtete Freundschaftsbeziehungen miteinander verbunden sind.\footnote{\url{http://pokec.azet.sk/}} Abbildung \ref{fig:testdata} zeigt das integrierte Schema beider Netzwerke als Property-Graph.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.75]{schema.pdf}
	\caption[Benchmark: Schema Testdaten]{Integriertes Schema aus Amazon- und Pokec-Daten.}
	\label{fig:testdata}
\end{figure}

Beide Datensätze verfügen über eine Klasse \texttt{User}. Deren Instanzen werden innerhalb von \texttt{amazon-meta} durch eine eindeutige Identität repräsentiert und stehen nicht in Beziehung zueinander. In \texttt{soc-Pokec} hingegen weisen die Instanzen eine Vielzahl von Attributen auf und sind durch gerichtete \texttt{FRIEND\_OF}-Beziehungen miteinander verbunden. Die Anzahl der Nutzer stimmt in beiden Datensätzen annähernd überein, \texttt{amazon-meta} weist ca. 1.5 Mio., \texttt{soc-Pokec} etwa 1.6 Mio. Nutzer auf. Im Rahmen der Datenaufbereitung wurden zunächst Pokec-Nutzer pseudozufällig auf Amazon-Nutzer abgebildet, anschließend wurde der durch die ausgewählten Knoten induzierte Teilgraph aus \texttt{soc-Pokec} extrahiert und mit \texttt{amazon-meta} zu einem integrierten Graph zusammengeführt.\\
Die Netzwerke enthalten neben den topologischen Informationen auch Nutzdaten, welche für Gruppen, Produkte und Bewertungen vollständig aus den Rohdaten übernommen wurden, für die Nutzer hingegen wurde eine Auswahl von Attributen unterschiedlichen Datentyps getroffen. Die Rohdaten beider Netzwerke wurden für die weitere Verwendung in das textbasierte Geoff-Format\footnote{\url{http://nigelsmall.com/geoff}} überführt, welches von Neo4j entwickelt wurde.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|l|rl|rl|rl|rl|rl|rl|rl|rl|rl|}
	\hline
   	 & \multicolumn{8}{c|}{\textbf{Knoten}} & \multicolumn{2}{c|}{\textbf{Attribute}} \\ \cline{2-11}
   	\textbf{Graph} & \multicolumn{2}{c|}{\texttt{Group}} & \multicolumn{2}{c|}{\texttt{Product}} & \multicolumn{2}{c|}{\texttt{User}} & \multicolumn{2}{c|}{$\Sigma$} & \multicolumn{2}{c|}{$\Sigma$} \\
   	\hline
   	   	\hline
   	\texttt{orig} & \multicolumn{2}{c|}{10} & \multicolumn{2}{c|}{542\,684} & \multicolumn{2}{c|}{1\,555\,124} & \multicolumn{2}{c|}{2\,097\,819} & \multicolumn{2}{c|}{20\,377\,902} \\
   	\hline
   	\hline
	\texttt{p\_100} & 1 & (1) & 126 & (1) & 347\,752 & (1) & 347\,879 & (1) & 1\,874\,907 & (1)\\
	\hline
	\texttt{p\_1K} & 4 & (4) & 1\,089 & (8.64) & 665\,116 & (1.91) & 666\,209 & (1.92) & 3\,710\,473 & (1.98) \\
	\hline
	\texttt{p\_10K} & 4 & (1) & 10\,047 & (9.23) & 976\,985 & (1.47) & 987\,036 & (1.47) & 7\,255\,153 & (1.96) \\
   	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Anzahl Knoten und Attribute]{Anzahl Instanzen der verschiedenen Knotenklassen und Gesamtanzahl der Knoten- und Kantenattribute.}
		\label{tab:datasets_nodes}
\end{table}
\renewcommand{\arraystretch}{1}

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|l|rl|rl|rl|rl|rl|}
	\hline
	& \multicolumn{10}{c|}{\textbf{Kanten}} \\ \cline{2-11}

   	\textbf{Graph} & \multicolumn{2}{c|}{\texttt{BELONGS\_TO}} & \multicolumn{2}{c|}{\texttt{SIMILAR\_TO}} & \multicolumn{2}{c|}{\texttt{REVIEWED\_BY}} & \multicolumn{2}{c|}{\texttt{FRIEND\_OF}} & \multicolumn{2}{c|}{$\Sigma$} \\
   	\hline
   	\hline
   	\texttt{orig} & \multicolumn{2}{c|}{542\,684} & \multicolumn{2}{c|}{1\,231\,400} & \multicolumn{2}{c|}{7\,593\,109} & \multicolumn{2}{c|}{27\,787\,537} & \multicolumn{2}{c|}{37\,154\,730} \\
	\hline
	\hline
	\texttt{p\_100} & 126 & (1) & 396 & (1) & 1\,909 & (1) & 704\,092 & (1) & 706\,523 & (1) \\
	\hline
	\texttt{p\_1K} & 1\,089 & (8.64) & 3\,365 & (8.5) & 29\,848 & (15.64) & 1\,830\,064 & (2.6) & 1\,864\,366 & (2.64) \\
	\hline
	\texttt{p\_10K} & 10\,048 & (9.23) & 27\,976 & (8.31) & 401\,917 & (13.47) & 3\,576\,276 & (1.95) & 4\,016\,216 & (2.15) \\
	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Anzahl Kanten]{Anzahl Instanzen der verschiedenen Kantenbezeichner.}
	\label{tab:datasets_edges}
\end{table}
\renewcommand{\arraystretch}{1}

Ein wichtiges Kriterium bei der Durchführung eines Benchmarks ist das Leistungsverhalten einer Anfrage bei steigendem Datenvolumen. Synthetische Datensätze lassen sich erzeugen, reale Datensätze hingegen besitzen eine festgelegte Größe. Mit dem Ziel, die Skalierbarkeit von Anfragen dennoch untersuchen zu können, wurden zusammenhängende Teilgraphen aus dem integrierten Datensatz extrahiert. Die Teilgraphen sind bezüglich der Knoten aus \texttt{amazon-meta} induziert, dies gilt nicht für den Teilgraph, welcher ausschließlich aus Nutzerknoten besteht. Der Algorithmus wird in Anhang \ref{anh:extraction} beschrieben.

Dominguez-Sal et al. empfehlen die Angabe eines einzelnen Skalierungsfaktors, von welchem die Anzahl der erzeugten Knoten und Kanten abhängig ist, dies lässt sich jedoch bei der Verwendung realer Datensätze nicht umsetzen. Durch die Wahr der Parameter des Extraktionsalgorithmus wurde daher versucht, möglichst konstante Wachstumsfaktoren zu erreichen. Die Tabellen \ref{tab:datasets_nodes} und \ref{tab:datasets_edges} stellen den integrierten Graph (\texttt{orig}) und die extrahierten Teilgraphen bezogen auf die Anzahl der Knoten und Kanten gruppiert nach ihrer jeweiligen Klasse gegenüber. Zusätzlich wird der Wachstumsfaktor für jeden Wert in Relation auf dessen Äquivalent im nächstkleineren Graphen angeben. Ein Nachteil dieser Herangehensweise ist, dass sich die topologischen Eigenschaften der verschiedenen extrahierten Teilgraphen unterscheiden können, was bei der nachfolgenden Bewertung berücksichtigt wird.

\subsection{Operationen}

Stellvertretend für jene Anfragen, welche für die Analyse von Unternehmensdaten im Forschungsvorhaben relevant sind, wurden auf Grundlage des vorgestellten Schemas mehrere Anfragen definiert, die jeweils einzelne oder mehrere der in Abschnitt \ref{subsec:graph_operations} vorgestellten graphenspezifischen Operationen beinhalten. Es handelt sich um lokale Anfragen, die ausgehend von einem Knoten oder einer Knotenmenge einen Teil des Graphen analysieren. Dabei werden seine Topologie und auch Nutzdaten in die Operationen einbezogen. Es wurde bewusst auf rein topologische und globale Anfragen verzichtet, da sie für das Forschungsvorhaben nicht relevant sind, Beispiele hierfür sind das Berechnen der k-Nachbarschaft ohne Berücksichtigung von Kantenbezeichnern oder das Auslesen aller Kanten. Gleiches gilt für Schreibzugriffe, hier ist lediglich die Performance der Bulk-Load-Mechanismen von Interesse. 

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.3cm}|>{\arraybackslash}m{13.45cm}|}
	\hline
   	\multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{c|}{\textbf{Beschreibung (Kategorisierung der Operationen)}} \\
	\hline
	\hline
	\textbf{\texttt{import}} & Importieren der Testgraphen in das jeweilige GDBMS unter Verwendung von Bulk-Load-Mechanismen. (Schreibperformance beim Bulk-Load)\\
	\hline
	\textbf{\texttt{random\_read}} & Zufällige Auswahl einzelner Produkte und Nutzer sowie vollständiges Auslesen ihrer Attribute. (Leseperformance beim Attributzugriff) \\
	\hline
	\textbf{\texttt{sim\_products}} & Zufällige Auswahl eines Produktes und anschließendes Traversieren  ähnlicher Produkte bis Abstand $\leq$ 2, die Kantenrichtung ist nicht relevant. Die Produkttitel sollen ausgegeben werden, jeder Titel soll einmalig in der Ergebnismenge sein. (Lokale Traversierung, Einschränkung) \\
	\hline
	\textbf{\texttt{foaf\_reviews}} & Zufällige Auswahl eines Nutzers und anschließende Selektion der Produkte, für die Freunde oder deren Freunde ein Review geschrieben haben. Das Ergebnis soll nach Produkttitel gruppiert und nach durchschnittlicher Bewertung sortiert werden. (Lokale Traversierung, Einschränkung, Gruppierung, Aggregation)\\
	\hline
	\textbf{\texttt{path\_all}} & Zufällige Auswahl eines Nutzers und eines Produktes und anschließendes Berechnen aller Pfade der Länge $\leq 4$ zwischen beiden Knoten. Dabei sollen nur die Kantenbezeichner \texttt{FRIEND\_OF}, \texttt{REVIEWED\_BY} und \texttt{SIMILAR\_TO} berücksichtigt werden, die Kantenrichtung ist nicht relevant. Im Ergebnis sollen die Pfade gruppiert nach Länge und der jeweiligen Anzahl ausgegeben werden. (Erreichbarkeit, Einschränkung, Gruppierung, Aggregation) \\
	\hline
	\textbf{\texttt{path\_shortest}} & Zufällige Auswahl zweier Nutzer und anschließende Berechnung des kürzesten Pfades unter Berücksichtigung der Kantenbezeichner \texttt{FRIEND\_OF}, \texttt{REVIEWED\_BY} und \texttt{SIMILAR\_TO}. Die maximale Pfadlänge beträgt 4, Kantenrichtungen werden nicht berücksichtigt. Das Ergebnis soll das Attribut \texttt{\_\_id\_\_} der Knoten innerhalb des Pfades beinhalten. (Erreichbarkeit, Einschränkung) \\
	\hline
	\textbf{\texttt{top\_regions}} & Auswahl aller Produkte, welche der Gruppe \texttt{'Books'} angehören und das Prädikat \texttt{salesrank} $\leq$ 500\,000 erfüllen. Das Ergebnis soll nach dem Attribut \texttt{region} jener Nutzer gruppiert werden, welche die Produkte mit einem \texttt{rating} $\geq$ 3 bewertet haben und dies für $\geq$ 5 Nutzer hilfreich war. Darüber hinaus soll das Ergebnis nach der Anzahl der Produkte pro Region sortiert und die oberen 10 Regionen ausgegeben werden. (Lokale Traversierung, Aggregation, Gruppierung, Selektion) \\
	\hline
	\textbf{\texttt{sim\_pattern}} & Zufällige Auswahl eines Nutzers und anschließendes Bestimmen seiner Freunde, die für mindestens ein übereinstimmendes Produkt Reviews geschrieben haben. Das Ergebnis soll den Nutzer selbst, die Freunde des Nutzers und die übereinstimmende Produktmenge beinhalten. (Lokale exakte Mustersuche) \\
	\hline
  	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Benchmark: Beschreibung der einzelnen Anfragen]{Namen und Beschreibungen der durchzuführenden Anfragen.}
	\label{tab:benchmark_queries}
\end{table}
\renewcommand{\arraystretch}{1}

In Tabelle \ref{tab:benchmark_queries} werden die Anfragen beschrieben und entsprechend der verwendeten Operationen kategorisiert. Alle Anfragen wurden mittels Cypher und Gremlin realisiert und sind in Anhang \ref{anh:queries} aufgeführt. Eine Implementierung unter Verwendung der vorhandenen Java APIs wurde nicht durchgeführt, da in dieser Arbeit die Verwendung aktueller graphenspezifischer Anfragesprachen für die Formulierung komplexerer, analytischer Anfragen vordergründig ist. Bereits in \cite{Ciglan:2012}, \cite{Gehrels:2013} und \cite{Holzschuher:2013:PGQ:2457317.2457351} wurde gezeigt, dass sich der Verzicht auf eine zusätzliche Anfrageverarbeitung positiv auf das Leistungsverhalten auswirkt. Eine Eignung der APIs für die Implementierung beliebiger analytischer Algorithmen und Operationen wurde den Systemen bereits im vorhergehenden Kapitel attestiert.

\subsection{Systemkonfiguration}

Die verwendete Testumgebung setzt sich wie folgt zusammen:

\begin{itemize}
	\setlength{\parskip}{1pt}
	\item Intel i7-2620M (2x3.4 Ghz)
	\item 8 GB DDR-3 RAM (1333 Mhz)
	\item Crucial M4 SSD (128 GB)
	\item Xubuntu 13.10 64-Bit (Kernel 3.11.0-12-generic, ext4)
	\item Java(TM) SE Runtime Environment (build 1.7.0\_45-b18)
\end{itemize}

\paragraph*{Neo4j}

Das GDBMS wird in einer zentralen, eingebetteten Konfiguration verwendet, Anfragen werden sowohl in Cypher als auch in Gremlin ausgeführt. Für Cypher-Anfragen wird die im vorhergehenden Kapitel betrachtete Version 2.0.0-M04 eingesetzt. Die Berücksichtigung von Gremlin ermöglicht eine bessere Vergleichbarkeit mit Titan, macht es jedoch erforderlich, für die Durchführung auf Version 1.9.4 des GDBMS zurückzugreifen, da Blueprints 2.4.0 und somit auch Gremlin bisher nicht kompatibel zu den Neuerungen in Neo4j 2.0 sind.  Die Ausführung von Cypher erfolgt unter Verwendung der \texttt{ExecutionEngine}\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/tutorials-cypher-java.html}}, für Gremlin wird die in der Dokumentation beschriebene \texttt{GremlinGroovyScriptEngine} \footnote{\url{https://github.com/tinkerpop/gremlin/wiki/Using-Gremlin-through-Java\#using-jsr-223-gremlingroovyscriptengine}} genutzt.

Für den Bulk-Load der Testgraphen wird im \texttt{import}-Benchmark der von Neo4j zur Verfügung gestellte \texttt{BatchInserter} entsprechend der Dokumentation\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/batchinsert.html}} eingesetzt. Während des Import erfolgt das Aktualisieren eines zusätzlichen Lucene-Index auf dem Knotenattribut \texttt{\_\_id\_\_}. Bei der Verwendung von Neo4j 2.0.0-M04 werden darüber hinaus Knotenbezeichner entsprechend der Knotenklasse gesetzt, diese können folglich nur in Cypher-Anfragen berücksichtigt werden.

Die Kernel-Einstellungen\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/kernel-configuration.html}} des GDBMS werden unverändert übernommen. Die Größe des Heap-Speichers der JVM wird entsprechend den Empfehlungen\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/configuration-jvm.html}} auf 4 GB festgelegt, eine Änderung des Stack-Speichers erfolgt nicht. Darüber hinaus wird der Concurrent Mark and Sweep Compactor Garbage Collector\footnote{\url{http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html\#BehavioralOptions}} verwendet.\\
Die Einstellungen des Object-Cache bleiben unverändert, es wird demnach die in Abschnitt \ref{subsec:neo4j_persistency} beschriebene Standard-Implementierung genutzt. Der Filesystem-Cache wurde entsprechend der Größe der Stores angepasst. Um deren Speicherbedarf zu ermitteln, wurde der größte Testgraph (\texttt{p\_10K}) importiert und die Größe der Stores im Dateisystem bestimmt. Für den Knoten-Store sind dies 20 MB, für den Kanten-Store 150 MB.\footnote{Dieser Wert lässt sich ebenfalls aus der Datensatzgröße von 14 bzw. 33 Byte und der Anzahl Knoten bzw. Kanten in Tabelle \ref{tab:datasets_nodes} bzw. \ref{tab:datasets_edges} berechnen.} Interessant ist, dass trotz der Verwendung von String- und Array-Properties der Property-Store für primitive Datentypen den größten Speicherbedarf aufweist.\footnote{Für primitive Datentypen werden 150 MB, für Strings 50 MB und für Arrays 10 MB beansprucht.} Neo4j verwendet für Strings und Arrays zusätzliche Kompressionsmethoden\footnote{\url{http://docs.neo4j.org/chunked/2.0.0-M04/short-strings.html} und \url{http://docs.neo4j.org/chunked/2.0.0-M04/short-arrays.html}} und fügt, wenn möglich, die entsprechenden Werte in den Property-Store für primitive Datentypen ein und vermeidet damit eine zusätzliche Indirektion beim Lese- und Schreibzugriff. Die Anpassung des Filesystem-Cache ermöglicht es dem GDBMS die komplette Datenbasis im Hauptspeicher vorhalten zu können.

\paragraph*{Titan}

Das GDBMS wird ebenfalls in einer zentralen, eingebetteten Konfiguration verwendet. Anfragen werden ausschließlich in Gremlin ausgeführt, dies erfolgt wie bei Neo4j unter Verwendung der \texttt{GremlinGroovyScriptEngine}. Das verwendete Speichersystem ist BerkeleyDB Java Edition, die Konfiguration erfolgt ausschließlich mit den von Titan zur Verfügung gestellten Parametern.

Für den Import der Testgraphen wird der im TinkerPop-Projekt verfügbare \texttt{BatchGraph} verwendet, eine Wrapper-Klasse, die Bulk-Load-Funktionalität für blueprints-kompatible GDBMS zur Verfügung stellt.\footnote{\url{https://github.com/tinkerpop/blueprints/wiki/Batch-Implementation}} Die Verwendung von \texttt{BatchGraph} wird von Aurelius für Graphen mit bis zu 100 Mio. Kanten empfohlen. Darüber hinaus wurde der Konfigurationsparameter \texttt{storage.batch-loading} auf \texttt{true} gesetzt, was die internen Konsistenzmechanismen von Titan deaktiviert und den Import beschleunigen soll.\\
Vor dem Datenimport werden Instanzen von \texttt{TitanKey} bzw. \texttt{TitanLabel} erzeugt. Für Instanzen von \texttt{TitanKey} werden Attributschlüssel, Datentyp des Attributwertes und Eindeutigkeit an der Instanz festgelegt, dem Knotenattribut \texttt{\_\_id\_\_} wird wie bei Neo4j ein Index zugeordnet. Die Instanzen von \texttt{TitanLabel} werden entsprechend den vier Beziehungsarten bezeichnet, \texttt{BELONGS\_TO}-Kanten werden darüber hinaus als $n:1$-Beziehung zwischen Produkt und Gruppe deklariert. Die Durchführung erfolgt sowohl mit manueller als auch mit systemseitiger Typdefinition, damit soll untersucht werden, inwieweit sich die Festlegung der Datentypen auf die Leistungsfähigkeit des GDBMS auswirkt.

Entsprechend der Empfehlung von Aurelius werden BerkeleyDB 80\% des zur Verfügung stehenden Heap-Speichers zur Verfügung gestellt.\footnote{\url{https://github.com/thinkaurelius/titan/wiki/Using-BerkeleyDB}} Dieser wird wie bei Neo4j auf insgesamt 4 GB festgelegt. Oracle empfiehlt für BerkeleyDB ebenfalls die Verwendung des Concurrent Mark and Sweep Compactor Garbage Collector, welcher folglich bei der Durchführung aktiviert ist.\footnote{\url{http://www.oracle.com/technetwork/database/berkeleydb/je-faq-096044.html\#WhatJVMparametersshouldIconsiderwhentuninganapplicationwithalargecachesize}}

\subsection{Methodik}

% Verweis auf Framework
Für die Durchführung der Messungen wurde ein Java-Framework\footnote{\url{https://github.com/s1ck/master_thesis/tree/master/benchmark}} entwickelt, mit dem sich individuell konfigurierbare Benchmarks nach einem definierten Protokoll ausführen lassen. Jede der zu messenden Anfragen kann einzeln aktiviert und konfiguriert werden. Dabei lässt sich die Ausführungsreihenfolge beliebig variieren, bei der Durchführung wird die Reihenfolge entsprechend Tabelle \ref{tab:benchmark_queries} beibehalten.

% Import
Die Testgraphen liegen im Geoff-Format vor und werden unter Verwendung eines Iterators eingelesen. Dieser Ansatz ermöglicht es, auch umfangreiche Datensätze ohne zusätzliche Inanspruchnahme des Hauptspeichers zu verarbeiten und gleichzeitig die unmittelbare Schreibperformance des GDBMS in Abhängigkeit vom Externspeicher zu messen.

% Warmup Caches
Für die Simulation eines realistischen Antwortzeitverhaltens empfehlen Dominguez-Sal et al. ein sog. \textit{warmup} der Caches. Eine Zielstellung des Forschungsvorhabens ist die Verwendung des GDBMS im Rahmen einer Analyseplattform. Dabei wird angenommen, dass diese nicht nur bei Bedarf gestartet wird, sondern permanent in Betrieb ist. Folglich ist davon auszugehen, dass sich entweder der gesamte Graph oder Teilgraphen zum Zeitpunkt der Anfrage in den Caches befinden und somit eine effizientere Ausführung möglich ist.\\ % Darüber hinaus verdeutlichen aktuelle Entwicklungen, wie zum Beispiel SAP HANA\cite{plattner2011memory}, dass die Verwendung mehrerer hundert Gigabyte Hauptspeicher in aktuellen Server-Systemen kosteneffizient ist und auf lange Sicht die Bedeutung der im Vergleich langsamen Externspeichern sinken lässt.\\
Mit dem Ziel, eine vergleichbare Situation zu schaffen, wurde vor der Ausführung einer Messung eine Iteration sowohl über die gesamte Knotenmenge als auch über die gesamte Kantenmenge durchgeführt.\footnote{In Titan erfolgt in der warmup-Prozedur nach 20\,000 gelesenen Objekten ein Commit um potentielle Speicherprobleme durch den Transaktionscache zu verhindern.} Zusätzlich wurde das Knotenattribut \texttt{\_\_type\_\_} ausgelesen und die jeweilige Identität nach Typ gruppiert gespeichert, diese Informationen werden für die pseudozufällige Auswahl der Startknoten einer Anfrage genutzt.

% Zeitmessung
Ein Benchmark zu jeder Anfrage wird nach folgendem Protokoll durchgeführt:
\begin{enumerate}
	\setlength{\parskip}{1pt}
	\item Vorbereitung des Benchmarks (GDBMS initialisieren)
	\item Warmup-Prozedur ausführen (außer beim Importieren)
	\item Für $n$ Wiederholungen
		\begin{enumerate}
			\item Vorbereitung der Messung (Auswahl der Startknoten, Anfrage parametrisieren)
			\item Beginn der Zeitmessung
			\item Ausführen der Operation und ggf. vollständiges Auslesen der Ergebnismenge
			\item Ende der Zeitmessung		
		\end{enumerate}
	\item Nachbereitung des Benchmarks (Ressourcen freigeben)
	\item Speichern der Messergebnisse sowie GDBMS- und Benchmark-Konfiguration
\end{enumerate}

% Random Seed
Mit dem Ziel, eine Benachteiligung eines GDBMS zu vermeiden, wird für den Pseudozufallsgenerator ein \texttt{seed}-Wert festgelegt. Dies führt dazu, dass für alle Anfragen in jedem GDBMS die gleichen Knoten ausgewählt werden und darüber hinaus die Benchmarks reproduzierbar sind. Die Übereinstimmung der Ergebnismengen wurde für jede Anfrage validiert.

Für den Erhalt signifikanter Ergebnisse wird die Anzahl der Wiederholungen generell auf $n=1000$ festgelegt, die \texttt{import}-Operation hingegen wird einmalig ausgeführt. Die Zeitmessung erfolgt unter Verwendung der statischen Methode \texttt{System.nanoTime()}. Da sowohl die \texttt{ExecutionEngine} als auch die \texttt{GremlinGroovyScriptEngine} einen Cache für die jeweils generierten Ausführungspläne besitzen, ist die erste Anfrage typischerweise deutlich langsamer als alle nachfolgenden Anfragen, infolgedessen wird der Messwert der ersten Iterationen nicht berücksichtigt. Alle Anfragen werden sequentiell ausgeführt, es findet kein konkurrierender Zugriff auf die Datenbasis statt. Die Messgrößen sind für \texttt{import} die Importdauer und der Speicherverbrauch der Datenbank inklusive aller Indexstrukturen auf dem Hintergrundspeicher, für alle anderen Operationen wird die Ausführungszeit gemessen. Die erhaltenen Messwerte werden gespeichert und mittels R und LibreOffice Calc weiterverarbeitet.

\section{Ergebnisse}

Im nachfolgenden Abschnitt werden die Ergebnisse der einzelnen Messungen vorgestellt und diskutiert. Hierfür wird entweder der Durchschnittswert in einem Säulendiagramm oder alle Werte in einem Boxplot visualisiert. Das Säulendiagramm wird für Anfragen verwendet, in denen die Ergebnismengen eine konstante oder annähernd konstante Größe aufweisen, dies trifft auf \texttt{import}, \texttt{random\_read} und \texttt{top\_regions} zu. Für die Visualisierung der übrigen Messergebnisse wurde sich für die Boxplot-Darstellung entschieden, da sich die Ergebnismengen je nach Grad zu berücksichtigender Knoten stark unterscheiden können und die Messwerte keiner Normalverteilung unterliegen. Ein Durchschnittswert spiegelt in diesem Fall das Antwortzeitverhalten der einzelnen Systeme nicht zwingend exakt wider und ermöglicht keine Beurteilung des generellen Leistungsverhaltens.

\paragraph*{\texttt{import}} Die Abbildungen \ref{fig:import_time} und \ref{fig:import_space} stellen die Ergebnisse des Datenimport dar. Es wird deutlich, dass Neo4j hinsichtlich beider Messgrößen annähernd lineares Verhalten in Abhängigkeit zur Datenmenge aufweist. In Titan gilt dies für den Speicherverbrauch, die Importdauer hingegen skaliert mit zunehmender Datenmenge schlechter. Es wird vermutet, dass dies mit der Anzahl verwalteter Key-Value-Datenbanken in Zusammenhang steht: Eine KV-Datenbank speichert Topologie und Nutzdaten, zwei KV-Datenbanken verwalten den Knoten- bzw. Kantenindex und der manuell definierte Index erfordert eine weitere KV-Datenbank in BerkeleyDB. Festzuhalten ist, dass Neo4j grundsätzlich weniger Zeit für den Bulk-Import beansprucht und eine kompaktere physische Repräsentation des Graphen aufweist. 

\begin{figure}[htb]
	\centering	
	\subfigure[Importdauer]{\label{fig:import_time}\includegraphics[scale=.5]{import_time.pdf}}\qquad	
	\subfigure[Speicherverbrauch]{\label{fig:import_space}\includegraphics[scale=.5]{import_space.pdf}}	
	\caption[Benchmark: \texttt{import}]{Ergebnisse der \texttt{import}-Messung. Titan (auto) bezeichnet die automatische Typisierung von Attributschlüsseln und Kantenbezeichner, während Titan(manual) die manuelle Typisierung repräsentiert.}
\end{figure}

\paragraph*{\texttt{random\_read}} Diese Anfrage greift unter Verwendung der systemseitigen Identitäten auf Knoteninstanzen zu und liest ihre Attribute vollständig aus, Abbildung \ref{fig:random_read} zeigt hierfür die durchschnittliche Antwortzeit der beiden GDBMS inklusive der Standardabweichung innerhalb der Messreihe. Auffällig ist der deutliche Zeitunterschied zwischen der Verwendung von Cypher und Gremlin: Cypher ist um einen Faktor von ca. 20 bis 30 langsamer als eine gleichwertige Gremlin-Anfrage, dies deckt sich mit den Beobachtungen in \cite{Gehrels:2013} und \cite{Holzschuher:2013:PGQ:2457317.2457351}. Weiter lässt sich für Cypher-Anfragen eine deutlich höhere Standardabweichung der Messergebnisse feststellen. Anzumerken ist, dass Neo4j in Verbindung mit Gremlin generell leicht geringere Antwortzeiten erreicht als Titan, es gilt jedoch zu berücksichtigen, dass die in Titan indexierte Datenmenge nicht nur Knoten, sondern auch Kanten und Attribute umfasst.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{random_read.pdf}
	\caption[Benchmark: \texttt{random\_read}]{Durchschnittliche Antwortzeit und Standardabweichung der \texttt{random\_read}-Messung.}
	\label{fig:random_read}
\end{figure}

Eine manuelle Typisierung führt in Titan beim vollständigen Auslesen der Attribute zu keiner messbaren Leistungssteigerung. Auffällig hingegen ist, dass die Antwortzeiten bei steigendem Datenvolumen annähernd konstant bleiben, während sie bei Neo4j 2.0 leicht ansteigen. Dies ist insofern interessant, als das beim Warmup lediglich auf das \texttt{\_\_type\_\_}-Attribut zugegriffen wurde und somit in Titan alle Attribute beim Zugriff aus BerkeleyDB geladen werden müssen. In Neo4j werden einfache Properties satzweise geladen und sollten sich somit beim Benchmark im Object-Cache befinden. Dies spricht für die Leistungsfähigkeit von BerkeleyDB.

\paragraph*{\texttt{sim\_products}} Die Anfrage führt eine Berechnung der 2-Nachbarschaft ausgewählter Knoten durch und bezieht folglich die Struktur des Graphen ein, die Menge zu berücksichtigender Kantenbezeichner wird eingeschränkt. Da die Anzahl ähnlicher Produkte je nach ausgewählten Produkt verschieden sein kann, wurde in Abbildung \ref{fig:sim_products} das Boxplot-Diagramm für die Darstellung der Ergebnisse gewählt. Zu beachten ist die logarithmische Skalierung der Antwortzeit.

Analog zu \texttt{random\_read} zeigt sich für Neo4j auch in dieser Messung ein deutlicher Zeitunterschied zwischen der Ausführung mit Cypher und Gremlin, wobei Letztere um einen Faktor von ca. 20 schneller ist. Für beide Systeme ist das Antwortzeitverhalten bei steigendem Datenvolumen hervorzuheben, die Antwortzeit bleibt unabhängig von der Größe des Graphen konstant, allein bei Neo4j (Cypher) lässt sich ein geringer Anstieg und eine Verschiebung der Ausreißer feststellen. Es wird vermutet, dass das auffällige Antwortzeitverhalten von Cypher-Anfragen in \texttt{p\_100} mit der geringen Produktanzahl (126) zusammenhängt. Einzelne Produkte werden mehrfach abgefragt, dabei wird vermutlich von Caching-Mechanismen des Betriebssystems sowie der CPU profitiert.\\
Die Anfrage erfordert eine Auflistung der Produkttitel und somit den direkten Zugriff auf das entsprechende Knotenattribut. Ein manuelles Festlegen der Datentypen in Titan erzielt dabei keine messbare Verbesserung. Generell erreicht auch in dieser Anfrage Neo4j in Verbindung mit Gremlin die beste Performance.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{sim_products.pdf}
	\caption[Benchmark: \texttt{sim\_products}]{Ergebnisse der \texttt{sim\_products}-Messung.}
	\label{fig:sim_products}
\end{figure}

\paragraph*{\texttt{foaf\_reviews}} Diese Anfrage beinhaltet neben einer lokalen Traversierung des Graphen auch eine Gruppierung nach Knotenattributen sowie das Berechnen von Aggregaten anhand eines Kantenattributs, die Ergebnismenge wird sortiert ausgegeben. Abbildung \ref{fig:foaf_reviews} zeigt die Messergebnisse als Boxplot, auch hier ist die logarithmische Skalierung der Antwortzeit zu beachten.

Erneut lässt sich ein deutlicher Unterschied zwischen den Antwortzeiten von Cypher- und Gremlin-Anfragen in Neo4j feststellen (ca. Faktor 80). Für beide Sprachen sind die Antwortzeiten unabhängig von der Datenmenge konstant und insbesondere die cypher-basierte Ausführung variiert im Vergleich zu den Gremlin-Anfragen in Neo4j und Titan nur wenig, was auf eine effizientere Anfrageausführung schließen lässt. Auch für diese Anfrage weist Neo4j in Verbindung mit Gremlin das im Vergleich beste Leistungsverhalten auf. 

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{foaf_reviews.pdf}
	\caption[Benchmark: \texttt{foaf\_reviews}]{Ergebnisse der \texttt{foaf\_reviews}-Messung.}
	\label{fig:foaf_reviews}
\end{figure}

Anders als in den bisher betrachteten Anfragen wird in dieser auf Kantenattribute zugegriffen. Dabei erreicht die Verwendung von typisierten Attributschlüsseln in allen Testgraphen niedrigere Antwortzeiten als eine automatische Vergabe, die Differenz ist jedoch sehr gering. Deutlicher sind hingegen die in beiden Systemen höheren Antwortzeiten bei steigendem Datenvolumen, dabei fallen insbesondere die Ausreißer von ca. 10s im größten Datensatz auf. Eine genauere Betrachtung der Daten hat ergeben, dass eine Ergebnismenge durchschnittlich 37 Produkttitel enthält. Die Ergebnismenge, welche zu diesem Ausreißer führte, umfasst hingegen 3\,599 Einträge. Auffällig ist dabei, dass Neo4j mit Cypher für diesen Wert ein besseres Ergebnis erzielt als die ebenfalls in Neo4j ausgeführte Gremlin-Anfrage. Die Ursache wird somit entweder in der Implementierung der Anfrageausführung von Gremlin bzw. in einer nicht-optimalen Formulierung der Anfrage vermutet.

\paragraph*{\texttt{path\_all}} Die Anfrage berechnet alle existierenden Pfadinstanzen zwischen zwei Knoten, die maximale Pfadlänge ist begrenzt und die Menge zu besuchender Knoten wird durch die Definition zulässiger Kantenbezeichner eingeschränkt. Wie in Abschnitt \ref{sec:operations} im Zusammenhang mit der Traversierung erläutert, bedarf die Pfadsuche eine Betrachtung aller Knoten, welche sich im definierten maximalen Abstand zum Startknoten befinden und erfordert gleichzeitig das Zwischenspeichern besuchter Knoten und berechneter Pfadinstanzen. Je nach Knotengrad kann folglich schon bei geringer Pfadlänge ein großer Teil des Graphen traversiert werden. Während der Ausführung wurde für einige der Messreihen festgestellt, dass der zur Verfügung stehende Hauptspeicher für diese Berechnung nicht ausreicht und der Swap-Bereich des Betriebssystems beansprucht wurde. Die resultierenden Ergebnisse sind für eine allgemeingültige Bewertung folglich nicht verwendbar und es musste auf die Messreihe Neo4j (Cypher) im Datensatz \texttt{p\_1K} sowie auf alle Messreihen im Datensatz \texttt{p\_10K} verzichtet werden. Abbildung \ref{fig:path_all} zeigt die Ergebnisse für die durchgeführten Messungen.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{path_all.pdf}
	\caption[Benchmark: \texttt{path\_all}]{Ergebnisse der \texttt{path\_all}-Messung.}
	\label{fig:path_all}
\end{figure}

Es wird deutlich, dass das Prüfen der Erreichbarkeit in beiden GDBMS und in Verbindung mit der verwendeten Hardware ausschließlich auf dem kleinsten Datensatz akzeptable Werte liefert. Eine Verdopplung der Datenmenge führt zu deutlich mehr Ausreißern mit einem Maximalwert von 777 Sekunden  für Titan (auto). Neo4j erreicht unter Verwendung von Gremlin die besten Ergebnisse und ist im kleinsten Datensatz etwa um einen Faktor 10 schneller als die Ausführung mit Cypher. Knoten- und Kantenattribute wurden in dieser Anfrage nicht berücksichtigt, eine Auswirkung der manuellen Typisierung von Kantenbezeichnern in Titan konnte nicht festgestellt werden.

\paragraph*{\texttt{path\_shortest}} Die Anfrage berechnet den kürzesten Pfad zwischen zwei Knoten unter Berücksichtigung definierter Kantenbezeichner und einer gleichzeitigen Beschränkung der maximalen Pfadlänge. Auch hier musste auf Grund begrenzter Hardware-Ressourcen auf die Ausführung der Gremlin-Anfragen in den Testgraphen \texttt{p\_1K} und \texttt{p\_10K} verzichtet werden. Abbildung \ref{fig:path_shortest} stellt die Ergebnisse logarithmisch skaliert in einem Boxplot dar.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{path_shortest.pdf}
	\caption[Benchmark: \texttt{path\_shortest}]{Ergebnisse der \texttt{path\_shortest}-Messung.}
	\label{fig:path_shortest}
\end{figure}

Bei der Formulierung der Cypher-Anfrage wurde die im Rahmen der Sprache angebotene \texttt{shortestPath}-Funktion verwendet. Wie aus der Abbildung hervorgeht, erzielt deren Implementierung im Vergleich die niedrigsten Antwortzeiten, welche sich auch auch bei steigendem Datenvolumen nur geringfügig verschlechtern. Die manuelle Umsetzung der Anfrage in Gremlin führt hingegen in beiden GDBMS zu deutlich höheren Ausführungszeiten und resultiert bereits im kleinsten Datensatz in Ausreißern von bis zu 150 Sekunden.

\paragraph*{\texttt{top\_regions}} Die Anfrage berücksichtigt sowohl die Topologie des Graphen als auch eine Einschränkung der Nutzdaten, die Ergebnisse werden gruppiert und aggregiert sowie anschließend sortiert und limitiert. Für die Darstellung der Messergebnisse wurde das Säulendiagramm gewählt, welches für jede Messreihe den Durchschnittswert und die Standardabweichung der Messwerte visualisiert (Abbildung \ref{fig:top_regions}).

\begin{figure}[h]
	\centering
		\includegraphics[scale=.55]{top_regions.pdf}
	\caption[Benchmark: \texttt{top\_regions}]{Durchschnittliche Antwortzeit und Standardabweichung der \texttt{top\_regions}-Messung.}
	\label{fig:top_regions}
\end{figure}

In der Messung erreicht Neo4j die besten Ergebnisse, in Verbindung mit Cypher sind die Antwortzeiten geringer als bei der Verwendung von Gremlin. Es wird vermutet, dass Cypher ein Sortieren der Ergebnismenge effizienter durchführt, da diese Operation die einzige ist, welche die Anfrage zum Beispiel von \texttt{foaf\_reviews} unterscheidet. Weiter lässt sich feststellen, dass die Antwortzeiten in Neo4j linear mit der Datenmenge skalieren. Die Anzahl zu berücksichtigender Produkte entspricht 1\,852 (\texttt{p\_100}), 12\,831 (\texttt{p\_1K}) und 242\,354 (\texttt{p\_10K}). Am Beispiel von \texttt{p\_1K} und \texttt{p\_10K} entspricht dies einem Faktor von ca. 18, die durchschnittliche Antwortzeit der Anfrage in Neo4j 2.0 steigt von 60 auf 1\,110 Millisekunden (Faktor 18) und in Neo4j 1.9.4 von 80 auf 1\,370 Millisekunden (Faktor 18).\\
Gleiches gilt auch für Titan, hier sind die Antwortzeiten jedoch grundlegend höher, was in diesem Fall auf das GDBMS zurückzuführen ist, da eine identische Gremlin-Anfrage in Neo4j niedrigere Antwortzeiten erzielt. Die Anfrage berücksichtigt Attribute sowohl für die Einschränkung der Produktmenge als auch für die Gruppierung der Ergebnisse. Eine manuelle Typdefinition in Titan führte hierbei nicht zu messbaren Leistungsunterschieden.

%p\_100 1852
%p\_1K	12831 (*7)
%p\_10K 	242354 (*18)
%
%60 -> 1110 (18)
%80 -> 1370 (18)
%
%68 -> 470 (*7)
%68 -> 463 (*7)

\paragraph*{\texttt{sim\_pattern}} Die letzte Anfrage repräsentiert eine komplexe Mustersuche innerhalb des Graphen, bei der eine Überlappung der Nachbarschaft einzelner Knoten berechnet werden muss. Wie Anhang \ref{anh:queries} zu entnehmen ist, sind die Anfragen in beiden Sprachen im Vergleich zu den bisherigen Anfragen deutlich umfangreicher. Da sich die Ergebnismengen je nach ausgewähltem Startknoten unterscheiden können, wurde auch hier die Boxplot-Darstellung gewählt (Abbildung \ref{fig:sim_pattern}).

Es wird deutlich, dass die Antwortzeiten mit steigender Datenmenge in beiden GDBMS konstant bleiben. Die Antwortzeiten mit Cypher sind hierbei um einen Faktor von ca. $10^3$ langsamer als die Ausführung mittels Gremlin. Bei der Messung im größten Datensatz treten in beiden Systemen Ausreißer auf, was folglich auf die Anfrageverarbeitung von Gremlin bzw. auf eine nicht-optimale Anfrageformulierung zurückzuführen ist. Ein Leistungsunterschied bei der Verwendung manuell typisierter Attributschlüssel und Kantenbezeichner konnte nicht festgestellt werden. Insgesamt betrachtet ist dies die einzige Anfrage, bei der Titan minimal besser abschneidet als Neo4j.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=.55]{sim_pattern.pdf}
	\caption[Benchmark: \texttt{sim\_pattern}]{Ergebnisse der \texttt{sim\_pattern}-Messung.}
	\label{fig:sim_pattern}
\end{figure}

\paragraph*{Gesamtergebnis}

Beide GDBMS erzielen Antwortzeiten, die in einem für das Forschungsprojekt akzeptablen Bereich liegen, die besten Ergebnisse für fast alle Anfragen erreicht Neo4j in Verbindung mit Gremlin, der Vorsprung zu Titan ist dabei oft nur minimal. Hervorzuheben ist die lineare Skalierbarkeit beider Systeme bei steigendem Datenvolumen, wobei sich Neo4j für größere Datenmengen besser zu eignen scheint, da die Messwerte bei Anfragen auf dem größten Datensatz näher zusammenliegen und Ausreißer im Vergleich seltener und generell schwächer sind. Dies ist auf die Verwendung von BerkeleyDB als Speichersystem zurückzuführen, die Ergebnisse können folglich für andere Speichersysteme variieren.\\
Das Prüfen der Erreichbarkeit ist in beiden Systemen grundsätzlich möglich, erfordert aber je nach Datenumfang entsprechende Hardware-Ressourcen, generell sollte die Nutzung systemseitiger Funktionen wie z.B. \texttt{shortestPath} einer eigenen Implementierung vorgezogen werden, da sich hierdurch - wie auch gezeigt wurde - deutlich geringere Antwortzeiten erreichen lassen. Die Suche nach dem kürzesten Pfad ist die Grundlage für komplexere, analytische Graphalgorithmen, Cypher weist durch die Integration der Funktion gegenüber Gremlin einen wesentlichen Vorteil auf.

Neben der Suche nach dem kürzesten Pfad erzielte Cypher nur bei der Ausführung von \texttt{top\_region} bessere Ergebnisse als Gremlin, allgemein betrachtet ist die gremlin-basierte Ausführung jedoch deutlich performanter, die Messwerte unterscheiden sich dabei um einen Faktor von ca. 20 bis $10^3$. Das im Vergleich schlechte Antwortzeitverhalten von Cypher gegenüber Gremlin wurde bereits in den verwandten Arbeiten festgestellt und ist noch immer aktuell. Laut Neo Technologies sind nach der Veröffentlichung von Version 2.0 umfangreiche Optimierungen für Cypher geplant.\footnote{Dies ergab eine Rückfrage im November 2013 per Email an Philip Rathle, dem Senior Director of Products von Neo Technologies.}\\
Titan erreicht im Vergleich ebenfalls akzeptable Werte, erzielte aber insbesondere bei topologischen Anfragen auf dem größten Datensatz schlechtere Ergebnisse als Neo4j mit teilweise deutlichen Ausreißern. Ob dies aus einer nicht-optimalen Anfrageformulierung, der Anfrageausführung in Gremlin, Titan oder BerkeleyDB resultiert, lässt sich nicht eindeutig feststellen. Eine manuelle Typisierung von Attributschlüsseln und Kantenbezeichnern führte nur in einer Anfrage zu messbaren Verbesserungen, diese waren jedoch minimal. Es wird vermutet, dass sich die manuelle Typisierung bei Verwendung eines KCV-Speichersystems eher auswirkt, da in diesem Fall alle Nutzdaten und Kanteninformationen innerhalb eines Datensatzes gespeichert sind und nicht getrennt voneinander, wie es bei der Verwendung von BerkeleyDB der Fall ist.

Neben der reinen Leistungsfähigkeit bei der Ausführung analytischer Anfragen sollte auch die Anfrageformulierung in Cypher und Gremlin bewertet werden. Alle Anfragen konnten in beiden Sprachen umgesetzt und dabei eine annähernd identische Struktur der Ergebnismenge erreicht werden, unter ausschließlicher Berücksichtigung der formulierten Anfragen sind die Sprachen somit gleich mächtig. Subjektiv betrachtet lässt sich feststellen, dass das Formulieren graphenspezifischer Anfragen in einer deklarativen Sprache wie Cypher im Vergleich zu einer imperativen Sprache wie Gremlin einfacher ist. Durch die Kombination aus graphenspezifischer Musterdefinition und SQL-ähnlichen Filterkriterien, lassen sich in Cypher sowohl einfache Traversierungen als auch komplexere Mustersuchen, Aggregationen und Transformationen realisieren. Gremlin eignet sich ebenfalls sehr gut für lokale Traversierungen, erfordert hingegen bei komplexeren Anfragen zusätzliche Datenstrukturen zur Zwischenspeicherung und bedarf dem Formulieren mehrerer Anweisungen in einem Gremlin-Skript um identische Informationen abfragen zu können. Die Lesbarkeit der Anfragen und deren Wartbarkeit bei eingebetteter Verwendung  wird hierdurch stark eingeschränkt. Für Programmierer sind beide Sprachen für die Analyse von Graphen geeignet, Analysten mit SQL- und wenig Programmiererfahrung werden vermutlich Cypher bevorzugen. Zu beachten ist auch, dass das Formulieren in Gremlin ein hohes Maß an manueller Optimierung erfordert, während es eine deklarative Sprache dem Datenbanksystem überlässt, wie die Anfrage letztendlich ausgeführt wird und somit Raum für Anfrageoptimierung bietet.