\section{HyperGraphDB}

HyperGraphDB ist ein quelloffenes GDBMS, das von Kobrix Software\footnote{\url{http://kobrix.com/index.jsp}} entwickelt wird. Die Quellcode-Lizenz ist GNU LGPL\footnote{Die Lizenz erlaubt die Verwendung in freier und kommerzieller Software. Die Verwendung in kommerzieller Software verlangt nicht, dass diese ebenfalls quelloffen sein muss: \url{http://www.gnu.org/licenses/lgpl-3.0.de.html}.}, die erste stabile Version 1.0 wurde 2010 veröffentlicht. Die Implementierung des Systems erfolgt ausschließlich in Java und sieht den Einsatz als eingebettetes Graphdatenbanksystem vor. Modellierung und Verwendung der Daten erfolgen graphenorientiert, die Speicherung ist jedoch nicht-nativ: Der Graph wird auf eine Menge assoziativer Arrays abgebildet, für deren Speicherung eine beliebige, entsprechend optimierte Speicherlösung eingesetzt werden kann. Standardmäßig nutzt HyperGraphDB hierfür die quelloffene, disk-orientierte Key-Value-Datenbank BerkeleyDB Java Edition\cite{Oracle_BerkeleyDB:2013}. Die Nutzung des Hauptspeichers als primäres Speichermedium ist bei Verwendung einer entsprechenden Speicherschicht möglich, HyperGraphDB bietet hierfür jedoch keine Implementierung an. Das GDBMS kann als zentrales System, aber auch in einer verteilten Konfiguration eingesetzt werden.

Grundlegend betrachtet handelt es sich bei HyperGraphDB um ein objektorientiertes Persistenz-Framework zur dauerhaften Speicherung von Java-Objektinstanzen. Die Repräsentation der Daten im Hauptspeicher, die Indexierung und das Caching sind jedoch für die effiziente Traversierung ausgelegt. Wesentliche Eigenschaft des GDBMS und gleichzeitig Alleinstellungsmerkmal innerhalb der Evaluation ist die Möglichkeit zur Modellierung n-ärer Beziehungen: Als Datenmodell wird ein erweitertes Property-Hypergraph-Modell in Verbindung mit einem flexiblen Typsystem eingesetzt.\\
Konzipiert wurde das GDBMS für die Verwaltung hochkomplexer Daten, wie sie zum Beispiel in der Wissensrepräsentation auftreten\cite{Iordanov:2010:HGG:1927585.1927589}. Laut Hersteller eignet sich das System darüber hinaus für die Verwaltung sozialer Netzwerke und für den Einsatz in klassischen objektorientierten Geschäftsanwendungen\cite{HGDB_business_applications:2012}. Ein weiteres wichtiges Merkmal ist die offene Architektur, welche die Implementierung und Integration eigener Anfrage-,  Indizierungs-, Persistenz- und Verteilungsmechanismen ermöglicht.

Die nachfolgenden Ausführungen beziehen sich auf die im November 2012 veröffentlichte Version 1.2 des GDBMS. Der Großteil der Informationen stammt aus der offiziellen Dokumentation\cite{hypergraph_db_docu:2013} und der primären Publikation zu HyperGraphDB\cite{Iordanov:2010:HGG:1927585.1927589}, weitere Quellen werden an entsprechender Stelle aufgeführt.

\subsection{Datenmodell und Typsystem}

% Modelltheorie
Die Basiseinheit zur Darstellung von Informationen innerhalb des Datenmodells ist das \textit{Atom}. Jedem Atom ist ein aus weiteren Atomen bestehendes Tupel zugeordnet, welches als \textit{Zielmenge} bezeichnet wird. Die Kardinalität der Zielmenge ist die \textit{Arität}: Ein Atom mit Arität Null ist ein Knoten, wohingegen ein Atom mit einer Arität größer Null eine Kante repräsentiert.\footnote{Die Begriffe Kante und Hyperkante werden bei der Beschreibung von HyperGraphDB synonym verwendet.} Eine Kante kann folglich auf eine beliebige Anzahl von Atomen verweisen. Dies stellt eine Erweiterung des in Abschnitt \ref{subsec:hgm} definierten Hypergraph-Modells dar, da eine Kante in HyperGraphDB sowohl auf Knoten, als auch auf andere Kanten verweisen kann. Im Datenmodell werden Beziehungen zwischen Beziehungen als Relationen höherer Ordnung bezeichnet. Die \textit{Inzidenzmenge} eines Atoms $a$ ist die Menge aller Atome, die $a$ in ihrer Zielmenge enthalten, d.h. die Menge aller gerichteter Kanten, die auf $a$ zeigen. An dieser Stelle wird deutlich, dass es sich um eine nicht-native Verarbeitung handelt, da ausgehend von einem Knoten nicht direkt auf dessen Nachbarschaft zugegriffen werden kann. Es muss zunächst festgestellt werden, in welchen Zielmengen der entsprechende Knoten enthalten ist. Wie nachfolgend gezeigt wird, setzt HyperGraphDB hierfür Indexstrukturen ein.

Neben der Zielmenge ist jedem Atom genau ein typisierter Wert zugeordnet. Der Typ ist beliebig und wird wie reguläre Daten innerhalb der Datenbasis als Atom gespeichert. Folglich können sowohl Beziehungen zwischen Typen untereinander als auch zwischen Typen und ihren Instanzen abgebildet und in Operationen verwendet werden. Daraus geht hervor, dass Atome die Struktur und auch die Semantik des Graphen abbilden. Die Werte entsprechen den Nutzdaten, sie können beliebig strukturiert oder unstrukturiert sein und zur Laufzeit durch Werte eines anderen Typs ausgetauscht werden. Damit lassen sich Semantik und Struktur unabhängig voneinander ändern, was der Schemaevolution innerhalb einer Anwendung entspricht und somit eine vergleichbare Flexibilität wie zum Beispiel Neo4j bietet.

\paragraph*{Typsystem} Aus Anwendungssicht ist es die wesentliche Aufgabe eines Typen die Semantik der Daten zu beschreiben. Aus Systemsicht hingegen ist es die Serialisierung von Laufzeitobjekten in das Format der darunterliegenden Speicherschicht sowie die umgekehrte Deserialisierung. Im Sinne der Objektorientierung ist ein Typ somit eine abstrakte Fabrik und stellt Methoden zum Erzeugen, Speichern und Löschen von Laufzeitrepräsentationen seiner Instanzen zur Verfügung.\footnote{Das Aktualisieren eines Wertes ist nicht möglich, da Werte in HyperGraphDB generell unveränderlich (engl. \textit{immutable}) sind. Dies hat den Vorteil, dass ein Wert mehreren Atomen zugeordnet sein kann, führt jedoch dazu, dass bei der Aktualisierung eines Wertes ein neuer Wert erzeugt werden muss.} Da es sich bei Typen um Atome handelt, besitzen auch diese einen übergeordneten Datentyp. Für jene, die bereits im Typsystem existieren, ist dies ein systemseitiger Datentyp mit der Bezeichnung \texttt{Top}. Wird hingegen ein Objekt, dessen Typ nicht bereits in der Datenbasis hinterlegt ist, zur Laufzeit eingefügt, so ist dessen Typ ein Typkonstruktur. Dieser erzeugt neue Typen aus bestehenden, es handelt sich folglich um einen Datentyp, dessen Instanzen ebenfalls Datentypen sind.\\
Neben den genannten Operationen stellt ein Typ eine weitere Operation zur Verfügung: Das Subsumieren. Eine Instanz A subsumiert eine Instanz B genau dann, wenn A allgemeiner ist als B bzw. wenn B immer dann verwendet werden kann, wenn auch A verwendet werden kann\cite{HGDB_subsume:2013}. Damit wird zum Beispiel geprüft, ob sich zwei Instanzen gegenseitig enthalten und folglich gleichwertig sind oder ob eine Instanz durch die andere ersetzt werden kann. Handelt es sich bei den Instanzen um Typen, so ermöglicht die Subsumierung die Abbildung von Vererbungshierarchien und somit die Konstruktion beliebiger Typsysteme: Wenn eine Instanz A eine zweite Instanz B subsumiert und A und B Typen sind, so erbt A von B.

Aus den Ausführungen sollte hervorgehen, dass ein Typ in HyperGraphDB ein Atom mit einer speziellen Rolle ist. Aus Anwendungssicht ermöglicht es die Definition von Knoten- und Kantenbezeichnern sowie das Speichern von Nutzdaten, aus Systemsicht die Verwaltung von Assoziationen sowohl zwischen einem Typ und seinen Instanzen als auch zwischen mehreren Typen. Das GDBMS beinhaltet vordefinierte Typimplementierungen für primitive Datentypen, JavaBeans\footnote{JavaBeans wurden für den standardisierten Datenaustausch zwischen Softwarekomponenten entwickelt. Es handelt sich um Klassen, die einen öffentlichen Standardkonstruktur besitzen, serialisierbar sind sowie öffentliche Getter und Setter für den Zugriff auf ihre Eigenschaften anbieten (\url{http://www.oracle.com/technetwork/java/javase/documentation/spec-136004.html}).}, 
Arrays, Collections und Maps.\footnote{Eine vollständige Übersicht befindet sich im Quelltext des GDBMS unter \url{https://code.google.com/p/hypergraphdb/source/browse/tags/release1.2/core/src/config/org/hypergraphdb/types}} Vererbungshierarchien werden ebenfalls persistiert und durch einen dedizierten Kantentyp repräsentiert. Sollen komplexere Datentypen verwendet werden oder ist die Einhaltung der JavaBeans-Spezifikation nicht möglich, lassen sich eigene Datentypen implementieren. Diese werden im Typsystem des GDBMS registriert, anschließend lassen sich deren Instanzen in der Datenbasis verwalten.\\
Ein Typsystem erlaubt die Definition von Integritätsbedingungen und das GDBMS sorgt durch deren Einhaltung für die Wahrung der Konsistenz. So lässt sich zum Beispiel die Zielmenge entsprechend typisierter Kanten auf definierte Typen einschränken, darüber hinaus ist das Definieren von Wertebereichen und Kardinalitäten möglich.

% eine oder mehrere Datenbanken
In HyperGraphDB existieren aus Anwendungssicht keine Primärschlüssel, die Identität eines Atoms wird durch die Instanz eines sog. Handle repräsentiert. Dessen Funktion wird im Zusammenhang mit den Zugriffsmechanismen näher erläutert.

\subsection{Zugriffsmechanismen}

HyperGraphDB bietet keine dedizierte Anfragesprache, sondern erlaubt den Zugriff auf die Datenbasis ausschließlich via Java API im eingebetteten Betrieb. Unter ihrer Verwendung sind CRUD- und mengenorientierte Operationen sowie die Traversierung des Graphen möglich.

\paragraph*{CRUD-Operationen via Java API}

Das GDBMS bietet grundlegende Funktionen zum Erzeugen, Auslesen und Löschen von Atomen an. Da Werte innerhalb der Datenbasis unveränderlich sind, erfolgt das Aktualisieren ausschließlich über den Austausch von Werten.

%Knoten
Ein Knoten definiert sich innerhalb der Laufzeitumgebung durch eine Objektinstanz. Diese lässt sich dem Graphen hinzufügen: Ist ihr Datentyp bereits im Typsystem registriert, wird er automatisch mit dem Knoten verbunden, andernfalls zunächst durch einen Typkonstruktor erzeugt. Das Resultat des Anlegens ist ein Handle, welches den Knoten innerhalb der Datenbasis identifiziert. Anhand des Handles kann die Objektinstanz und deren Typ aus der Datenbasis gelesen werden, umgekehrt lässt sich unter Angabe der Objektinstanz das zugehörige Handle laden. Das Löschen eines Atoms ist ausschließlich unter Angabe des zugehörigen Handles möglich.\\
Unter Verwendung des flexiblen Typsystems und den vorhandenen Typimplementierungen lassen sich beliebige Nutzdaten an einem Knoten speichern. Wird zum Beispiel ein JavaBeans-Objekt dem Graphen hinzugefügt, wird dieses intern durch eine Record-Struktur repräsentiert, die den schlüsselbasierten Zugriff auf die Attribute des Objektes ermöglicht. Da Attribute wiederum typisierte Werte sind, lassen sich beliebig verschachtelte Objekte hinterlegen.

%Kanten
Kanten werden in HyperGraphDB nicht durch Referenzen zwischen Objektinstanzen modelliert, sondern durch spezielle Kantenobjekte, diese sind Implementierungen der Schnittstelle \texttt{HGLink}. Das GDBMS stellt drei Implementierungen zur Verfügung: Kanten können ohne jegliche Zusatzinformationen, zum Beispiel ohne eine semantische Bedeutung oder ohne Nutzdaten, angelegt werden. Eine zweite Implementierung erlaubt das Speichern von Nutzdaten, dies können beliebig komplexe Objektinstanzen oder einfache Zeichenketten zur Festlegung eines Kantenbezeichners sein. Ein dritter Typ ermöglicht zudem das Festlegen zulässiger Typen innerhalb der Zielmenge und gestattet damit die Definition von Integritätsbedingungen.\\
Kanten werden unter Angabe ihrer Zielmenge und eventueller Nutzdaten erzeugt und anschließend mittels Handle identifiziert, Auslesen und Löschen erfolgen wie bereits für Knoten beschrieben. Kanten bieten darüber hinaus Funktionen zum Lesen der Zielmenge und der Arität an. Da die Zielmenge ein Tupel und somit geordnet ist, können Handles unter Angabe ihrer Position innerhalb der Zielmenge ausgelesen werden. Dies ermöglicht die Definition von Kantentypen, in denen den einzelnen Positionen innerhalb der Zielmenge eine Semantik zugeordnet ist. Ein Beispiel für das Erzeugen von Knoten und Kanten findet sich in Anhang \ref{list:hgdb_api_example}.

\paragraph*{Mengenorientierte Operationen via Java API}

Neben dem Auslesen von Atomen unter Angabe ihres Handles bietet HyperGraphDB die Möglichkeit, deklarative, mengenorientierte Anfragen an die Datenbasis zu stellen. Die hierfür vorhandene API basiert auf der Definition von Prädikaten zur Einschränkung der Ergebnismenge. Prädikate lassen sich konjunktiv bzw. disjunktiv verknüpfen sowie beliebig schachteln und negieren. Sie beziehen sich entweder auf den Wert eines Atoms oder auf die Topologie des Graphen. Die folgende Anfrage definiert zum Beispiel die Menge aller Mitarbeiter, deren Attribut \texttt{age} kleiner oder gleich dem Wert 25 ist:

\texttt{hg.and(hg.type(Employee.class), hg.gte(\string"age\string", 25))}.

\texttt{hg} ist eine vom GDBMS bereitgestellte Klasse, welche syntaktisch verkürzte, einfache Methoden für das Formulieren von Anfragen anbietet und diese intern auf eine komplexere API abbildet.\footnote{Die zugrundeliegende API wird an dieser Stelle nicht beschrieben, weil die Methoden der Klasse \texttt{hg} für die Erläuterung ausreichend sind. Weiterführende Informationen sind in der offiziellen Dokumentation enthalten\cite{hypergraph_db_docu:2013}.} In der Anfrage werden die Prädikate \texttt{hg.type(Employee.class)} und \texttt{hg.gte(\string"age\string", 25)} durch den logischen Operator \texttt{hg.and} konjunktiv verknüpft.\footnote{Die Methode \texttt{hg.and} nimmt eine variable Anzahl Argumente entgegen, die Menge der an einer Konjunktion beteiligten Prädikate ist somit nicht beschränkt.} Das erste Prädikat legt den Typ des Atoms auf Mitarbeiter fest, während das zweite den Attributwert einschränkt.\footnote{Die Methode \texttt{hg.gte} beschreibt eine $\geq$-Relation (engl. \textit{greater than or equal to}).} \texttt{Employee} ist im Beispiel eine Klasse nach JavaBeans-Spezifikation.

Neben den Werten lässt sich auch die Topologie des Graphen in einer Anfrage durch Prädikate beschreiben. Das folgende Beispiel definiert die Menge aller Kanten, die zwei gegebene Atome in ihrer Zielmenge enthalten und insgesamt zehn Atome verbinden:

\texttt{hg.and(hg.link(atom1, atom2), hg.arity(10))}.

Im vorhergehenden Abschnitt wurde das Speichern eines Typs innerhalb der Datenbasis beschrieben: Vererbungshierarchien werden durch Subsumierung von Typen ausgedrückt, diese Beziehung lässt sich folglich auch innerhalb von Anfragen verwenden. Nachfolgend wird die Menge aller Atome definiert, deren Datentyp von einer Klasse \texttt{Person} erbt und deren Instanzen nicht 25 Jahre alt sind:

\texttt{hg.and(hg.subsumes(Person.class), hg.not(hg.eq(\string"age\string", 25)))}.

Es handelt sich demnach um eine Anfrage, in die Topologie, Semantik und auch Nutzdaten des Graphen einbezogen werden. Neben den gezeigten Operatoren stehen weitere zum Vergleich von Werten, zur Einschränkung von Typbeziehungen und zur Beschreibung der Topologie zur Verfügung.

Für das Auslesen der Ergebnismenge werden drei Methoden angeboten. Grundsätzlich wird ein Iterator erzeugt, mit dem sich die Ergebnismenge bi-direktional durchlaufen lässt, der Wert eines Atoms wird erst beim Zugriff geladen. Die direkte Verwendung des Iterators bietet sich insbesondere bei umfangreichen Ergebnismengen an. Alternativ stellt die Klasse \texttt{hg} zwei Methoden zur Verfügung, mit denen sich entweder die vollständig deserialisierten Objektinstanzen oder nur deren Handles in einer Liste zurückgeben lassen.\\
Optional kann innerhalb einer Anfrage eine Abbildung definiert und mittels \texttt{hg.apply} auf die Ergebnismenge angewendet werden. Die Abbildung ermöglicht die Realisierung einer Projektion, für den Fall, dass nur bestimmte Attribute der Atomwerte ausgegeben werden sollen. Zusätzlich kann eine Transformation der Elemente erfolgen. Für eine Aggregation der Ergebnismenge stehen außer \texttt{hg.count} keine Operatoren zur Verfügung, sie müssten folglich bei Bedarf selbst implementiert werden. Ein Beispiel für die Verwendung der mengenorientierten API und das Auslesen der Ergebnismenge findet sich in Anhang \ref{list:hgdb_query_example}.

An dieser Stelle sei auf die offene Architektur des GDBMS hingewiesen: Neue Operatoren lassen sich durch das Implementieren der Schnittstellen \texttt{HGAtomPredicate} und \texttt{HGQueryCondition} hinzufügen. Dies erlaubt das Definieren beliebiger domänenspezifischer Operatoren im Rahmen des beschriebenen Forschungsprojektes. Ein Beispiel hierfür ist das Prüfen, ob eine gegebene Kante eine kausale Abhängigkeit beschreibt, was genau dann der Fall ist, wenn alle in der Zielmenge vorhandenen Typen einen Datentyp zur Beschreibung transaktionaler Daten subsumieren.

\paragraph*{Traversierung via Java API}

Vergleichbar zu Neo4j steht in HyperGraphDB eine Menge von Schnittstellen zur Verfügung, mit der sich eine Traversierung innerhalb der Datenbasis beschreiben lässt. Die Reihenfolge, in der ein Graph durchlaufen wird, kann durch die Implementierung der Schnittstelle \texttt{HGTraversal} festgelegt werden. Es handelt sich um einen Iterator, dessen Elemente Paare von Handles sind. Jedes Paar besteht aus einer Kante und einem Atom, auf welches die Kante zeigt. Die Schnittstelle kann darüber hinaus prüfen, ob ein Handle bereits während der Traversierung besucht wurde. HyperGraphDB stellt zwei Implementierungen der Schnittstelle zur Verfügung: \texttt{HGBreadthFirstTraversal} für einen Breitendurchlauf und \texttt{HGDepthFirstTraversal} für einen Tiefendurchlauf. 

Neben der Festlegung einer Reihenfolge kann es notwendig sein, die Menge der relevanten Paare einzuschränken. Hierfür stellt HyperGraphDB die Schnittstelle \texttt{HGALGenerator} zur Verfügung. Diese Schnittstelle ermöglicht es, eine Adjazenzliste (AL) zu generieren, welche jene Paare enthält, die, ausgehend von einem Atom, bei der Traversierung berücksichtigt werden sollen. Auch hier stellt das GDBMS zwei Implementierungen zur Verfügung. Der \texttt{SimpleALGenerator} erzeugt Adjazenzlisten aller benachbarter Atome ohne Berücksichtigung von Kanten- und Knotentypen bzw. deren Werten. Deutlich flexibler ist hingegen der \texttt{DefaultALGenerator}; unter Verwendung der bereits beschriebenen Prädikate lassen sich sowohl Bedingungen für Kanten, als auch für Knoten\footnote{Semantisch korrekt wäre hier die Bezeichnung Geschwister, da eine Adjazenz auch zwischen Kanten definiert sein kann.} definieren. Das folgende kurze Beispiel veranschaulicht dies:

\texttt{DefaultALGenerator alGen = new DefaultALGenerator(graph,\newline
		hg.and(hg.type(WorksWith.class), hg.gte(\string"since\string", 2010)), // edge predicate \newline
		hg.and(hg.type(Person.class), hg.eq(\string"region\string", \string"Leipzig\string"))); // node predicate}
		
Es wird festgelegt, dass ausschließlich jene Kanten traversiert werden, die vom Typ \texttt{WorksWith} sind und deren repräsentierte Beziehung seit 2010 besteht. Die Beziehung selbst soll nur zu Knoten bestehen, die vom Typ \texttt{Person} sind und aus der Region Leipzig stammen. Alle Unterklassen werden durch das Prädikat ebenfalls berücksichtigt.\\
Beide Implementierungen von \texttt{HGALGenerator} verbieten das mehrfache Besuchen von Knoten, d.h. wenn mehrere Paare aus unterschiedlichen Kanten und dem gleichen Knoten existieren, wird nur eines dieser Paare berücksichtigt. Letzteres kann durch eine eigene Implementierung umgangen werden. Ein vollständiges Beispiel, welches den \texttt{DefaultALGenerator} verwendet, findet sich in Anhang \ref{list:hgdb_traversal_example}.

Sind Reihenfolge und eventuelle Einschränkungen definiert, wird die Traversierung unter Angabe eines Start-Handles initialisiert und gestartet. Während der Ausführung werden die relevanten Paare elementweise betrachtet. Dabei stehen im Unterschied zu Neo4j keine Instanzen bereits berechneter Wege zur Verfügung. Das Berechnen des aktuellen Abstands vom Startknoten oder das Speichern berechneter Wege muss bei Bedarf manuell erfolgen.\\
Zur Berechnung kürzester Pfade steht eine Implementierung des Dijkstra-Algorithmus zur Verfügung. Diese erfordert mindestens die Angabe eines Start- und eines Zielhandle. Darüber hinaus können optional ein \texttt{HGALGenerator} und nicht-negative Kantengewichte in Form eines assoziativen Arrays definiert werden. Soll der Ergebnispfad rekonstruierbar sein, so erfordert dies die Übergabe eines assoziativen Arrays, das jedem Handle innerhalb des Pfades seinen jeweiligen Vorgänger zuordnet.

%\input{Inhalt/HGDB_Transactions}

\subsection{Persistenz-, Index- und Cacheverwaltung}

Wie eingangs erwähnt, ist HyperGraphDB ein nicht-natives GDBMS, welches den Graphen auf assoziative Arrays abbildet und diese im Rahmen der Anfrageausführung und der physischen Repräsentation der Datenbasis verwendet. Die Organisation erfolgt dabei innerhalb des GDBMS in zwei Schichten: Der primitiven Speicherschicht, welche direkt auf das eingesetzte Speichersystem zugreift, und der Modellschicht, welche von der primitiven Speicherschicht abstrahiert und die darin enthaltenen Informationen als Elemente des Datenmodells darstellt. Das eingesetzte Speichersystem wird nachfolgend als physische Speicherschicht bezeichnet, da es letztendlich die Persistenz der Daten sicherstellt.

Die primitive Speicherschicht repräsentiert einen Graphen bestehend aus Identitäten und ihnen zugeordneter Rohdaten, eine semantische Zuordnung findet in dieser Schicht nicht statt. Für die Speicherung werden zwei assoziative Arrays verwendet:

\texttt{LinkStore: ID $\rightarrow$ List<ID>}\newline
\texttt{DataStore: ID $\rightarrow$ byte[]}

Der \texttt{LinkStore} bildet die Topologie des Graphen ab, indem er Identitäten (IDs) eine Liste weiterer Identitäten zuordnet. Im \texttt{DataStore} werden einer Identität Rohdaten in Form eines Byte-Arrays zugewiesen. Jeder Datensatz in der primitiven Speicherschicht ist folglich ein Schlüssel-Wert-Paar. Der Schlüssel wird in HyperGraphDB durch ein spezielles Handle repräsentiert, das sog. \texttt{HGPersistentHandle}. Dieses ordnet jeder Entität eine UUID fester Länge zu. Innerhalb der primitiven Speicherschicht ist somit der \texttt{LinkStore} eine Liste von Instanzen des genannten Handles.

Die Modellschicht wandelt die Informationen der primitiven Speicherschicht in die abstrakten Elemente des Datenmodells um. Nachfolgend sind alle ID-Bezeichner als Instanzen von \texttt{HGPersistentHandle} zu verstehen. Ein Eintrag im \texttt{LinkStore} wird in der Modellschicht entweder als Atom oder als Wert eines zusammengesetzten, nicht-primitiven Datentyps interpretiert.

\texttt{AtomID $\rightarrow$ [TypeID, ValueID, TargetID, ..., TargetID]}\newline
\texttt{ValueID $\rightarrow$ [ID, ID, ..., ID] | byte[]}\newline
\texttt{TypeID $\rightarrow$ AtomID}\newline
\texttt{TargetID $\rightarrow$ AtomID}

Im ersten Fall verweist die \texttt{TypeID} auf den Typ des Atoms während die \texttt{ValueID} den zugehörigen Wert referenziert. Anschließend wird die Zielmenge des Atoms aus einer Menge von \texttt{TargetIDs} definiert. Da ein Knoten im Datenmodell ein Atom mit Arität Null ist, enthält seine physische Repräsentation, im Gegensatz zu einer Kante, nur den Verweis auf seinen Typ und den Wert. Da sowohl der Typ eines Atoms als auch die Einträge in der Zielmenge Atome sind, referenzieren \texttt{TypeID} und \texttt{TargetID} eine \texttt{AtomID}.\\
Alternativ repräsentiert ein Eintrag im \texttt{LinkStore} den Wert eines zusammengesetzten, nicht-primitiven Datentyps und wird mittels \texttt{ValueID} referenziert. Wird hingegen nur der Wert eines primitiven Datentyps am Atom gespeichert, verweist die \texttt{ValueID} direkt auf das entsprechende Byte-Array im \texttt{DataStore}. An dieser Stelle wird deutlich, warum Werte an Atomen grundsätzlich unveränderlich sind und eine Wertänderung nur durch den Austausch des Wertes erfolgen kann.

Die Deserialisierung der Werte erfolgt nicht in der Modellschicht, sondern wird von der jeweiligen Typimplementierung bzw. vom jeweiligen Typkonstruktur durchgeführt. Im Zusammenhang mit dem Typsystem wurde bereits erwähnt, dass Typen abstrakte Fabriken sind und u.a. eine Methode zur Erzeugung der entsprechenden Instanzen bereitstellen. Diese Methode nimmt die \texttt{ValueID} entgegen und führt die Deserialisierung durch.\footnote{Dies lässt sich im Quelltext des \texttt{HGAtomType} nachvollziehen: \url{https://code.google.com/p/hypergraphdb/source/browse/tags/release1.2/core/src/java/org/hypergraphdb/type/HGAtomType.java}, Zeile 65.}

In der physischen Speicherschicht (BerkeleyDB) werden die Werte von \texttt{LinkStore} und \texttt{DataStore} als Byte-Arrays abgelegt. Die Deserialisierung der Identitäten erfolgt in der primitiven Speicherschicht, ermöglicht wird dies durch die feste Länge der UUIDs. Die Byte-Arrays im \texttt{DataStore} können erst in der Modellschicht deserialisiert werden, da erst hier Informationen zum Datentyp vorhanden sind. Die Schlüsselmengen von \texttt{LinkStore} und \texttt{DataStore} können sich überlappen und werden somit in zwei getrennten Key-Value-Datenbanken gespeichert.

% Index

\paragraph*{Indexverwaltung}

Für die effiziente Ausführung mengenorientierter und traversierender Anfragen enthält die Modellschicht drei zusätzliche Indexstrukturen, welche jeweils in einer Key-Value-Datenbank persistiert werden:

\texttt{IncidenceIndex: UUID $\rightarrow$ SortedSet<UUID>}\newline
\texttt{TypeIndex: UUID $\rightarrow$ SortedSet<UUID>}\newline
\texttt{ValueIndex: UUID $\rightarrow$ SortedSet<UUID>}

Der \texttt{IncidenceIndex} ordnet jedem Atom seine Inzidenzmenge zu, d.h. die Menge aller Kanten, welche auf das Atom zeigen. Der \texttt{TypeIndex} verweist auf die Menge aller Instanzen eines gegebenen Datentyps und der \texttt{ValueIndex} weist einem Wert die Menge der Atome zu, die ihn besitzen. Bei zusammengesetzten Werten wird der Wert auf höchster Ebene indexiert. Zu beachten ist, dass die referenzierten Werte geordnete Mengen sind. Auf ihnen lassen sich Mengenoperationen effizient ausführen, zum Beispiel kann man anhand der Schnittmenge der Inzidenzlisten zweier Knoten prüfen, ob diese adjazent sind. Am genannten Beispiel wird deutlich, dass auch die Traversierung von der Indexierung profitiert.

Neben den systemseitigen Indexstrukturen können von der Anwendung zusätzliche Indizes definiert werden. Mit diesen ist das Indexieren der Topologie des Graphen und der hinterlegten Nutzdaten möglich. Indizes sind immer an einen Typ gebunden, gelten jedoch für alle Typen, welche diesen subsumieren. Auch im Zusammenhang mit Indexstrukturen wird die offene Architektur des GDBMS deutlich: Das Implementieren der Schnittstelle \texttt{HGIndexer} ermöglicht das Hinzufügen eigener Datenstrukturen. HyperGraphDB beinhaltet bereits Implementierungen zur Indexierung der Attribute eines Datentyps und zur Indexierung vollständiger Werte eines Atoms. Für den effizienten Zugriff auf Teilgraphen ermöglicht eine weitere Implementierung die Indexierung der kompletten Zielmenge eines Atoms. Ein weiterer topologischer Index indexiert Kanten anhand eines Atoms an einer expliziten Position innerhalb der Zielmenge. Wie bereits erwähnt wurde, ist diese geordnet, die Positionen können somit anwendungsseitig mit einer Semantik versehen werden.

Es wurde gezeigt, dass HyperGraphDB mindestens fünf Key-Value-Datenbanken zur Abbildung der primitiven Speicherschicht und der obligatorischen Indexstrukturen einsetzt. Für jeden anwendungsseitig definierten Index wird eine zusätzliche Datenbank benötigt. Die Komplexität der einzelnen Operationen ist dabei im Wesentlichen von der Implementierung des Speichersystems abhängig. BerkeleyDB bildet eine Datenbank innerhalb eines B-Baumes ab. Es handelt sich um eine spezielle Form, in der Nutzdaten ausschließlich in den Blättern hinterlegt sind. Der Zugriff auf diese Daten ist somit logarithmisch von der Anzahl der Einträge und der Ordnung des Baumes abhängig\cite{ottmann2002algorithmen}. Die indexfreie Adjazenz hingegen ist nur möglich, wenn sich die Daten in konstanter Zeit lesen lassen. BerkeleyDB verfügt über Caches um den Zugriff auf die Datenbasis zu beschleunigen\cite{oracle_bdb:2013}. Da es sich jedoch um ein austauschbares Speichersystem handelt, wird nachfolgend nur die Cacheverwaltung von HyperGraphDB beschrieben.

% Caching

\paragraph*{Cacheverwaltung}

Für den performanten, wahlfreien Zugriff auf die Elemente innerhalb des Graphen bietet auch HyperGraphDB Caches an, den Atom-Cache und einen Cache für Inzidenzmengen. Der Atom-Cache ermöglicht den beschleunigten Zugriff auf Objektinstanzen und deren Handles. Realisiert wird der Cache durch zwei Hashtabellen und die Verwendung schwacher Referenzen. Letztere zeichnen sich dadurch aus, dass sich die von ihnen referenzierten Objektinstanzen vom Garbage Collector aus dem Speicher verdrängen lassen\cite{oracle_weak_references:2013}, beim Zugriff auf die Referenz wird das Objekt wiederhergestellt. Ein Atom wird folglich genau dann aus dem Cache verdrängt, wenn es entweder manuell durch die Anwendung oder automatisch durch die JVM entfernt wird.\\
Der zweite Cache beschleunigt den Zugriff auf die Inzidenzmengen der Atome und wird ebenfalls durch eine Hashtabelle realisiert. Hierfür implementiert HyperGraphDB einen Least Recently Used Cache (LRU), der jene Objekte vorhält, auf welche zuletzt zugegriffen wurde. Bei der Instanziierung kann festgelegt werden, welcher Anteil des freien Speichers vom Cache genutzt werden darf und wie groß der Anteil zu verdrängender Elemente bei Überschreiten der Speichergrenze sein soll.

% Cache Synchronisation
%Alle Transaktionen in HyperGraphDB greifen auf den Atom-Cache zu, die ACID-\linebreak~Eigenschaften müssen somit auch bei der Verwendung des Caches gegeben sein. Das in diesem Zusammenhang eingesetzte Verfahren ist Multiversion Concurrency Control (MVCC), ein optimistisches Synchronisationsverfahren für nebenläufige Transaktionen\cite{DBLP:books/sp/HarderR01}.\footnote{Das Verfahren verzichtet auf das Setzen von Lese- und Schreibsperren, stattdessen werden zu ändernde Objekte dupliziert und Änderungen an den Duplikaten durchgeführt. Objektduplikate werden durch das Führen einer Versionsnummer unterschieden. Leseoperationen greifen ausschließlich auf jene Objektversionen zu, die zum Beginn der Transaktion aktuell waren und erhalten folglich immer eine konsistente Sicht auf die Datenbasis. Dies entspricht dem Konzept der reihenfolgeerhaltenden Serialisierbarkeit\cite{DBLP:books/sp/HarderR01}. Reine Lesetransaktionen können somit ohne Blockierungen durchgeführt werden. Änderungstransaktionen werden erst beim Commit auf eventuell vorhandene Konflikte mit nebenläufigen Transaktionen überprüft. Dies erfolgt über den Vergleich von Versionsnummern der geänderten Objekte: Stimmt die Versionsnummer des Objektes zum Commit-Zeitpunkt mit der Versionsnummer bei der Duplikaterstellung überein, liegt kein Konflikt vor. Sind die Versionen hingegen verschieden, hat eine nebenläufige Transaktion das Objekt und somit die Versionsnummer geändert, die aktuelle Transaktion muss folglich zurückgesetzt werden. Ist hingegen die beschriebene Übereinstimmung der Versionen für alle geänderten Objekte gegeben, so ist die Transaktion valide und ihre Änderungen können im Cache sichtbar gemacht werden.} In diesem Konzept sind keine Mehrbenutzeranomalien möglich, die Isolationsebene innerhalb des Caches ist somit \texttt{SERIALIZABLE}. In Verbindung mit der Transaktionsausführung in der physischen Speicherschicht lässt sich der Ablauf beim Commit einer Transaktion in HyperGraphDB anhand der folgenden Schritte zusammenfassen:
%
%\begin{enumerate}
%	\item Anfordern einer Commit-Sperre um nebenläufige Commits zu blockieren
%	\item Prüfen, ob die Transaktion im Cache valide ist
%	\item Ausführung des Commit in der physischen Speicherschicht (BerkeleyDB)
%	\item Schreiben der Änderungen im Cache
%	\item Freigabe der Commit-Sperre
%\end{enumerate}
%
%Ist die Transaktion bereits im Cache nicht valide oder führt das Commit in der physischen Speicherschicht zum Abbruch der Transaktion, werden die Änderungen im Cache verworfen und die Transaktion ist zurückgesetzt.\footnote{Die Erläuterung der Transaktionsverwaltung innerhalb des Caches ist nicht Teil der offiziellen Dokumentation, sondern basiert auf der Recherche innerhalb des Quelltextes von HyperGraphDB. Die dabei dokumentierten internen Abläufe wurden im Austausch mit dem Entwickler bestätigt: \url{https://groups.google.com/forum/?hl=de\#!topic/hypergraphdb/fmjdVtDxf-g.}} Für die Verwaltung der Duplikate nutzt HyperGraphDB Versioned Boxes\cite{Cachopo:2006:VBB:1228561.1228566}, die Darstellung der Funktionsweise überschreitet jedoch den Rahmen der vorliegenden Evaluation und ist für das Verständnis der Transaktions- und Cacheverwaltung nicht erforderlich.

\subsection{Verteilung und Skalierbarkeit}

Die Verteilung der Datenbasis erfolgt in HyperGraphDB unter Verwendung eines integrierten Peer-to-Peer-Frameworks, welches verschiedene Mechanismen zur Kommunikation zwischen verteilten Datenbankinstanzen bereitstellt. Eine Peer-to-Peer-Kommunikation zeichnet sich im Gegensatz zur Client-Server-Kommunikation dadurch aus, dass alle Teilnehmer gleichberechtigt sind und innerhalb des Netzes keine zentrale Instanz existiert\cite{Tanenbaum:2002:CN:572404}. Für die Kommunikation zwischen den Peers setzt HyperGraphDB die standardisierte Agent Communication Language\footnote{\url{http://www.fipa.org/repository/aclspecs.html}} ein, die Übertragung erfolgt in Form von Nachrichten auf Grundlage des XMPP-Protokolls\footnote{\url{http://xmpp.org/xmpp-protocols/rfcs/}}. Die Kommunikation selbst ist  asynchron, was bedeutet, dass Nachrichten von Peers empfangen, in einem Pool gesammelt und anschließend in beliebiger Reihenfolge verarbeitet werden.

Intention von HyperGraphDB ist das Definieren einer Datenverteilung innerhalb der Anwendung, da diese unter Berücksichtigung von Domänenwissen besser entscheiden kann, wie die Daten zu partitionieren bzw. zu replizieren sind. Das Framework ist somit ausschließlich als Mittel zur Umsetzung konkreter Verteilungsalgorithmen gedacht. Auf eine detaillierte Beschreibung des Frameworks wird an dieser Stelle verzichtet, da dies nicht dem Schwerpunkt der Evaluation entspricht. Sollte HyperGraphDB für das Forschungsprojekt eingesetzt und dabei eine Verteilung realisiert werden, so findet sich eine ausführliche Beschreibung des Frameworks in der offiziellen Dokumentation.

In \cite{Iordanov:2010:HGG:1927585.1927589} wird ein sehr abstraktes Beispiel für die Umsetzung einer Replikation in HyperGraphDB vorgestellt. Auf dieser Grundlage wird nachfolgend - stark vereinfacht -  die mögliche Realisierung einer fragmentierten Replikation beschrieben: Ein Peer kann durch die Definition von Prädikaten die für ihn interessanten Atome festlegen. Zum Beispiel kann durch die Verwendung von Typ-Prädikaten bestimmt werden, welcher Peer die Instanzen eines Typs speichert. Folglich lässt sich durch Partitionierung des Schemas festlegen, welche Atome zusammen gespeichert werden. Die Anzahl der Peers, die das gleiche Typ-Prädikat besitzen, entspricht der Anzahl der Replikate der jeweiligen Instanzen. Die Prädikate aller Peers sind jedem Teilnehmer innerhalb des Netzwerkes bekannt. Sobald ein Atom ein definiertes Prädikat erfüllt, werden alle daran interessierten Peers benachrichtigt. Die Prüfung erfolgt event-basiert beim Erzeugen, Löschen oder Aktualisieren eines Atoms innerhalb einer Transaktion. Die Nachricht selbst beinhaltet die zugehörige Transaktion. Trifft die Nachricht beim Interessent ein, bestätigt er diese und entscheidet selbst, ob er die Transaktion ausführt oder verwirft. Die Konsistenz muss dabei durch Festlegen einer Ausführungsreihenfolge sichergestellt werden, dies erfolgt durch die Vergabe einer Versionsnummer. In \cite{Iordanov:2010:HGG:1927585.1927589} wird nicht definiert, wie diese innerhalb des Netzwerkes erzeugt wird, das Framework stellt jedoch sicher, dass letztendlich alle Peers eine konsistente Sicht auf die Daten aufweisen.\\
Durch eine anwendungsseitige Aufteilung des Schemas und die mehrfache Definition identischer Prädikate lässt sich somit eine fragmentierte Replikation umsetzen.