\section{HyperGraphDB}

HyperGraphDB ist ein quelloffenes GDBMS, das von Kobrix Software\footnote{\url{http://kobrix.com/index.jsp}} entwickelt wird. Die Quellcode-Lizenz ist GNU LGPL\footnote{Die Lizenz erlaubt die Verwendung in freier und kommerzieller Software. Die Verwendung in kommerzieller Software erfordert nicht, dass diese ebenfalls quelloffen sein muss: \url{http://www.gnu.org/licenses/lgpl-3.0.de.html}.}, die erste stabile Version 1.0 wurde 2010 veröffentlicht. Die Implementierung des Systems erfolgt ausschließlich in Java und sieht den Einsatz als eingebettetes Graphdatenbanksystem vor. Modellierung und Verwendung der Daten erfolgen graphenorientiert, Verarbeitung und Speicherung sind jedoch nicht-nativ: Der Graph wird auf eine Menge assoziativer Arrays abgebildet für deren Speicherung eine beliebige, entsprechend optimierte Speicherlösung eingesetzt werden kann. Standardmäßig nutzt HyperGraphDB hierfür die quelloffene, disk-orientierte Key-Value-Datenbank BerkeleyDB Java Edition\cite{Oracle_BerkeleyDB:2013}. Die Nutzung des Hauptspeichers als primäres Speichermedium ist bei Verwendung einer entsprechenden Speicherschicht möglich, HyperGraphDB bietet hierfür jedoch keine Implementierung an. Das GDBMS kann als zentrales System oder in einer verteilten Konfiguration eingesetzt werden.

Grundlegend betrachtet handelt es sich um ein objektorientiertes Persistenz-Framework zur dauerhaften Speicherung von Java-Objektinstanzen. Die Repräsentation der Daten im Hauptspeicher, Indexierung und Caching sind jedoch für die Unterstützung von Traversierung und Mustersuche ausgelegt. Wesentliche Eigenschaft des GDBMS und gleichzeitig Alleinstellungsmerkmal innerhalb der Evaluation ist die Möglichkeit zur Modellierung n-ärer Beziehungen: Als Datenmodell wird ein erweitertes Property-Hypergraph-Modell in Verbindung mit einem flexiblen Typsystem eingesetzt.\\
Konzipiert wurde das GDBMS für die Verwaltung hochkomplexer Daten, wie sie zum Beispiel in der Wissensverwaltung vorkommen\cite{Iordanov:2010:HGG:1927585.1927589}. Laut Hersteller eignet sich das System darüber hinaus für die Verwaltung sozialer Netzwerke und für den Einsatz in klassischen objektorientierten Geschäftsanwendungen\cite{HGDB_business_applications:2012}. Ein weiteres wichtiges Merkmal ist die offene Architektur, welche die Implementierung und Integration eigener Anfrage-,  Indizierungs-, Persistenz- und Verteilungsmechanismen ermöglicht.

Die nachfolgenden Ausführungen beziehen sich auf Version 1.2 des GDBMS, diese wurde im November 2012 veröffentlicht. Der Großteil der Informationen stammt aus der offiziellen Dokumentation\cite{hypergraph_db_docu:2013} und der primären Publikation zu HyperGraphDB\cite{Iordanov:2010:HGG:1927585.1927589}. Weitere Quellen werden an entsprechender Stelle genannt.

\subsection{Datenmodell und Typsystem}

% Modelltheorie
Die Basiseinheit zur Darstellung von Informationen innerhalb des Datenmodells ist das \textit{Atom}. Jedem Atom ist ein Tupel bestehend aus Atomen zugeordnet, dieses wird als \textit{Zielmenge} bezeichnet. Die Kardinalität der Zielmenge ist die \textit{Arität}: Ein Atom mit Arität Null ist ein Knoten, wohingegen ein Atom mit einer Arität größer Null eine Kante repräsentiert.\footnote{Die Begriffe Kante und Hyperkante werden bei der Beschreibung von HyperGraphDB synonym verwendet.} Eine Kante kann folglich auf eine beliebige Anzahl von Atomen verweisen. Dies stellt eine Erweiterung des in Abschnitt \ref{subsec:hgm} definierten Hypergraph-Modells dar, da eine Kante in HyperGraphDB sowohl auf Knoten, als auch auf andere Kanten verweisen kann. Im Datenmodell werden Beziehungen zwischen Beziehungen als Relationen höherer Ordnung bezeichnet. Die \textit{Inzidenzmenge} eines Atoms $a$ ist die Menge aller Atome, die $a$ in ihrer Zielmenge enthalten, d.h. die Menge aller gerichteter Kanten, die auf $a$ zeigen. An dieser Stelle wird deutlich, dass es sich um eine nicht-native Verarbeitung handelt, da ausgehend von einem Knoten nicht direkt auf dessen Nachbarschaft zugegriffen werden kann. Es muss zunächst festgestellt werden, in welchen Zielmengen der entsprechende Knoten vorkommt. Wie nachfolgend gezeigt wird, setzt HyperGraphDB hierfür entsprechende Indexstrukturen ein.

Neben der Zielmenge ist jedem Atom genau ein typisierter Wert zugeordnet. Der Typ ist beliebig und wird genau wie reguläre Daten innerhalb der Datenbasis als Atom gespeichert. Folglich können Beziehungen zwischen Typen untereinander bzw. zwischen Typen und ihren Instanzen abgebildet und in Operationen verwendet werden. Daraus geht hervor, dass Atome sowohl die Struktur als auch die Semantik des Graphen abbilden. Die Werte entsprechen den Nutzdaten und können beliebig strukturiert oder unstrukturiert sein und zur Laufzeit durch Werte eines anderen Typs ausgetauscht werden. Damit lassen sich Semantik und Struktur unabhängig voneinander ändern, dies entspricht der Schemaevolution innerhalb einer Anwendung und bietet somit eine vergleichbare Flexibilität wie zum Beispiel Neo4j.

\paragraph*{Typsystem} Aus Anwendungssicht ist es die wesentliche Aufgabe eines Typen die Semantik der Daten zu beschreiben. Aus Systemsicht ist es hingegen die Serialisierung von Laufzeitobjekten in das Format der darunterliegenden Speicherschicht sowie die umgekehrte Deserialisierung. Im Sinne der Objektorientierung ist ein Typ somit eine abstrakte Fabrik und stellt Methoden zum Erzeugen, Speichern und Löschen von Laufzeitrepräsentationen seiner Instanzen zur Verfügung.\footnote{Das Aktualisieren eines Wertes ist nicht möglich, da Werte in HyperGraphDB generell unveränderlich (engl. \textit{immutable}) sind. Dies hat den Vorteil, dass ein Wert mehreren Atomen zugeordnet sein kann, führt jedoch dazu, dass bei der Aktualisierung eines Wertes ein neuer Wert erzeugt werden muss.} Da es sich bei Typen um Atome handelt, besitzen auch diese einen übergeordneten Datentyp. Für jene, die bereits im Typsystem existieren, ist dies ein systemseitiger Datentyp mit der Bezeichnung \texttt{Top}. Wird hingegen ein Objekt, dessen Typ nicht bereits in der Datenbasis hinterlegt ist, zur Laufzeit eingefügt, so ist dessen Typ ein Typkonstruktur. Dieser erzeugt neue aus bestehenden Typen, es handelt sich folglich um einen Datentyp, dessen Instanzen ebenfalls Datentypen sind.\\
Neben den genannten Operationen stellt ein Typ eine weitere Operation zur Verfügung: Das Subsumieren. Eine Instanz A subsumiert eine Instanz B genau dann, wenn A allgemeiner ist als B bzw. wenn B immer dann verwendet werden kann, wenn A verwendet werden kann\cite{HGDB_subsume:2013}. Damit wird zum Beispiel geprüft, ob sich zwei Instanzen gegenseitig enthalten und folglich gleichwertig sind oder ob eine Instanz durch die andere ersetzt werden kann. Handelt es sich bei den Instanzen um Typen, so ermöglicht die Subsumierung die Abbildung von Vererbungshierarchien und somit die Konstruktion beliebiger Typsysteme: Wenn eine Instanz A eine zweite Instanz B subsumiert und A und B Typen sind, so erbt A von B.

Es sollte deutlich werden, dass ein Typ in HyperGraphDB ein Atom mit einer speziellen Rolle ist. Aus Anwendungssicht ermöglicht es die Definition von Knoten- und Kantenbezeichnern sowie das Speichern von Nutzdaten, aus Systemsicht die Verwaltung von Assoziationen sowohl zwischen einem Typ und seinen Instanzen als auch zwischen mehreren Typen. Das GDBMS beinhaltet vordefinierte Typimplementierungen für primitive Datentypen, JavaBeans\footnote{\url{http://www.oracle.com/technetwork/java/javase/documentation/spec-136004.html}}, 
Arrays, Collections und Maps.\footnote{Eine vollständige Übersicht befindet sich im Quelltext des GDBMS unter \url{https://code.google.com/p/hypergraphdb/source/browse/tags/release1.2/core/src/config/org/hypergraphdb/types}} Vererbungshierarchien werden ebenfalls persistiert und durch einen dedizierten Kantentyp repräsentiert. Sollen komplexere Datentypen verwendet werden oder ist die Einhaltung der JavaBeans-Spezifikation nicht möglich, lassen sich eigene Datentypen implementieren. Diese werden im Typsystem des GDBMS registriert, anschließend lassen sich deren Instanzen in der Datenbasis verwalten.\\
Ein Typsystem erlaubt die Definition von Integritätsbedingungen und das GDBMS sorgt durch deren Einhaltung für die Wahrung der Konsistenz. So lässt sich zum Beispiel die Zielmenge entsprechend typisierter Kanten auf definierte Typen einschränken, darüber hinaus ist das Definieren von Wertebereichen und Kardinalitäten möglich.

% eine oder mehrere Datenbanken
In HyperGraphDB existieren aus Anwendungssicht keine Primärschlüssel, die Identität eines Atoms wird durch die Instanz eines sog. Handle repräsentiert. Deren Funktion wird im Zusammenhang mit den Zugriffsmechanismen näher erläutert.

\subsection{Zugriffsmechanismen und Transaktionen}

HyperGraphDB bietet keine dedizierte Anfragesprache an, sondern erlaubt den Zugriff auf die Datenbasis ausschließlich via Java API im eingebetteten Betrieb. In diesem Zusammenhang stehen CRUD- und mengenorientierte Operationen sowie die Möglichkeit zur Traversierung des Graphen zur Verfügung.

\paragraph*{CRUD-Operationen}

Das GDBMS bietet grundlegende Funktionen zum Erzeugen, Auslesen und Löschen von Atomen an. Da Werte innerhalb der Datenbasis unveränderlich sind, erfolgt das Aktualisieren ausschließlich über den Austausch von Werten.

%Knoten
Ein Knoten definiert sich durch eine Objektinstanz innerhalb der Laufzeitumgebung. Diese lässt sich dem Graphen hinzufügen: Ist ihr Datentyp bereits im Typsystem registriert, wird er automatisch mit dem Knoten verbunden, andernfalls zunächst durch einen Typkonstruktor erzeugt. Das Resultat des Anlegens ist ein Handle, welches den Knoten innerhalb der Datenbasis identifiziert. Anhand des Handles kann die Objektinstanz und deren Typ aus der Datenbasis gelesen werden, umgekehrt lässt sich unter Angabe der Objektinstanz das zugehörige Handle laden. Das Löschen eines Atoms ist ausschließlich unter Angabe des zugehörigen Handles möglich.\\
In Verbindung mit dem flexiblen Typsystem und den vorhandenen Typimplementierungen lassen sich beliebige Nutzdaten an einem Knoten speichern. Wird zum Beispiel ein JavaBeans-Objekt dem Graphen hinzugefügt, so wird dieses intern durch eine Record-Struktur repräsentiert, die den schlüsselbasierten Zugriff auf die Attribute des Objektes ermöglicht. Da Attribute wiederum typisierte Werte sind, lassen sich beliebig verschachtelte Objekte hinterlegen.

%Kanten
Kanten werden in HyperGraphDB nicht durch Referenzen zwischen Objektinstanzen, sondern durch spezielle Kantenobjekte modelliert. Letztere sind Implementierungen der Schnittstelle \texttt{HGLink}, das GDBMS stellt drei Implementierungen zur Verfügung: Kanten können ohne jegliche Zusatzinformationen, zum Beispiel ohne eine semantische Bedeutung oder ohne Nutzdaten, angelegt werden. Eine zweite Implementierung erlaubt das Speichern von Nutzdaten, dies können beliebig komplexe Objektinstanzen oder einfache Zeichenketten zur Festlegung eines Kantenbezeichners sein. Ein dritter Typ ermöglicht zudem das Festlegen zulässiger Typen innerhalb der Zielmenge und gestattet damit die Definition von Integritätsbedingungen.\\
Kanten werden unter Angabe ihrer Zielmenge und eventueller Nutzdaten erzeugt und anschließend mittels Handle identifiziert, Auslesen und Löschen erfolgen wie bereits für Knoten beschrieben. Kanten bieten darüber hinaus Funktionen zum Lesen der Zielmenge und der Arität an. Da die Zielmenge ein Tupel und somit geordnet ist, können Handles unter Angabe ihrer Position innerhalb der Zielmenge ausgelesen werden. Dies ermöglicht die Definition von Kantentypen die einzelnen Positionen innerhalb der Zielmenge eine Semantik zuordnen.

\paragraph*{Mengenorientierte Anfragen}

Neben dem Auslesen von Atomen unter Angabe ihres Handles bietet HyperGraphDB die Möglichkeit, deklarative, mengenorientierte Anfragen an die Datenbasis zu stellen. Die hierfür vorhandene API basiert auf der Definition von Prädikaten zur Einschränkung der Ergebnismenge. Prädikate lassen sich konjunktiv bzw. disjunktiv verknüpfen sowie beliebig schachteln und negieren. Sie beziehen sich entweder auf den Wert eines Atoms oder auf die Topologie des Graphen. Die folgende Anfrage definiert zum Beispiel die Menge aller Mitarbeiter, deren Attribut \texttt{age} kleiner oder gleich dem Wert 25 ist:

\texttt{hg.and(hg.type(Employee.class), hg.gte(\string"age\string", 25))}.

\texttt{hg} ist eine vom GDBMS bereitgestellte Klasse die syntaktisch verkürzte, einfache Methoden für das Formulieren von Anfragen anbietet und diese intern auf eine komplexere API abbildet.\footnote{Die zugrundeliegende API wird an dieser Stelle nicht beschrieben, weil die Methoden der Klasse \texttt{hg} für die Erläuterung ausreichend sind. Weiterführende Informationen sind in der offiziellen Dokumentation enthalten\cite{hypergraph_db_docu:2013}.} In der Anfrage werden die Prädikate \texttt{hg.type(Employee.class)} und \texttt{hg.gte(\string"age\string", 25)} durch den logischen Operator \texttt{hg.and} konjunktiv verknüpft. Das erste Prädikat legt den Typ des Atoms auf Mitarbeiter fest, während das zweite den Attributwert einschränkt. \texttt{Employee} ist im Beispiel eine Klasse nach JavaBeans-Spezifikation.

Neben den Werten lässt sich auch die Topologie des Graphen in einer Anfrage durch Prädikate beschreiben. Das folgende Beispiel definiert die Menge aller Kanten, die zwei gegebene Atome in ihrer Zielmenge enthalten und insgesamt zehn Atome verbinden:

\texttt{hg.and(hg.link(atom1, atom2), hg.arity(10))}.

Im vorhergehenden Abschnitt wurde das Speichern eines Typs innerhalb der Datenbasis beschrieben: Vererbungshierarchien werden durch Subsumierung von Typen ausgedrückt, diese Beziehung lässt sich folglich auch innerhalb von Anfragen verwenden. Nachfolgend wird die Menge aller Atome definiert, deren Datentyp von einer Klasse \texttt{Person} erbt und deren Instanzen nicht 25 Jahre alt sind:

\texttt{hg.and(hg.subsumes(Person.class), hg.not(hg.eq(\string"age\string", 25)))}.

Es handelt sich demnach um eine Anfrage, in der Topologie, Semantik und auch Nutzdaten des Graphen einbezogen werden. Neben den gezeigten stehen weitere Operatoren zum Vergleich von Werten, zur Einschränkung von Typbeziehungen und zur Beschreibung der Topologie zur Verfügung.

Für das Auslesen der Ergebnismenge werden drei Methoden angeboten: Grundsätzlich wird ein Iterator erzeugt, mit dem sich die Ergebnismenge bi-direktional durchlaufen lässt, der Wert eines Atoms wird erst beim Zugriff geladen. Die direkte Verwendung des Iterators bietet sich insbesondere bei umfangreichen Ergebnismengen an. Alternativ stellt die Klasse \texttt{hg} zwei Methoden zur Verfügung, mit denen sich entweder die vollständig deserialisierten Objektinstanzen oder nur deren Handles in einer Liste zurückgeben lassen.\\
Optional kann innerhalb einer Anfrage eine Abbildung definiert und mittels \texttt{hg.apply} auf die Ergebnismenge angewendet werden. Die Abbildung ermöglicht die Realisierung einer Projektion wenn nur bestimmte Attribute der Atomwerte ausgegeben werden sollen. Zusätzlich kann eine Transformation der Elemente erfolgen. Für eine Aggregation der Ergebnismenge stehen außer \texttt{hg.count} keine Operatoren zur Verfügung und müssen folglich bei Bedarf selbst implementiert werden.

An dieser Stelle sei auf die offene Architektur des GDBMS hingewiesen: Neue Operatoren lassen sich durch das Implementieren der Schnittstellen \texttt{HGAtomPredicate} und \texttt{HGQueryCondition} hinzufügen. Dies erlaubt das Definieren beliebiger domänenspezifischer Operatoren im Rahmen des beschriebenen Forschungsprojektes. Ein Beispiel hierfür ist das Prüfen, ob eine gegebene Kante eine kausale Abhängigkeit beschreibt. Dies ist genau dann der Fall, wenn alle in der Zielmenge vorhandenen Typen einen Datentyp zur Beschreibung transaktionaler Daten subsumieren.

\paragraph*{Traversierung}

Vergleichbar mit Neo4j steht in HyperGraphDB eine Menge von Schnittstellen zur Verfügung, mit der sich eine Traversierung innerhalb der Datenbasis beschreiben lässt. Die Reihenfolge, in der ein Graph durchlaufen wird, kann durch die Implementierung der Schnittstelle \texttt{HGTraversal} festgelegt werden. Es handelt sich um einen Iterator, dessen Elemente Paare von Handles sind. Jedes Paar besteht aus einer Kante und einem Atom, auf welches die Kante zeigt. Die Schnittstelle kann darüber hinaus prüfen, ob ein Handle bereits während der Traversierung besucht wurde. HyperGraphDB stellt zwei Implementierungen der Schnittstelle zur Verfügung: \texttt{HGBreadthFirstTraversal} für die Durchführung eines Breitendurchlaufs und \texttt{HGDepthFirstTraversal} für die Durchführung eines Tiefendurchlaufs. 

Neben dem Festlegen einer Reihenfolge kann es notwendig sein, die Menge der relevanten Paare einzuschränken. Hierfür stellt HyperGraphDB die Schnittstelle \texttt{HGALGenerator} zur Verfügung. Diese Schnittstelle ermöglicht es, eine Adjazenzliste (AL) zu generieren, welche jene Paare enthält, die ausgehend von einem Atom von der Traversierung berücksichtigt werden sollen. Auch hier stellt das GDBMS zwei Implementierungen zur Verfügung. Der \texttt{SimpleALGenerator} erzeugt Adjazenzlisten aller benachbarter Atome ohne Berücksichtigung von Kanten- und Knotentypen bzw. deren Werten. Deutlich flexibler ist hingegen der \texttt{DefaultALGenerator}: Unter Verwendung der bereits beschriebenen Prädikate lassen sich sowohl Bedingungen für Kanten, als auch für Knoten\footnote{Semantisch korrekt wäre hier die Bezeichnung Geschwister, da eine Adjazenz auch zwischen Kanten definiert sein kann.} definieren. Das folgende kurze Beispiel verdeutlicht dies:

\texttt{DefaultALGenerator alGen = new DefaultALGenerator(graph,\newline
		hg.and(hg.type(WorksWith.class), hg.gte(\string"since\string", 2010)), // edge predicate \newline
		hg.and(hg.type(Person.class), hg.eq(\string"region\string", \string"Leipzig\string"))); // node predicate}
		
Es wird festgelegt, dass ausschließlich jene Kanten traversiert werden, die vom Typ \texttt{WorksWith} sind und deren repräsentierte Beziehung seit 2010 besteht. Die Beziehung selbst soll nur zu Knoten bestehen, die vom Typ \texttt{Person} sind und aus der Region Leipzig stammen. Alle Unterklassen werden durch das Prädikat ebenfalls berücksichtigt.\\
Beide Implementierungen von \texttt{HGALGenerator} verbieten das mehrfache Besuchen von Knoten, d.h. wenn mehrere Paare bestehend aus unterschiedlichen Kanten und dem gleichen Knoten existieren, wird nur eines dieser Paare berücksichtigt. Letzteres kann durch eine eigene Implementierung umgangen werden. 

Sind Reihenfolge und eventuelle Einschränkungen definiert, wird die Traversierung unter Angabe eines Start-Handles initialisiert und gestartet. Während der Ausführung werden die relevanten Paare elementweise betrachtet. Dabei stehen im Gegensatz zu Neo4j keine Instanzen bereits berechneter Wege zur Verfügung. Das Berechnen des aktuellen Abstands vom Startknoten oder das Speichern berechneter Wege muss bei Bedarf manuell erfolgen.\\
Zur Berechnung kürzester Pfade steht eine Implementierung des Dijkstra-Algorithmus zur Verfügung. Diese erfordert mindestens die Angabe eines Start- und eines Zielhandle. Darüber hinaus können optional ein \texttt{HGALGenerator} und nicht-negative Kantengewichte in Form eines assoziativen Arrays definiert werden. Soll der Ergebnispfad rekonstruierbar sein, so erfordert dies die Übergabe eines assoziativen Arrays: Dieses ordnet jedem Handle innerhalb des Pfades seinen jeweiligen Vorgänger zu.

\paragraph*{Transaktionen}

% Zugriffsart, explizig, implizit

HyperGraphDB unterstützt die Ausführung von Anfragen innerhalb von Transaktionen. Für Änderungsoperationen ist dies obligatorisch, rein lesende Zugriffe können auch transaktionsunabhängig ausgeführt werden. Bei der Ausführung einer einzelnen Schreiboperation wird eine Transaktion implizit erzeugt, sollen hingegen mehrere Zugriffe innerhalb einer Transaktion erfolgen, muss diese anwendungsseitig explizit erzeugt und verwaltet werden. Das GDBMS stellt hierfür entsprechende Funktionen zur Verfügung. Darüber hinaus besteht die Möglichkeit, Zugriffe an eine aktive Transaktion zu binden.\\ 
Transaktionen können beim Systemstart deaktiviert werden, dies ist zum Beispiel beim Importieren umfangreicher Datenmengen sinnvoll und setzt voraus, dass keine nebenläufigen Zugriffe erfolgen. Bezüglich der ACID-Eigenschaften sind Transaktionen in HyperGraphDB atomar, konsistent und erfolgen isoliert voneinander. Die Dauerhaftigkeit wird nicht garantiert, was bedeutet, dass Änderungen erfolgreich beendeter Transaktionen nach einem Systemfehler verloren sein können. Der Hersteller begründet dies mit dem daraus resultierenden höheren Schreibdurchsatz und mit der geringen Häufigkeit kompletter Abstürze der JVM.

% Schachtelung von Transaktionen

Das GDBMS erlaubt die Schachtelung von Transaktionen: Im Gegensatz zu Neo4j lassen sich dabei untergeordnete Transaktionen isoliert zurücksetzen. Der Abbruch einer übergeordneten Transaktionen führt zum Rollback aller ihr untergeordneten Transaktionen. Dies hat zur Folge, dass ein Fehler in komplexen, lange laufenden Transaktionen isoliert behandelt und der Arbeitsverlust je nach Granularität der Aufteilung minimiert werden kann.

% Mehrbenutzeranomalien

Wie bereits erwähnt, nutzt HyperGraphDB die Key-Value-Datenbank BerkeleyDB für die Speicherung der Datenbasis. Diese verwendet ein pessimistisches RX-Sperrverfahren zur Vermeidung von Lese-Schreib-Konflikten. In BerkeleyDB lassen sich verschiedene Isolationsebenen konfigurieren, standardmäßig wird \texttt{REPEATABLE READ} verwendet\cite{oracle:2013}. Lese- und Schreibsperren werden in dieser Stufe für die Dauer der gesamten Transaktion gehalten. Somit werden die Mehrbenutzeranomalien Dirty Read, Non-Repeatable Read und Lost Update vermieden. Das Phantom Problem beim parallelen Einfügen neuer Datensätze ist weiterhin möglich.\\
% Deadlocks
BerkeleyDB implementiert einen Timeout-Mechanismus\cite{DBLP:books/sp/HarderR01} zur Erkennung von\linebreak~Deadlocks\cite{oracle:2013}. Der Timeout legt fest, wie lange eine Sperre auf einem Objekt gehalten werden kann. Wird dieser Wert überschritten, geht das System von einem Deadlock aus. Da dies nicht zwingend der Realität entsprechen muss, sollte der Wert dem Zugriffsverhalten und der erwarteten Transaktionsdauer entsprechend angepasst werden um unnötige Rücksetzungen zu vermeiden. Wird ein potentieller Deadlock erkannt, benachrichtigt BerkeleyDB die Anwendung, d.h. HyperGraphDB, mittels einer Ausnahme. Die Behandlung dieser Ausnahme wird entweder von HyperGraphDB oder von Anwendung übernommen: Das GDBMS bietet die Möglichkeit eine in Folge eines Deadlocks abgebrochene Transaktion automatisch zu wiederholen bis diese erfolgreich beendet wird. Alternativ wird die Ausnahme an die Anwendung weitergeleitet, welche über die nachfolgenden Schritte individuell entscheidet.

% Logging

HyperGraphDB garantiert standardmäßig keine Dauerhaftigkeit von Transaktionen. Um dies zu erläutern,  muss kurz auf die Interna von BerkeleyDB eingegangen werden: BerkeleyDB bildet eine Datenbank innerhalb eines B-Baumes ab. Es handelt sich um eine spezielle Form, in der Nutzdaten ausschließlich in den Blättern hinterlegt sind. Änderungsoperationen beeinflussen sowohl die Struktur des Baumes als auch die Einträge in den Blättern. Zur Gewährleistung von Dauerhaftigkeit nutzt BerkeleyDB ein Transaktions-Log, in dem alle logischen Änderungsoperationen registriert werden. Dies bedeutet, dass sich durch sequentielles Ausführen der Log-Einträge der B-Baum rekonstruieren lässt. Folglich ist das Transaktions-Log die Datenbasis. Um den Wiederherstellungsaufwand im Fehlerfall zu minimieren, werden periodisch Sicherungspunkte geschrieben in denen der B-Baum vollständig gespeichert ist\cite{oracle_bdb:2013}.\\
Das Transaktions-Log wird permanent im Hauptspeicher gehalten. Kommt es während der Ausführung einer Transaktion zum Ausfall des GDBMS, sind die bis dahin erfolgten Änderungen ausschließlich im Hauptspeicher und somit verloren. Die Atomarität einer Transaktion ist damit sichergestellt und eine UNDO-Recovery nicht erforderlich. Für die Wiederholbarkeit erfolgreicher Transaktionen wird beim Commit  ein entsprechender Eintrag in das Log geschrieben. In der Standardeinstellung von BerkeleyDB führt dieser Eintrag zum Ausschreiben des Logs auf den Hintergrundspeicher, eine REDO-Recovery ist folglich möglich. HyperGraphDB initialisiert BerkeleyDB standardmäßig mit einer Konfiguration, die es der Datenbank erlaubt, das Transaktions-Log asynchron auf den Hintergrundspeicher zu schreiben, was bedeutet, dass Änderungen zum Commit-Zeitpunkt nicht unmittelbar persistiert werden.\footnote{Die Initialisierung kann im Quelltext unter \url{https://code.google.com/p/hypergraphdb/source/browse/tags/release1.2/storage/bdb-je/src/java/org/hypergraphdb/storage/bje/BJEConfig.java} in Zeile 64 nachvollzogen werden} Kommt es zwischen Commit und Persistieren des Logs zum Systemausfall, sind die Änderungen der Transaktion verloren.

\subsection{Persistenz-, Index- und Cacheverwaltung}

Wie anfangs erwähnt, ist HyperGraphDB ein nicht-natives GDBMS, welches den Graphen auf assoziative Arrays abbildet und diese im Rahmen der Anfrageausführung und der physischen Repräsentation der Datenbasis verwendet. Die Organisation erfolgt dabei innerhalb des GDBMS in zwei Schichten: Der primitiven Speicherschicht, welche direkt auf das eingesetzte Speichersystem zugreift, und der Modellschicht, welche von der primitiven Speicherschicht abstrahiert und die darin enthaltenen Informationen als Elemente des Datenmodells darstellt. Das eingesetzte Speichersystem wird nachfolgend als physische Speicherschicht bezeichnet, da es letztendlich die Persistenz der Daten sicherstellt, standardmäßig ist dies BerkeleyDB Java Edition.

Die primitive Speicherschicht repräsentiert einen Graphen bestehend aus Identitäten und ihnen zugeordneter Rohdaten, eine semantische Zuordnung findet in dieser Schicht nicht statt. Für die Speicherung werden zwei assoziative Arrays verwendet:

\texttt{LinkStore: ID $\rightarrow$ List<ID>}\newline
\texttt{DataStore: ID $\rightarrow$ byte[]}

Der \texttt{LinkStore} bildet die Topologie des Graphen ab, indem er Identitäten (IDs) eine Liste weiterer Identitäten zuordnet. Im \texttt{DataStore} werden einer Identität Rohdaten in Form eines Byte-Arrays zugewiesen. Jeder Datensatz in der primitiven Speicherschicht ist folglich ein Schlüssel-Wert-Paar. Der Schlüssel wird in HyperGraphDB durch ein spezielles Handle repräsentiert, das sog. \texttt{HGPersistentHandle}. Dieses ordnet jeder Entität eine UUID fester Länge zu. Innerhalb der primitiven Speicherschicht ist somit der \texttt{LinkStore} eine Liste von Instanzen des genannten Handles.

Die Modellschicht wandelt die Informationen der primitiven Speicherschicht in die abstrakten Elemente des Datenmodells um. Nachfolgend sind alle ID-Bezeichner als Instanzen von \texttt{HGPersistentHandle} zu verstehen. 

\texttt{AtomID $\rightarrow$ [TypeID, ValueID, TargetID, ..., TargetID]}\newline
\texttt{ValueID $\rightarrow$ [ID, ID, ..., ID] | byte[]}\newline
\texttt{TypeID $\rightarrow$ AtomID}\newline
\texttt{TargetID $\rightarrow$ AtomID}

Ein Eintrag im \texttt{LinkStore} wird in der Modellschicht entweder als Atom oder als Wert eines zusammengesetzten, nicht-primitiven Datentyps interpretiert. Im ersten Fall verweist die \texttt{TypeID} auf den Typ des Atoms während die \texttt{ValueID} den zugehörigen Wert referenziert. Anschließend wird die Zielmenge des Atoms aus einer Menge von \texttt{TargetIDs} definiert. Da ein Knoten im Datenmodell ein Atom mit Arität Null ist, enthält seine physische Repräsentation im Gegensatz zu einer Kante nur den Verweis auf seinen Typ und den Wert. Da sowohl der Typ eines Atoms als auch die Einträge in der Zielmenge Atome sind, referenzieren \texttt{TypeID} und \texttt{TargetID} eine \texttt{AtomID}.\\
Alternativ repräsentiert ein Eintrag im \texttt{LinkStore} den Wert eines zusammengesetzten, nicht-primitiven Datentyps und wird mittels \texttt{ValueID} referenziert. Wird hingegen nur der Wert eines primitiven Datentyps am Atom gespeichert verweist die \texttt{ValueID} direkt auf das entsprechende Byte-Array im \texttt{DataStore}. An dieser Stelle wird deutlich, warum Werte an Atomen grundsätzlich unveränderlich sind und eine Wertänderung nur durch den Austausch des Wertes erfolgen kann.\\
Die Deserialisierung der Werte erfolgt nicht in der Modellschicht, sondern wird von der jeweiligen Typimplementierung bzw. vom jeweiligen Typkonstruktur durchgeführt. Im Zusammenhang mit dem Typsystem wurde bereits erwähnt, dass Typen abstrakte Fabriken sind und unter anderem eine Methode zum Erzeugen der entsprechenden Instanzen zur Verfügung stellen. Diese Methode nimmt die \texttt{ValueID} entgegen und führt die Deserialisierung durch.\footnote{Dies lässt sich im Quelltext des \texttt{HGAtomType} nachvollziehen: \url{https://code.google.com/p/hypergraphdb/source/browse/tags/release1.2/core/src/java/org/hypergraphdb/type/HGAtomType.java}, Zeile 65.}

In der physischen Speicherschicht (BerkeleyDB) werden die Werte von \texttt{LinkStore} und \texttt{DataStore} als Byte-Arrays abgelegt. Die Deserialisierung der Identitäten erfolgt in der primitiven Speicherschicht, ermöglicht wird dies durch die feste Länge der UUIDs. Die Byte-Arrays im \texttt{DataStore} können erst in der Modellschicht deserialisiert werden, da erst hier Informationen zum Datentyp vorhanden sind. Es sollte deutlich werden, dass sich die Schlüsselmengen von \texttt{LinkStore} und \texttt{DataStore} überlappen können und diese somit in zwei getrennten Key-Value-Datenbanken gespeichert werden müssen.

% Index

\paragraph*{Indexverwaltung}

Für die effiziente Ausführung mengenorientierter und traversierender Anfragen beinhaltet die Modellschicht drei zusätzliche Indexstrukturen, welche jeweils in einer Key-Value-Datenbank der physischen Speicherschicht persistiert werden:

\texttt{IncidenceIndex: UUID $\rightarrow$ SortedSet<UUID>}\newline
\texttt{TypeIndex: UUID $\rightarrow$ SortedSet<UUID>}\newline
\texttt{ValueIndex: UUID $\rightarrow$ SortedSet<UUID>}

Der \texttt{IncidenceIndex} ordnet jedem Atom seine Inzidenzmenge zu, d.h. die Menge aller Kanten die auf das Atom zeigen. Der \texttt{TypeIndex} verweist auf die Menge aller Instanzen eines gegebenen Datentyps und der \texttt{ValueIndex} weist einem Wert die Menge der Atome zu, die ihn besitzen. Bei zusammengesetzten Werten wird der Wert auf höchster Ebene indexiert. Zu beachten ist, dass die zugeordneten Werte geordnete Mengen sind auf denen sich Mengenoperationen effizient ausführen lassen. Folglich lassen sich mit Hilfe der Indexstrukturen graphenspezifische Operationen effizient ausführen. Zum Beispiel lässt sich anhand der Schnittmenge der Inzidenzlisten zweier Knoten prüfen, ob diese adjazent sind.

Neben den systemseitigen Indexstrukturen können auch von der Anwendung zusätzliche Indizes definiert werden. Mit diesen ist das Indexieren sowohl der Topologie des Graphen als auch der hinterlegten Nutzdaten möglich. Indizes sind immer an einen Typ gebunden, gelten jedoch für alle Typen, welche diesen subsumieren. Auch im Zusammenhang mit Indexstrukturen wird die offene Architektur des GDBMS deutlich: Das Implementieren der Schnittstelle \texttt{HGIndexer} ermöglicht das Hinzufügen eigener Datenstrukturen. HyperGraphDB beinhaltet bereits Implementierungen zur Indexierung der Attribute eines Datentyps oder zur Indexierung vollständiger Werte eines Atoms. Für den effizienten Zugriff auf Teilgraphen ermöglicht eine weitere Implementierung die Indexierung der kompletten Zielmenge eines Atoms. Ein weiterer topologischer Index indexiert Kanten anhand eines Atoms an einer expliziten Position innerhalb der Zielmenge. Wie bereits erwähnt, ist diese geordnet, die Positionen können somit anwendungsseitig mit einer Semantik versehen werden.

Aus den bisherigen Ausführungen geht hervor, dass HyperGraphDB mindestens fünf Key-Value-Datenbanken zur Abbildung der primitiven Speicherschicht und der obligatorischen Indexstrukturen einsetzt. Für jeden anwendungsseitig definierten Index wird eine zusätzliche Datenbank benötigt. Die Komplexität der einzelnen Operationen ist dabei im Wesentlichen von der Implementierung des Speichersystems abhängig. Wie bereits im Zusammenhang mit Transaktionen beschrieben, speichert BerkeleyDB die Daten einer Datenbank in den Blättern eines B-Baumes. Der Zugriff auf diese Daten ist somit logarithmisch von der Anzahl der Einträge und der Ordnung des Baumes abhängig\cite{ottmann2002algorithmen}. Die indexfreie Adjazenz ist hingegen nur möglich, wenn sich die Daten in konstanter Zeit lesen lassen. BerkeleyDB verfügt über Caches um den Zugriff auf die Datenbasis zu beschleunigen\cite{oracle_bdb:2013}. Da es sich jedoch um ein austauschbares Speichersystem handelt, wird nachfolgend nur die Cacheverwaltung von HyperGraphDB beschrieben.

% Caching

\paragraph*{Cacheverwaltung}

Für den performanten, wahlfreien Zugriff auf die Elemente innerhalb des Graphen bietet auch HyperGraphDB Caches an: Den Atom-Cache und einen Cache für Inzidenzmengen. Der Atom-Cache ermöglicht den effizienten Zugriff sowohl auf die Objektinstanz unter Angabe des zugehörigen Handles als auch für den umgekehrten Fall. Realisiert wird der Cache durch zwei Hashtabellen und die Verwendung schwacher Referenzen. Letztere zeichnen sich dadurch aus, dass sich die von ihnen referenzierten Objektinstanzen vom Garbage Collector aus dem Speicher verdrängen lassen\cite{oracle_weak_references:2013}, beim Zugriff auf die Referenz wird das Objekt wiederhergestellt. Ein Atom wird folglich genau dann aus dem Cache verdrängt, wenn es entweder manuell durch die Anwendung oder automatisch durch die JVM entfernt wird.\\
Der zweite Cache beschleunigt den Zugriff auf die Inzidenzmengen der Atome und wird ebenfalls durch eine Hashtabelle realisiert. Hierfür implementiert HyperGraphDB einen Least Recently Used Cache (LRU), welcher jene Objekte vorhält, auf die als letztes zugegriffen wurde. Bei der Instanziierung kann festgelegt werden, welcher Anteil des freien Speichers vom Cache genutzt werden darf und wie groß der Anteil zu verdrängender Elemente bei Überschreiten der Speichergrenze sein soll.

% Cache Synchronisation
Alle Transaktionen in HyperGraphDB greifen auf den Atom-Cache zu, die ACID-\linebreak~Eigenschaften müssen somit auch bei der Verwendung des Caches gegeben sein. Das in diesem Zusammenhang eingesetzte Verfahren ist Multiversion Concurrency Control (MVCC), ein optimistisches Synchronisationsverfahren für nebenläufige Transaktionen\cite{DBLP:books/sp/HarderR01}.\footnote{Das Verfahren verzichtet auf das Setzen von Lese- und Schreibsperren, stattdessen werden zu ändernde Objekte dupliziert und Änderungen an den Duplikaten durchgeführt. Objektduplikate werden durch das Führen einer Versionsnummer unterschieden. Leseoperationen greifen ausschließlich auf jene Objektversionen zu, die zum Beginn der Transaktion aktuell waren und erhalten folglich immer eine konsistente Sicht auf die Datenbasis.\footnote{Dies entspricht dem Konzept der reihenfolgeerhaltenden Serialisierbarkeit\cite{DBLP:books/sp/HarderR01}.} Reine Lesetransaktionen können somit ohne Blockierungen durchgeführt werden. Änderungstransaktionen werden erst beim Commit auf eventuell vorhandene Konflikte mit nebenläufigen Transaktionen überprüft. Dies erfolgt über den Vergleich von Versionsnummern der geänderten Objekte: Stimmt die Versionsnummer des Objektes zum Commit-Zeitpunkt mit der Versionsnummer bei der Duplikaterstellung überein, liegt kein Konflikt vor. Sind die Versionen hingegen verschieden, hat eine nebenläufige Transaktion das Objekt und somit die Versionsnummer geändert, die aktuelle Transaktion muss folglich zurückgesetzt werden. Ist hingegen die beschriebene Übereinstimmung der Versionen für alle geänderten Objekte gegeben, so ist die Transaktion valide und ihre Änderungen können im Cache sichtbar gemacht werden.} In diesem Konzept sind keine Mehrbenutzeranomalien möglich, die Isolationsebene innerhalb des Caches ist somit \texttt{SERIALIZABLE}. In Verbindung mit der Transaktionsausführung in der physischen Speicherschicht lässt sich der Ablauf beim Commit einer Transaktion in HyperGraphDB anhand der folgenden Schritte zusammenfassen:

\begin{enumerate}
	\item Anfordern einer Commit-Sperre um nebenläufige Commits zu blockieren
	\item Prüfen, ob die Transaktion im Cache valide ist
	\item Ausführung des Commit in der physischen Speicherschicht (BerkeleyDB)
	\item Schreiben der Änderungen im Cache
	\item Freigabe der Commit-Sperre
\end{enumerate}

Ist die Transaktion bereits im Cache nicht valide oder führt das Commit in der physischen Speicherschicht zum Abbruch der Transaktion, werden die Änderungen im Cache verworfen und die Transaktion ist zurückgesetzt.\footnote{Die Erläuterung der Transaktionsverwaltung innerhalb des Caches ist nicht Teil der offiziellen Dokumentation, sondern basiert auf der Recherche innerhalb des Quelltextes von HyperGraphDB. Die dabei dokumentierten internen Abläufe wurden im Austausch mit dem Entwickler bestätigt: \url{https://groups.google.com/forum/?hl=de\#!topic/hypergraphdb/fmjdVtDxf-g.}} Für die Verwaltung der Duplikate nutzt HyperGraphDB Versioned Boxes\cite{Cachopo:2006:VBB:1228561.1228566}, das Vermitteln der Funktionsweise überschreitet jedoch den Rahmen der vorliegenden Evaluation und ist für das Verständnis der Transaktions- und Cacheverwaltung nicht erforderlich.

\subsection{Verteilung und Skalierbarkeit}

Die Verteilung der Datenbasis erfolgt in HyperGraphDB unter Verwendung eines integrierten Peer-to-Peer-Frameworks, welches verschiedene Mechanismen zur Kommunikation zwischen verteilten Datenbankinstanzen bereitstellt. Eine Peer-to-Peer-Kommunikation zeichnet sich im Gegensatz zur Client-Server-Kommunikation dadurch aus, dass alle Teilnehmer gleichberechtigt sind und innerhalb des Netzes keine zentrale Instanz existiert\cite{Tanenbaum:2002:CN:572404}. Für die Kommunikation zwischen den Peers setzt HyperGraphDB die standardisierte Agent Communication Language\footnote{\url{http://www.fipa.org/repository/aclspecs.html}} ein, die Übertragung erfolgt in Form von Nachrichten auf Grundlage des XMPP-Protokolls\footnote{\url{http://xmpp.org/xmpp-protocols/rfcs/}}. Die Kommunikation selbst ist  asynchron, was bedeutet, dass Nachrichten von Peers empfangen, in einem Pool gesammelt und anschließend in beliebiger Reihenfolge verarbeitet werden.

Intention von HyperGraphDB ist das Definieren einer Datenverteilung innerhalb der Anwendung, da diese unter Berücksichtigung von Domänenwissen besser entscheiden kann, wie die Daten zu partitionieren bzw. zu replizieren sind. Das Framework ist somit ausschließlich als Mittel zur Umsetzung konkreter Verteilungsalgorithmen gedacht. Auf eine detaillierte Beschreibung des Frameworks wird an dieser Stelle verzichtet, da dies nicht dem Schwerpunkt der Evaluation entspricht. Sollte HyperGraphDB für das Forschungsprojekt eingesetzt und dabei eine Verteilung realisiert werden, so findet sich eine ausführliche Beschreibung des Frameworks in der offiziellen Dokumentation.

In \cite{Iordanov:2010:HGG:1927585.1927589} wird ein sehr abstraktes Beispiel für die Umsetzung einer Replikation in HyperGraphDB vorgestellt. Auf dieser Grundlage wird nachfolgend - stark vereinfacht -  die mögliche Realisierung einer fragmentierten Replikation beschrieben: Ein Peer kann durch die Definition von Prädikaten die für ihn interessanten Atome festlegen. Zum Beispiel kann durch die Verwendung von Typ-Prädikaten bestimmt werden, welcher Peer die Instanzen eines Typs speichert. Folglich lässt sich durch Partitionierung des Schemas festlegen, welche Atome zusammen gespeichert sind. Die Anzahl der Peers, die das gleiche Typ-Prädikat besitzen, entspricht der Anzahl der Replikate der jeweiligen Instanzen. Die Prädikate aller Peers sind jedem Teilnehmer innerhalb des Netzwerkes bekannt. Sobald ein Atom ein definiertes Prädikat erfüllt, werden alle daran interessierten Peers benachrichtigt. Die Prüfung erfolgt event-basiert beim Erzeugen, Löschen oder Aktualisieren eines Atoms innerhalb einer Transaktion. Die Nachricht selbst beinhaltet die zugehörige Transaktion. Trifft die Nachricht beim Interessent ein, bestätigt er diese und entscheidet selbst, ob er die Transaktion ausführt oder verwirft. Die Konsistenz muss dabei durch Festlegen einer Ausführungsreihenfolge sichergestellt werden, dies erfolgt durch die Vergabe einer Versionsnummer. In \cite{Iordanov:2010:HGG:1927585.1927589} wird nicht definiert, wie diese innerhalb des Netzwerkes erzeugt wird, das Framework stellt jedoch sicher, dass letztendlich alle Peers eine konsistente Sicht auf die Daten aufweisen.\\
Durch eine anwendungsseitige Aufteilung des Schemas und die mehrfache Definition identischer Prädikate lässt sich somit eine fragmentierte Replikation umsetzen.