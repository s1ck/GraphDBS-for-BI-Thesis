\chapter{Evaluation von Graphdatenbanksystemen}
\label{cha:evaluation}

Dieses Kapitel setzt sich mit konkreten GDBMS-Implementierungen auseinander. Mit der Zielstellung, aus der Vielzahl existierender Systeme geeignete auszuwählen, werden zunächst funktionale Anforderungen definiert. Diese ergeben sich aus aktuellen Forschungsvorhaben am Lehrstuhl Datenbanken der Universität Leipzig. Die ausgewählten Systeme werden anschließend im Detail betrachtet, die Schwerpunkte dabei sind: Datenmodellierung und Konsistenzerhaltung, Zugriffsmechanismen und angebotene graphenspezifische Operationen, physische Repräsentation des Graphen und Möglichkeiten der Indexierung und Verteilung. Das Kapitel schließt mit einer Gegenüberstellung der Systeme.

\section{Aktuelle Forschungsvorhaben}
\label{sec:anforderungen}

Wie bereits im vorhergehenden Kapitel erläutert, ist ein Informationsnetzwerk der Netzwerktypus, in welchem Informationen in Form von Begriffen oder konkreten Daten miteinander verknüpft sind. Die Struktur des Netzwerkes ist dabei die Grundlage für Analysen, deren Ziel es ist, aus bestehenden Informationen neue Informationen abzuleiten, aus denen wiederum neues Wissen generiert werden soll. Im Bereich der Unternehmensdaten werden diese analytischen Verfahren und damit verbundene Anwendungen unter dem Begriff Business Intelligence (BI) zusammengefasst\cite{Watson:2007:CSB:1300761.1301970}. Unternehmen setzen BI ein, um möglichst gewinnbringende Informationen aus vorhandenen Daten zu extrahieren. Auf Basis dieser Informationen können der Zustand des Unternehmens eingeschätzt und Entscheidungen getroffen werden.

Verschiedene Bereiche eines Unternehmens nutzen unterschiedliche Geschäftsinformationssysteme zur Bewältigung ihrer Aufgaben. So unterscheidet man beispielsweise Systeme für Enterprise Resource Planning (ERP), Project Management (PM) und Customer Relationship Management (CRM), welche sich in technologischer, struktureller und semantischer Hinsicht unterscheiden können. BI setzt voraus, dass Daten aus heterogenen Systemen zunächst in ein System integriert werden, zu diesem Zweck werden Data Warehouses (DWH) eingesetzt\cite{Chaudhuri:2011:OBI:1978542.1978562, Watson:2007:CSB:1300761.1301970}. Ein DWH ist eine zentrale Datenbank, welche für Analysezwecke optimiert ist und in welcher Daten aus mehreren, i.A. heterogenen Quellen zusammengeführt, ggf. bereinigt und transformiert werden\cite{}. Im Rahmen der Transformation werden die Daten in ein einheitliches Schema überführt. Fakten werden in einer zentralen Tabelle hinterlegt und mit Dimensionstabellen verknüpft. Ein Fakt kann zum Beispiel der Kauf eines Produktes sein, der aus dem Kauf resultierende Umsatz ist die dem Fakt zugeordnete Kennzahl. Mögliche Dimensionen sind das Produkt, der Kaufzeitpunkt, der Kunde und die Filiale. Auf dieser Datenbasis sind vielfältige Analysen möglich, so können zum Beispiel der Umsatz in bestimmten Regionen, die Beliebtheit von Produkten oder die Rentabilität einzelner Filialen bestimmt werden.

Wie aus dem Beispiel des DWH hervorgeht, erfordert die Transformation das Definieren eines einheitlichen Schemas. Das bedeutet, dass die für die Analyse relevanten Beziehungen zwischen Dimensionen und Fakten vorab festgelegt werden müssen und somit jeder relevante Zusammenhang zwischen Fakt und Dimension bekannt sein und im Schema abgebildet werden muss. Dieser Sachverhalt schränkt jedoch die analytischen Möglichkeiten ein, da nur Zusammenhänge analysiert werden können, die im Schema definiert wurden. Unbekannte, eventuell nicht intuitiv erkennbare Zusammenhänge können in der Analyse nicht berücksichtigt werden.

Eines der Projekte am Lehrstuhl Datenbanken befasst sich mit der Entwicklung und Untersuchung von Methoden zur graphenbasierten Business Intelligence. Eine graphenbasierte Repräsentation von Unternehmensdaten weist die beschriebene Einschränkung eines vordefinierten Schemas nicht auf, vielmehr erlaubt sie die flexible Evaluation der Beziehungen zwischen einzelnen Objekten innerhalb der Unternehmensdaten. Diese lassen sich in zwei Kategorien einteilen: Transaktionale Daten und Stammdaten.
Zu den transaktionalen Daten gehören zum Beispiel Rechnungen im ERP-System, Plandaten im PM-System oder Kundenaktivitäten im CRM-System, sie entstehen bei der Ausführung von Geschäftsprozessen und sind sowohl untereinander als auch mit Stammdaten verknüpft. Beispiele für Stammdaten sind Informationen über Kunden, Produkte, Mitarbeiter oder Filialen. Aus diesem Zusammenhang lässt sich ein Graph ableiten: Transaktionale Daten und Stammdaten bilden die Knoten, der kausale und kontextuelle Zusammenhang zwischen ihnen wird durch Kanten beschrieben. Stammdaten weisen die Eigenschaft auf, dass sie in mehreren Systemen hinterlegt sein können, transaktionale Daten beschränken sich typischerweise auf das System, in dem sie erzeugt wurden. Beziehungen zwischen Objekten können generell systemübergreifend sein. Eine mögliche Analyse ist das Finden häufiger Muster. So lassen sich zum Beispiel Teilgraphen als Instanzen von Geschäftsprozessen extrahieren und hinsichtlich des Zusammenhangs zwischen erzeugtem Mehrwert und beteiligten Mitarbeitern untersuchen. Abbildung \ref{fig:bi-graph} zeigt ein Beispiel für einen aus Geschäftsdaten erzeugten Graphen.

Das Projekt verfolgt drei Ziele: Zunächst ist die Integration von Unternehmensdaten aus heterogenen Systemen in einen Graph erforderlich. Auf der Grundlage des integrierten Graphen werden in einer zweiten Phase Algorithmen für die graphenorientierte Analyse entwickelt. In der letzten Phase sollen Ansätze untersucht werden, die Datenbasis möglichst effizient für Analysten nutzbar zu machen, hierbei spielen insbesondere Anfragesprachen und Möglichkeiten zur Visualisierung eine Rolle. Für das Erreichen der Ziele sollen GDBMS die technologische Grundlage bilden, da sie eine flexible, graphenorientierte Datenmodellierung erlauben und Operationen zur Verfügung stellen unter deren Verwendung sich BI-orientierte Algorithmen implementieren lassen. Einige der verfügbaren Systeme beinhalten darüber hinaus bereits Anfragesprachen, welche als Basis für eigene Entwicklungen dienen können.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=0.45]{exa_docgraph.pdf}
	\caption[Beispiel: BI-Graph]{Informationsnetzwerk, welches die Beziehungen zwischen den Objekten eines ERP- und eines CRM-Systems darstellt. Transaktionale Daten sind weiß,  Stammdaten grau dargestellt. Bezeichner und Richtung einer Kante beschreiben den kausalen Zusammenhang zwischen transaktionalen Daten (z.B. \texttt{basedOn}, \texttt{serves}) sowie zwischen transaktionalen Daten und Stammdaten (z.B. \texttt{sentBy}, \texttt{doneFor}). Der gezeigte Teilgraph bildet die Instanz eines vollständigen Geschäftsprozesses ab, deren erzeugter Mehrwert sich aus den Einnahmen (engl. \textit{Revenue}) und Ausgaben (engl. \textit{Expense}) der transaktionalen Daten bestimmen lässt. Am Beispiel des Knotens \texttt{Employee (E01)} wird deutlich, dass Stammdaten in mehreren Systemen vorhanden sein können.}
	\label{fig:bi-graph}
\end{figure}

\input{Inhalt/Vorauswahl}

\input{Inhalt/Neo4j}
\input{Inhalt/HyperGraphDB}
\input{Inhalt/OrientDB}
\input{Inhalt/Titan}

\section{Zusammenfassung und Zwischenfazit}

\paragraph*{Dokumentation}

Neo4j
	- sehr gute Dokumentation
	- Weg der Länge $k$ führt zu $\mathcal{O}(\left|N(v_1)\right| \times \left|N(v_2)\right| \times \cdots \times \left|N(v_k)\right|)$
	- Support auf Mailingliste

HyperGraphDB
	- gut Dokumentation
	- Support auf Mailingliste
	
OrientDB
	- Dokumentation sehr eingeschränkt, inkonsistent, viel Quelltextrecherche
	- Support auf Mailingliste
	
Titan
	- gute Doku für junges Projekt
	- Support auf Mailingliste
	
\paragraph*{Datenmodell}

% Tabelle

- Neo4j: PGM + Knotenlabel
	- keine Objekteinbettung
	- keine Schemadefinition an Knoten und Kanten
- HyperGraphDB: 
	- Atom-Modell sehr generisch
	- Schema durch Klassendefinition
- OrientDB: 
	- Dokumentmodell als Basis
	- PGM auf Dokumente abgebildet 
	- Schema durch Klassendefinition
- Titan: PGM + TitanKey + TitanLabel
	- keine Schemadefinition an Knoten und Kanten
	- Einschränkung der Attribute
	- Einschränkung der Kanten
	- Einschränkung Datentypen
	- verschachtelte Attributwerte (Maps)
	- Vertex-centric Indices
	- unidirektionale Kanten

\paragraph*{Zugriffsmechanismen}

CRUD-Operationen:
	- Neo4j: CRUD
		- in nativer API und Cypher möglich
		- Algorithmen unterstützten Einschränkungen auf Graphen (im Gegensatz zu Blueprints)
	- HyperGraphDB: CRUD
	- OrientDB: CRUD
	- Titan: CRUD
Traversierung:
	- Neo4j:
		- algorithmische Traversierung mittels Traversal Framework -> Java
	- HyperGraphDB
		- algorithmische Traversierung mittels Traversal Framework -> Java
	- OrientDB
		- TRAVERSE-Operator oder Gremlin
	- Titan:
		- Gremlin, turing-mächtig
Erreichbarkeit
	- Neo4j:
		- native API stellt Algorithmen zur Verfügung
		- Cypher bietet shortestPath allShortestPath-Funktionen an
	- HyperGraphDB
		- durch Traversierung umsetzbar
		- Dijkstra-Implementierung
	- OrientDB
		- durch Traversierung umsetzbar
		- shortestPath und dijkstra in API
	- Titan
		- durch Traversierung umsetzbar
Mustersuche
	- Neo4j:
		- Cypher ermöglicht die Definition beliebiger Mustergraphen
	- HyperGraphDB
	 	- keine native Unterstützung
		- einfache Muster durch entsprechende Prädikatkombinationen
	- OrientDB
		- keine native Unterstützung
		- evtl. durch Schachtelung von SELECT und TRAVERSE
	- Titan
		- Musterdefinition via Gremlin und table-Funktion
		- weniger elegant als Cypher (= komplexer)
Aggregation und Summierung
	- Neo4j:
		- Aggregation ja
		- Summierung nein
	- HyperGraphDB
		- Aggregation nein -> (hg.apply)
		- Summierung nein
	- OrientDB
		- Aggregation ja
		- Summierung nein
	- Titan
		- Aggregation ja
		- Summierung nein
Metriken
	- Neo4j: allShortestPaths -> grundlage für centrality maße
	- bis auf Kardinalität der Knoten- / Kantenmenge nichts zusätzliches

Transaktionen
	- Neo4j: ACID, Locking, READ COMMITTED
	- HyperGraphDB: ACI(D), MVCC (GDBMS) + Locking (BerkeleyDB), SERIALIZABLE
	- OrientDB: ACID, MVCC, SERIALIZABLE
	- Titan: ACID, Locking (BerkeleyDB), SERIALIZABLE (BerkeleyDB)
	
\paragraph*{Speicherung und Caching}

- Neo4j: nativ
	- Trennung Topologie und Daten
	- Traversierung: O(1)
	- Fragmentierung der Stores
- HyperGraphDB: nicht-nativ
	- keine Trennung von Topologie und Daten
	- Speicherung in KV-Store 
	- Traversierung: O(logn)
- OrientDB: nativ
	- keine Trennung von Topologie und Daten 
	- Traversierung: O(N\_v)
	- Fragmentierung der Stores
	- attributierte Kanten sind zusätzliche Indirektion\url{https://github.com/orientechnologies/orientdb/wiki/Performance-Tuning-Blueprints}
- Titan: nicht-nativ
	- keine Trennung von Topologie und Daten
	- Speicherung in KV-Store 
	- Traversierung O(logn)
	- Ein Vorteil gegenüber OrientDB und HyperGraphDB, ist die Möglichkeit des direkten Zugriffes auf Attribute und inzidente Kanten eines Knotens unter Angabe der Knoten-Identität und der geforderten Column.

- generell: Beschleunigung via Caches -> Hashtabellen  O(1) (wenn da)


OrientDB:
	- widersprüchliche Dokumentation, wenig Beispiele
	- Bugs z.B. falsche Ergebnisse beim Traversieren, expand(shortestPath) und expand(dijkstra) haben 	kein Effekt

	- Ergebnisse zwischen Tiefen- und Breitensuche unterscheiden sich durch Verhindern des wiederholten Zugriffs

	- physische Repräsentation: Deserialisieren der Attribute kann sich negativ auf Performance auswirken, attributierte Kanten ebenfalls

\paragraph*{Titan}

- Besonderheit: 
	- out-unique Einschränkung innerhalb der Instanz
	- in-unique entspricht Unique in Neo4j
	- verschachtelte Attributwerte
	- Vertex-centric Indices
	- unidirektionale Kanten


