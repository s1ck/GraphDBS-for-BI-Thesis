\chapter{Evaluation von Graphdatenbanksystemen}
\label{cha:evaluation}

Dieses Kapitel setzt sich mit konkreten GDBMS-Implementierungen auseinander. Mit der Zielstellung, aus der Vielzahl existierender Systeme geeignete auszuwählen, werden zunächst funktionale Anforderungen definiert. Diese ergeben sich aus aktuellen Forschungsvorhaben am Lehrstuhl Datenbanken der Universität Leipzig. Die ausgewählten Systeme werden anschließend im Detail betrachtet, die Schwerpunkte dabei sind: Datenmodellierung und Konsistenzerhaltung, Zugriffsmechanismen und angebotene graphenspezifische Operationen, physische Repräsentation des Graphen und Möglichkeiten der Indexierung und Verteilung. Das Kapitel schließt mit einer Gegenüberstellung der Systeme.

\section{Aktuelle Forschungsvorhaben}
\label{sec:anforderungen}

Wie bereits im vorhergehenden Kapitel erläutert, ist ein Informationsnetzwerk der Netzwerktypus, in welchem Informationen in Form von Begriffen oder konkreten Daten miteinander verknüpft sind. Die Struktur des Netzwerkes ist dabei die Grundlage für Analysen, deren Ziel es ist, aus bestehenden Informationen neue Informationen abzuleiten, aus denen wiederum neues Wissen generiert werden soll. Im Bereich der Unternehmensdaten werden diese analytischen Verfahren und damit verbundene Anwendungen unter dem Begriff Business Intelligence (BI) zusammengefasst\cite{Watson:2007:CSB:1300761.1301970}. Unternehmen setzen BI ein, um möglichst gewinnbringende Informationen aus vorhandenen Daten zu extrahieren. Auf Basis dieser Informationen können der Zustand des Unternehmens eingeschätzt und Entscheidungen getroffen werden.

Verschiedene Bereiche eines Unternehmens nutzen unterschiedliche Geschäftsinformationssysteme zur Bewältigung ihrer Aufgaben. So unterscheidet man beispielsweise Systeme für Enterprise Resource Planning (ERP), Project Management (PM) und Customer Relationship Management (CRM), welche sich in technologischer, struktureller und semantischer Hinsicht unterscheiden können. BI setzt voraus, dass Daten aus heterogenen Systemen zunächst in ein System integriert werden, zu diesem Zweck werden Data Warehouses (DWH) eingesetzt\cite{Chaudhuri:2011:OBI:1978542.1978562, Watson:2007:CSB:1300761.1301970}. Ein DWH ist eine zentrale Datenbank, welche für Analysezwecke optimiert ist und in welcher Daten aus mehreren, i.A. heterogenen Quellen zusammengeführt, ggf. bereinigt und transformiert werden\cite{}. Im Rahmen der Transformation werden die Daten in ein einheitliches Schema überführt. Fakten werden in einer zentralen Tabelle hinterlegt und mit Dimensionstabellen verknüpft. Ein Fakt kann zum Beispiel der Kauf eines Produktes sein, der aus dem Kauf resultierende Umsatz ist die dem Fakt zugeordnete Kennzahl. Mögliche Dimensionen sind das Produkt, der Kaufzeitpunkt, der Kunde und die Filiale. Auf dieser Datenbasis sind vielfältige Analysen möglich, so können zum Beispiel der Umsatz in bestimmten Regionen, die Beliebtheit von Produkten oder die Rentabilität einzelner Filialen bestimmt werden.

Wie aus dem Beispiel des DWH hervorgeht, erfordert die Transformation das Definieren eines einheitlichen Schemas. Das bedeutet, dass die für die Analyse relevanten Beziehungen zwischen Dimensionen und Fakten vorab festgelegt werden müssen und somit jeder relevante Zusammenhang zwischen Fakt und Dimension bekannt sein und im Schema abgebildet werden muss. Dieser Sachverhalt schränkt jedoch die analytischen Möglichkeiten ein, da nur Zusammenhänge analysiert werden können, die im Schema definiert wurden. Unbekannte, eventuell nicht intuitiv erkennbare Zusammenhänge können in der Analyse nicht berücksichtigt werden.

Eines der Projekte am Lehrstuhl Datenbanken befasst sich mit der Entwicklung und Untersuchung von Methoden zur graphenbasierten Business Intelligence. Eine graphenbasierte Repräsentation von Unternehmensdaten weist die beschriebene Einschränkung eines vordefinierten Schemas nicht auf, vielmehr erlaubt sie die flexible Evaluation der Beziehungen zwischen einzelnen Objekten innerhalb der Unternehmensdaten. Diese lassen sich in zwei Kategorien einteilen: Transaktionale Daten und Stammdaten.
Zu den transaktionalen Daten gehören zum Beispiel Rechnungen im ERP-System, Plandaten im PM-System oder Kundenaktivitäten im CRM-System, sie entstehen bei der Ausführung von Geschäftsprozessen und sind sowohl untereinander als auch mit Stammdaten verknüpft. Beispiele für Stammdaten sind Informationen über Kunden, Produkte, Mitarbeiter oder Filialen. Aus diesem Zusammenhang lässt sich ein Graph ableiten: Transaktionale Daten und Stammdaten bilden die Knoten, der kausale und kontextuelle Zusammenhang zwischen ihnen wird durch Kanten beschrieben. Stammdaten weisen die Eigenschaft auf, dass sie in mehreren Systemen hinterlegt sein können, transaktionale Daten beschränken sich typischerweise auf das System, in dem sie erzeugt wurden. Beziehungen zwischen Objekten können generell systemübergreifend sein. Eine mögliche Analyse ist das Finden häufiger Muster. So lassen sich zum Beispiel Teilgraphen als Instanzen von Geschäftsprozessen extrahieren und hinsichtlich des Zusammenhangs zwischen erzeugtem Mehrwert und beteiligten Mitarbeitern untersuchen. Abbildung \ref{fig:bi-graph} zeigt ein Beispiel für einen aus Geschäftsdaten erzeugten Graphen.

Das Projekt verfolgt drei Ziele: Zunächst ist die Integration von Unternehmensdaten aus heterogenen Systemen in einen Graph erforderlich. Auf der Grundlage des integrierten Graphen werden in einer zweiten Phase Algorithmen für die graphenorientierte Analyse entwickelt. In der letzten Phase sollen Ansätze untersucht werden, die Datenbasis möglichst effizient für Analysten nutzbar zu machen, hierbei spielen insbesondere Anfragesprachen und Möglichkeiten zur Visualisierung eine Rolle. Für das Erreichen der Ziele sollen GDBMS die technologische Grundlage bilden, da sie eine flexible, graphenorientierte Datenmodellierung erlauben und Operationen zur Verfügung stellen unter deren Verwendung sich BI-orientierte Algorithmen implementieren lassen. Einige der verfügbaren Systeme beinhalten darüber hinaus bereits Anfragesprachen, welche als Basis für eigene Entwicklungen dienen können.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=0.45]{exa_docgraph.pdf}
	\caption[Beispiel: BI-Graph]{Informationsnetzwerk, welches die Beziehungen zwischen den Objekten eines ERP- und eines CRM-Systems darstellt. Transaktionale Daten sind weiß,  Stammdaten grau dargestellt. Bezeichner und Richtung einer Kante beschreiben den kausalen Zusammenhang zwischen transaktionalen Daten (z.B. \texttt{basedOn}, \texttt{serves}) sowie zwischen transaktionalen Daten und Stammdaten (z.B. \texttt{sentBy}, \texttt{doneFor}). Der gezeigte Teilgraph bildet die Instanz eines vollständigen Geschäftsprozesses ab, deren erzeugter Mehrwert sich aus den Einnahmen (engl. \textit{Revenue}) und Ausgaben (engl. \textit{Expense}) der transaktionalen Daten bestimmen lässt. Am Beispiel des Knotens \texttt{Employee (E01)} wird deutlich, dass Stammdaten in mehreren Systemen vorhanden sein können.}
	\label{fig:bi-graph}
\end{figure}

\input{Inhalt/Vorauswahl}

\input{Inhalt/Neo4j}
\input{Inhalt/HyperGraphDB}
\input{Inhalt/OrientDB}
\input{Inhalt/Titan}

\section{Zusammenfassung und Zwischenfazit}

\paragraph*{Neo4j}

Kritik:

- sehr gute Dokumentation
- keine Objekteinbettung
- keine Schemadefinition (attribute)
- Weg der Länge $k$ führt zu $\mathcal{O}(\left|N(v_1)\right| \times \left|N(v_2)\right| \times \cdots \times \left|N(v_k)\right|)$
- Fragmentierung der Stores
- Verteilung: was passiert bei Partitionierung des Netzwerkes

allShortestPaths -> grundlage für centrality maße

- CRUD
	- in Java API möglich
	- Algorithmen unterstützten Einschränkungen auf Graphen (im Gegensatz zu Blueprints)

- Traversierung
	- algorithmische Traversierung mittels Traversal Framework

- Erreichbarkeit
	- selber implementieren oder Dijkstra

- Mustersuche
	- nicht möglich

- Aggregation und Summierung
	- nicht möglich
	
\paragraph*{HyperGraphDB}

- CRUD
	- in nativer API und Cypher möglich

- Traversierung
	- algorithmische Traversierung mittels Traversal Framework

- Erreichbarkeit
	- native API stellt Algorithmen zur Verfügung
	- Cypher bietet shortestPath allShortestPath-Funktionen an

- Mustersuche
	- Cypher ermöglicht die Definition beliebiger Mustergraphen

- Aggregation und Summierung
	- Aggregation von Werten ist möglich
	- Summierung von topologischen Strukturen ist nicht möglich

- logarithmische Komplexität beim Zugriff auf die B-Bäume
	- indexfreie Adjazenz: Caches sind Hashtabellen, können aber nicht immer die komplette Datenbasis aufnehmen
- Verhungern langer Transaktionen (First-Come-First-Serve Prinzip)

\paragraph*{OrientDB}
- Avoid putting properties on edges -> \url{https://github.com/orientechnologies/orientdb/wiki/Performance-Tuning-Blueprints}

- widersprüchliche Dokumentation, wenig Beispiele
