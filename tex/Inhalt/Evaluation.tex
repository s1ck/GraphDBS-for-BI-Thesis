\chapter{Evaluation von Graphdatenbanksystemen}
\label{cha:evaluation}

Dieses Kapitel setzt sich mit konkreten GDBMS-Implementierungen auseinander. Mit der Zielstellung, aus der Vielzahl existierender Systeme geeignete auszuwählen, werden zunächst funktionale Anforderungen definiert. Diese ergeben sich aus aktuellen Forschungsvorhaben am Lehrstuhl Datenbanken der Universität Leipzig. Die ausgewählten Systeme werden anschließend im Detail betrachtet, die Schwerpunkte dabei sind: Datenmodellierung und Konsistenzerhaltung, Zugriffsmechanismen und angebotene graphenspezifische Operationen, physische Repräsentation des Graphen und Möglichkeiten der Indexierung und Verteilung. Das Kapitel schließt mit einer Gegenüberstellung der Systeme.

\section{Aktuelle Forschungsvorhaben}
\label{sec:anforderungen}

Wie bereits im vorhergehenden Kapitel erläutert, ist ein Informationsnetzwerk der Netzwerktypus, in welchem Informationen in Form von Begriffen oder konkreten Daten miteinander verknüpft sind. Die Struktur des Netzwerkes ist dabei die Grundlage für Analysen, deren Ziel es ist, aus bestehenden Informationen neue Informationen abzuleiten, aus denen wiederum neues Wissen generiert werden soll. Im Bereich der Unternehmensdaten werden diese analytischen Verfahren und damit verbundene Anwendungen unter dem Begriff Business Intelligence (BI) zusammengefasst\cite{Watson:2007:CSB:1300761.1301970}. Unternehmen setzen BI ein, um möglichst gewinnbringende Informationen aus vorhandenen Daten zu extrahieren. Auf Basis dieser Informationen können der Zustand des Unternehmens eingeschätzt und Entscheidungen getroffen werden.

Verschiedene Bereiche eines Unternehmens nutzen unterschiedliche Systeme zur Bewältigung ihrer Aufgaben. So unterscheidet man beispielsweise ERP-, PM- und CRM-Systeme, welche sich in technologischer, struktureller und semantischer Hinsicht unterscheiden können. BI setzt voraus, dass Daten aus heterogenen Systemen zunächst in ein System integriert werden, zu diesem Zweck werden Data Warehouses (DWH) eingesetzt\cite{Chaudhuri:2011:OBI:1978542.1978562, Watson:2007:CSB:1300761.1301970}. Ein DWH ist eine zentrale Datenbank, welche für Analysezwecke optimiert ist und in welcher Daten aus mehreren, i.A. heterogenen Quellen zusammengeführt, ggf. bereinigt und transformiert werden\cite{}. Im Rahmen der Transformation werden die Daten in ein einheitliches Schema überführt. Fakten werden in einer zentralen Tabelle hinterlegt und mit Dimensionstabellen verknüpft. Ein Fakt kann zum Beispiel der Kauf eines Produktes und der daraus resultierende Umsatz sein, mögliche Dimensionen sind das Produkt, der Kaufzeitpunkt, der Kunde und die Filiale. Auf dieser Datenbasis sind vielfältige Analysen möglich, so können zum Beispiel der Umsatz in bestimmten Regionen, die Beliebtheit von Produkten oder die Rentabilität einzelner Filialen bestimmt werden.

Wie aus dem Beispiel des DWH hervorgeht, erfordert die Transformation das Definieren eines einheitlichen Schemas. Das bedeutet, dass die für die Analyse relevanten Beziehungen zwischen Dimensionen und Fakten vorab festgelegt werden müssen und somit jeder relevante Zusammenhang zwischen Fakt und Dimension bekannt sein und im Schema abgebildet werden muss. Dieser Sachverhalt schränkt jedoch die analytischen Möglichkeiten ein, da nur Zusammenhänge analysiert werden können, die im Schema definiert wurden. Unbekannte, eventuell nicht intuitiv erkennbare Zusammenhänge können in der Analyse nicht berücksichtigt werden.

Eines der Projekte am Lehrstuhl Datenbanken befasst sich mit der Entwicklung und Untersuchung von Methoden zur graphenbasierten Business Intelligence. Eine graphenbasierte Repräsentation von Unternehmensdaten weist die beschriebene Einschränkung eines vordefinierten Schemas nicht auf, vielmehr erlaubt sie die flexible Evaluation der Beziehungen zwischen einzelnen Objekten innerhalb der Unternehmensdaten. Diese lassen sich in zwei Kategorien einteilen: Transaktionale Daten und Stammdaten.
Zu den transaktionalen Daten gehören zum Beispiel Rechnungen im ERP-System, Meeting-Protokolle im PM-System oder Kundenkontakte im CRM-System, sie entstehen innerhalb von Geschäftsprozessen und sowohl untereinander als auch mit Stammdaten verknüpft. Beispiele für Stammdaten sind Informationen über Kunden, Produkte, Mitarbeiter oder Filialen. Aus diesem Zusammenhang lässt sich ein Graph ableiten: Transaktionale Daten und Stammdaten bilden die Knoten, der kausale Zusammenhang zwischen ihnen wird durch Kanten beschrieben. Stammdaten weisen die Eigenschaft auf, dass sie in mehreren Systemen hinterlegt sein können, transaktionale Daten beschränken sich auf das System, in dem sie erzeugt wurden. Beziehungen zwischen Objekten können generell systemübergreifend sein. Eine mögliche Analyse ist das Finden häufiger Muster. So lassen sich zum Beispiel Teilgraphen zu bestimmten Geschäftsprozessen extrahieren und hinsichtlich des Zusammenhangs zwischen erzeugtem Mehrwert und beteiligten Mitarbeitern untersuchen. Abbildung \ref{fig:bi-graph} zeigt ein Beispiel für einen aus Geschäftsdaten erzeugten Graphen.

Das Projekt verfolgt drei Ziele: Zunächst ist die Integration von Unternehmensdaten aus heterogenen Systemen in einen Graph erforderlich. Auf der Grundlage des integrierten Graphen werden in einer zweiten Phase Algorithmen für die graphenorientierte Analyse entwickelt. In der letzten Phase sollen Ansätze untersucht werden, die Datenbasis möglichst effizient für Analysten nutzbar zu machen, hierbei spielen insbesondere Anfragesprachen und Möglichkeiten zur Visualisierung eine Rolle. Für das Erreichen der Ziele sollen GDBMS die technologische Grundlage bilden, da sie eine flexible, graphenorientierte Datenmodellierung erlauben und Operationen zur Verfügung stellen unter deren Verwendung sich BI-orientierte Algorithmen implementieren lassen. Einige der verfügbaren Systeme beinhalten darüber hinaus bereits Anfragesprachen, welche als Basis für eigene Entwicklungen dienen können.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=0.45]{exa_docgraph.pdf}
	\caption[Beispiel: BI-Graph]{Informationsnetzwerk, welches die Beziehungen zwischen den Objekten eines ERP- und eines CRM-Systems darstellt. Transaktionale Daten sind weiß,  Stammdaten grau dargestellt. Bezeichner und Richtung einer Kante beschreiben den kausalen Zusammenhang zwischen transaktionalen Daten (z.B. \texttt{basedOn}, \texttt{serves}) sowie zwischen transaktionalen Daten und Stammdaten (z.B. \texttt{sentBy}, \texttt{doneFor}). Der gezeigte Teilgraph bildet einen vollständigen Geschäftsprozess ab, dessen erzeugter Mehrwert sich aus den Einnahmen (engl. \textit{Revenue}) und Ausgaben (engl. \textit{Expense}) der transaktionalen Daten bestimmen lässt. Am Beispiel des Knotens \texttt{Employee (E01)} wird deutlich, dass Stammdaten in mehreren Systemen vorhanden sein können.}
	\label{fig:bi-graph}
\end{figure}

\section{Vorauswahl von Graphdatenbanksystemen}
\label{sec:vorauswahl}

Nachfolgend werden die Anforderungen an ein GDBMS für den Einsatz innerhalb des beschriebenen Projektes kategorisiert vorgestellt und vorhandene Implementierungen hinsichtlich der Erfüllung jener Anforderungen bewertet. Die Auswahl der Systeme erfolgte auf Grundlage von Literatur- und Webrecherche. Die Informationen zu den einzelnen GDBMS stammen von den Webseiten der Hersteller oder den primären Publikationen zu den jeweiligen Systemen. Eine Liste der Webseiten befindet sich in Anhang \ref{anh:vendor_list}.

Innerhalb jeder Kategorie werden obligatorische und optionale bzw. rein informative Anforderungen definiert. Ein GDBMS, welches eine verpflichtende Anforderung erfüllt, wird in der nachfolgenden Kategorie weiter betrachtet. Sollte nach der Betrachtung aller Kategorien die Kandidatenmenge zu groß sein, um im Rahmen dieser Arbeit evaluiert werden zu können, werden die optionalen Anforderungen in den Entscheidungsprozess einbezogen. Ziel ist die Auswahl von fünf GDBMS, welche die obligatorischen Anforderungen erfüllen, eine möglichst breite Verteilung über die vorgestellten GDBMS-Kategorien ist wünschenswert.

\paragraph*{Nutzbarkeit und Produktreife}

Eine der wichtigsten Anforderungen in dieser ersten Kategorie (Tabelle \ref{tab:nutzung}) ist die Quelloffenheit des GDBMS. Quellcode ist eine Dokumentationsart von Software, welche das Studium der exakten Funktionsweise ermöglicht. Widersprüche und Ungenauigkeiten innerhalb textueller Dokumentation können durch das Studium des Quellcodes ausgeglichen werden. Darüber hinaus soll das ausgewählte GDBMS als technologische Grundlage für Weiterentwicklungen innerhalb des Projektes dienen. Dies setzt ebenfalls Quelloffenheit und ein für die Nutzung geeignetes Lizenzmodell voraus. Eine ausreichende textuelle Dokumentation des Datenbanksystems ist ebenfalls erforderlich. Diese sollte wenigstens einen Überblick über die Architektur des GDBMS, die Zugriffsmechanismen und Installationsanweisungen enthalten.

Mit dem Ziel, eine möglichst stabile Software als Ausgangssituation nutzen zu können, wurde bei der Diskussion der Anforderungen festgelegt, dass es sich um ein Produktivsystem handeln muss, welches eine nachvollziehbar aktive Entwicklung aufweist. Ein Produktivsystem definiert sich dadurch, dass es mindestens einen stabilen Release aufweisen muss, die Aktivität kann anhand der Quelloffenheit der Systeme leicht nachvollzogen werden. Um als aktiv zu gelten, wurde ein Zeitraum von sechs Monaten festgelegt, in dem die Software Aktualisierungen erfahren haben muss.

Ein rein informatives Kriterium ist die Programmiersprache, in der das System entwickelt wird. Auffällig ist dabei, dass ein Großteil der GDBMS in Java implementiert ist. Generell ist Java aufgrund der persönlichen Erfahrung der Projektteilnehmer die bevorzugte Sprache, dies bedeutet jedoch nicht, dass objektiv bessere Systeme aufgrund ihrer Programmiersprache ausgeschlossen werden. Eine optionale Anforderung innerhalb dieser Kategorie ist die Unterstützung von Linux-basierten Betriebssystemen. Sollte das Projekt erfolgreich sein, ist eine Ausgründung vorgesehen. Aus diesem Grund soll vermieden werden, potentielle Kunden an eine proprietäre Plattform, wie zum Beispiel Microsoft Windows, zu binden.

Es kann nicht festgestellt werden, dass einzelne Anforderungen besonders häufig nicht erfüllt werden. Insgesamt werden die gestellten obligatorischen Anforderungen von neun GDBMS erfüllt, deren Evaluation in der nächsten Kategorie fortgesetzt wird.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{1.5cm}|>{\centering}m{2.5cm}|>{\centering}m{2.0cm}|c|c|>{\centering\arraybackslash}m{2cm}|}
	\hline
	\multicolumn{7}{|c|}{\textbf{Nutzbarkeit und Produktreife}} \\
	\hline
   	GDBMS & Quell-\newline~offen & Dokumentation & Produktiv-\newline~system & Sprache* & Aktiv & GNU/Linux* \\   
   	\hline
   	Affinity		& \checkmark	& \checkmark	& \checkmark	& C++	& \checkmark 	& \checkmark \\
   	ArangoDB		& \checkmark	& \checkmark	& \checkmark	& C/C++	& \checkmark	& \checkmark \\	
   	Bitsy			& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	DEX				& - 			& \checkmark	& \checkmark	& C++	& \checkmark	& \checkmark \\
   	Filament		& \checkmark	& \checkmark	& -				& Java	& \checkmark	& \checkmark \\
   	FlockDB			& \checkmark	& (\checkmark)	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	GraphBase		& -				& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	GraphPack		& \checkmark	& -				& -				& Java	& -				& \checkmark \\
   	G-Store			& -				& \checkmark	& -				& C/C++	& -				& - \\
   	Horton			& -				& -				& k.A.\tablefootnote{keine Angabe}	& k.A.	& k.A.			& - \\
   	HypergraphDB	& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	InfiniteGraph	& -				& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	Infogrid		& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	Fallen-8		& \checkmark	& -				& -				& C\#	& \checkmark	& \checkmark \\
   	Neo4j			& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	OQGRAPH			& \checkmark	& \checkmark	& \checkmark	& C		& \checkmark	& \checkmark \\
   	OrientDB		& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	RedisGraph		& \checkmark	& - 			& -				& Javascript & \checkmark	& \checkmark \\
   	SGDB3			& \checkmark	& -				& -				& Java	& -				& \checkmark \\
   	Titan			& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	Trinity			& -				& -				& k.A.			& k.A.	& k.A.			& - \\
   	VertexDB		& \checkmark	& \checkmark	& -				& C		& -				& \checkmark \\
   	\hline
   	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Nutzbarkeit und Produktreife]{Anforderungen an die Nutzbarkeit und Produktreife verschiedener GDBMS-Implementierungen. Mit * gekennzeichnete Anforderungen sind optional bzw. besitzen rein informativen Charakter.}
	\label{tab:nutzung}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Datenverwaltung und Datenmodellierung}

Datenmodell - grundsätzlich ist die Modellierung auch mit anderen Datenmodellen möglich (z.B. Zwischenknoten), wird jedoch hier nicht berücksichtigt um die Menge der zu vergleichenden Systeme einzuschränken
Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{3.5cm}|>{\centering}m{2.25cm}|>{\centering}m{1.5cm}|>{\centering}m{1.25cm}|>{\centering\arraybackslash}m{2.25cm}|}
	\hline
	\multicolumn{6}{|c|}{\textbf{Datenverwaltung und Datenmodellierung}} \\
	\hline
   	GDBMS & Datenmodell & Mehrere\newline~Datenbanken* & Schema* & ACID* & Integritäts-\newline bedingungen* \\   
   	\hline
   	Affinity		& Gerichteter, knotenattributierter Multigraph	& - & -	& \checkmark & \checkmark \\
   	ArangoDB		& PGM	& \checkmark & - & \checkmark & \checkmark \\
   	Bitsy			& PGM	& -	& -	& \checkmark & \checkmark \\
   	FlockDB			& Gerichteter, knotenattributierter, kantenbezeichneter Graph & \checkmark	& -	& -	& \checkmark \\
   	HypergraphDB	& PHGM	& -	& \checkmark & \checkmark & \checkmark \\
   	Infogrid		& Gerichteter, knotenattributierter, kantenbezeichneter Multigraph	& -	& \checkmark & \checkmark & \checkmark \\
   	Neo4j			& PGM	& -	& -	& \checkmark	& \checkmark \\
   	OQGRAPH			& Gerichteter, gewichteter Multigraph	& -	& -	& -	& \checkmark \\
   	OrientDB		& PGM	& -	& \checkmark	& \checkmark	& \checkmark \\
   	Titan			& PGM	& -	& \checkmark	& \checkmark	& \checkmark \\
   	\hline
   	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Datenverwaltung und Datenmodellierung]{Anforderungen hinsichtlich der Datenverwaltung und -modellierung innerhalb von GDBMS. (*optional/informativ)}
	\label{tab:verwaltung}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Zugriffsmechanismen}

Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{1.65cm}|>{\centering}m{1.25cm}|>{\centering}m{1.25cm}|>{\centering}m{1.25cm}|>{\centering\arraybackslash}m{2cm}|>{\centering}m{1.5cm}|>{\centering\arraybackslash}m{1.25cm}|}
	\hline
	\multicolumn{8}{|c|}{\textbf{Zugriffsmechanismen}} \\
	\hline
   	GDBMS & Embedded\newline API & Remote \newline API* & Plugin \newline API* & CRUD & Traversierung & Anfrage-\newline sprache* & Bulk\newline Load \\   
   	\hline   
   	ArangoDB		& -				& \checkmark 	& - 			& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	Bitsy			& \checkmark	& \checkmark	& -				& \checkmark 	& \checkmark & \checkmark	& -				\\
   	HypergraphDB	& \checkmark	& -				& - 			& \checkmark 	& \checkmark & - 			& -				\\
   	Neo4j			& \checkmark	& \checkmark	& \checkmark	& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	OrientDB		& \checkmark	& \checkmark	& -				& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	Titan			& \checkmark	& \checkmark	& \checkmark	& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	\hline
   	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Zugriffsmechanismen]{Anforderungen an die Zugriffsmechanismen von GDBMS. (*optional/informativ)}
	\label{tab:zugriff}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Speicherung}

Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{2.5cm}|>{\centering}m{2.5cm}|>{\centering}m{2.5cm}|>{\centering\arraybackslash}m{2.5cm}|}
	\hline
	\multicolumn{5}{|c|}{\textbf{Speicherung}} \\
	\hline
   	GDBMS & Persistenz & Native Speicherung*  & Hauptspeicher-\newline~zentriert* & Index-\newline unterstützung \\
   	\hline   
   	Bitsy			& \checkmark	& -				& \checkmark	& \checkmark 	\\
   	HypergraphDB	& \checkmark	& \checkmark	& - 			& \checkmark 	\\
   	Neo4j			& \checkmark	& \checkmark	& -				& \checkmark	\\
   	OrientDB		& \checkmark	& \checkmark	& -				& \checkmark	\\
   	Titan			& \checkmark	& -				& -				& \checkmark	\\
   	\hline
	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Speicherung]{Anforderungen an die Datenspeicherung in GDBMS. (*optional/informativ)}
	\label{tab:speicherung}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Skalierbarkeit und Verfügbarkeit}

Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{2.5cm}|>{\centering}m{2.5cm}|>{\centering\arraybackslash}m{2.5cm}|}
	\hline
	\multicolumn{4}{|c|}{\textbf{Skalierbarkeit und Verfügbarkeit}} \\
	\hline
   	GDBMS & Partitionierung* & Replikation*  & Backup* \\
   	\hline   
   	Bitsy			& -				& -				& \checkmark \\
   	HypergraphDB	& -				& \checkmark	& \checkmark \\
   	Neo4j			& -				& \checkmark	& \checkmark \\
   	OrientDB		& -				& \checkmark	& \checkmark \\
   	Titan			& \checkmark	& \checkmark	& \checkmark \\
   	\hline
	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Skalierbarkeit und Verfügbarkeit]{Anforderungen an die Skalierbarkeit und Verfügbarkeit von GDBMS. (*optional/informativ)}
	\label{tab:skalierbarkeit}
\end{table}
\renewcommand{\arraystretch}{1}

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.

\section{Neo4j}

Neo4j ist ein quelloffenes GDBMS, welches von der Firma Neo Technology\footnote{\url{http://www.neotechnology.com/}} entwickelt wird. Version 1.0 wurde 2010 veröffentlicht, zum aktuellen Zeitpunkt befindet sich Version 2.0 in Entwicklung. Die Implementierung des Systems erfolgt in den Programmiersprachen Java und Scala, die Ausführung erfolgt somit auf der Java Virtual Machine (JVM). Neo4j ist ein natives GDBMS, es unterstützt eine graphenorientierte Verarbeitung entsprechend der beschriebenen indexfreien Adjazenz und implementiert eine graphenorientierte physische Repräsentation der Datenbasis. Die Verwendung des Systems erfolgt entweder in Form einer eingebetteten Bibliothek innerhalb von Java-Anwendungen oder in einer Client-Server-Konfiguration. Letzteres erfordert den client-seitigen Zugriff über REST-Schnittstellen, entsprechende Clients stehen in vielen Programmiersprachen zur Verfügung\footnote{\url{http://www.neo4j.org/develop/drivers}}. Neo4j kann sowohl als zentrales GDBMS als auch in einer verteilten Konfiguration eingesetzt werden. Eine vollständige Replikation ermöglicht dabei die Skalierbarkeit lesender Anfragen und erhöht gleichzeitig die Ausfallsicherheit des Gesamtsystems. Die Speicherung der Datenbasis erfolgt disk-zentriert, ein hauptspeicher-zentrierter Betrieb ist nicht möglich.

Neo Technology bietet das Datenbanksystem in drei verschiedenen Ausführungen an: Community, Advanced und Enterprise. Die Community-Version bietet den grundlegendsten Funktionsumfang, während die Advanced-Version Monitoring-Funktionalität hinzufügt und die Enterprise-Version diese um Online-Backups und Hochverfügbarkeits-Mecha-nismen erweitert. Advanced- und Enterprise-Version eignen sich für den kommerziellen Einsatz, da sie zusätzliche Service-Leistungen durch Neo Technology beinhalten und ihre Lizenz die Verwendung in unfreier Software erlaubt. Die Community-Version darf nur in freier, quelloffener Software eingesetzt werden, Service-Anfragen werden durch die Neo4j-Community im Web beantwortet.

Die nachfolgenden Ausführungen beziehen sich auf Version 2.0.0-M04 des GDBMS, diese Version beinhaltet Erweiterungen hinsichtlich des Datenmodells und der Anfragesprache. Die Informationen stammen aus der offiziellen Neo4j-Dokumentation\cite{Neo4j_manual:2013} sowie aus den Ausführungen in \cite{robinson2013graph}.

\subsection{Datenmodell und Konsistenzerhaltung}

Neo4j implementiert das Property-Graph-Modell, dieses wird in der aktuellen Version um Knotenbezeichner erweitert. Mit deren Hilfe lassen sich Knoten zu Gruppen zusammenfassen. Ein Knoten kann keiner oder beliebig vielen Gruppen zugeordnet werden. Knoten- und Kantenbezeichner werden in Neo4j als Labels bezeichnet. Die Erweiterung um Knoten-Labels bietet verschiedene Vorteile: Anfragen lassen sich durch Einbeziehen von Labels auf einen Teilgraphen einschränken, was zum Einen die Formulierung von Anfragen stark vereinfacht und zum Anderen deren effizientere Ausführung ermöglichen kann. Labels sind jedoch nicht gleichbedeutend mit einer Relation in der relationalen Algebra, ein Label wird lediglich durch seinen Namen definiert, es wird kein Schema der zugeordneten Elemente vorgegeben. Sie sind jedoch ein nützliches Werkzeug in der strukturierten Anwendungsmodellierung und können zur Laufzeit an Knoten hinzugefügt und entfernt werden. 

Beziehungen zwischen Knoten werden durch Kanten beschrieben. In Neo4j sind diese grundsätzlich gerichtet, besitzen also immer Start- und Zielknoten, Schleifen\footnote{Eine Kante ist eine Schleife, wenn Start- und Endknoten identisch sind\cite{DBLP:books/daglib/0030488}.} sind ebenfalls zulässig. Kanten lassen sich in beiden Richtungen traversieren, d.h. eine bidirektionale Beziehung erfordert nicht zwingend die Definition von zwei Kanten unterschiedlicher Richtung. Eine Kante besitzt immer ein Label, welches zusammen mit der Richtung der Kante deren Semantik festlegt. Genau wie Knoten besitzen auch Kanten eine eindeutige Identität in Form einer 64-Bit Ganzzahl, diese wird vom GDBMS verwaltet und kann nicht durch die Anwendung geändert werden. Die Identität einer Kante ermöglicht die Definition paralleler Kanten mit gleichen Labels.

Knoten und Kanten lassen sich in Neo4j mit optionalen Attributen in Form von Schlüssel-Wert-Paaren versehen, sie werden in Neo4j als Properties bezeichnet. Property-Schlüssel sind vom Typ \texttt{String}, zulässige  Property-Werte müssen Instanzen eines primitiven Java-Datentypen (z.B. \texttt{int}, \texttt{float}) sein. Arrays von primitiven Datentypen sind ebenfalls zulässige Werte. Weist eine Instanz einen Wert nicht auf, so wird dies durch das Weglassen des entsprechenden Schlüssel-Wert-Paares definiert und nicht durch die Verwendung von \texttt{null} als Wert.

Mit dem Ziel, Datenintegrität zu gewährleisten, sieht das Modell verschiedene Mechanismen vor. Eine Kante kann nur zwischen existierenden Knoten erzeugt werden, das Löschen eines Knotens erfordert das vorherige Löschen aller inzidenten Kanten des Knotens. Diese Zusicherung kann als Analogie zur referentiellen Integrität\cite{vossen2008datenmodelle} in relationalen Datenbanksystemen verstanden werden. Neo4j unterstützt darüber hinaus auch attributbezogene Integritätsbedingungen. Die Festlegung einer eindeutigen Identität durch das GDBMS entspricht einer Primärschlüssel-Definition, die Definition eines Datentyps für Attributwerte stellt eine Wertebereichs-Einschränkung dar und darüber hinaus unterstützt Neo4j die Definition einer \texttt{UNIQUE}-Bedingung für Knotenattribute. Letztere legt fest, dass ein Wert in der Menge aller Werte eines Schlüssels einzigartig sein muss. Diese Bedingung lässt sich nur in Verbindung mit Knoten-Labels definieren.

Neo4j verwaltet exakt eine Graphdatenbank, alle Knoten und Kanten sind dieser Datenbank zugeordnet. Eine logische Partitionierung der Knotenmenge ist durch Labels oder dedizierte Attribute möglich, soll auch die Kantenmenge partitioniert werden, so ist dies ausschließlich über Attribute möglich. 

Aus den Ausführungen wird deutlich, dass Neo4j in Version 2.0 eine schema-optionale Datenbank darstellt. Es besteht die Möglichkeit, die Datenbank ohne jegliche Berücksichtigung eines Schemas zu verwenden, durch die optionalen Knoten-Labels ist es jedoch möglich, ein solches zu definieren und von den Vorteilen, wie strukturierter Anwendungsmodellierung, vereinfachten Anfragen und effizienter Anfrageausführung zu profitieren. Das Datenmodell eignet sich somit in Anwendungen, bei denen die Anforderungen nicht zu Beginn vollständig erfasst werden können und eine hohe Flexibilität hinsichtlich Schemaänderungen erforderlich ist.

\subsection{Zugriffsmechanismen und graphenspezifische Operationen}

Neo4j bietet vier Möglichkeiten unterschiedlicher Mächtigkeit für den Zugriff auf die Datenbasis an: Core API, Traversal Framework sowie die Anfragesprachen Cypher und Gremlin. Alle Zugriffsmechanismen lassen sich sowohl im eingebetteten Betrieb als auch in der Client-Server-Konfiguration via REST verwenden. Cypher ist die primäre Anfragesprache von Neo4j und wird von Neo Technology entwickelt. Gremlin entstand hingegen im Rahmen des Blueprints-Projektes\footnote{https://github.com/tinkerpop/blueprints/wiki}. Es handelt sich dabei um eine Sammlung von Schnittstellen und Implementierungen, welche die Verarbeitung von Graphen unterstützen und sich dabei am PGM orientieren. Gremlin ist Teil dieser Sammlung und wird unter anderem von Titan und Bitsy als primäre Anfragesprache eingesetzt. Die  Erläuterung von Gremlin erfolgt im Zusammenhang mit den zwei genannten Systemen.

\paragraph*{Core API}

Die Core API ist eine imperative Java-API und stellt CRUD-Operationen für den Lese- und Schreibzugriff auf Knoten, Kanten und Properties zur Verfügung. Knoten können erzeugt und optional mit Labels und Properties versehen werden. Kanten werden unter Angabe existierender Knoten erstellt, dabei impliziert die Knotenreihenfolge die Richtung der Kante, ein Label ist obligatorisch. Letzteres kann innerhalb der Anwendung statisch hinterlegt oder dynamisch zur Laufzeit erzeugt werden. Eine Kanteninstanz erlaubt das Auslesen des Start- und Endknotens, des Labels und - sofern vorhanden - der Properties. Das Aktualisieren von Knoten und Kanten ist ebenfalls mit der nativen API möglich, Knotenlabels können jederzeit angefügt oder entfernt werden, Knoten- und Kantenproperties lassen sich unter Berücksichtigung der zulässigen Datentypen beliebig manipulieren. Das Löschen von Knoten und Kanten ist unter Beachtung der referentiellen Integrität ebenfalls möglich.

Es sollte deutlich werden, dass sich ausgehend von der nativen API beliebige Graphalgorithmen anwendungsseitig implementieren lassen. Ein Beispiel für die Verwendung der nativen API befindet sich in Anhang \ref{anh:neo4j_native_api}. Neo4j bietet in der nativen Java-API bereits eine Algorithmensammlung zur Berechnung von Pfaden an. Hierbei können Pfade fester und beliebiger Länge, sowie kürzeste Pfade in ungewichteten und gewichteten Graphen berechnet werden. Für letztere steht eine  Implementierung des Dijkstra-Algorithmus zur Verfügung. Der ebenfalls implementierte A*-Algorithmus erlaubt die Definition beliebiger Heuristiken zur Priorisierung von Kanten, die Berechnung in ungewichteten Graphen erfolgt mittels Breitensuche. In allen Fällen können die zu traversierenden Kantenlabel vorgegeben werden sowie einzelne oder alle Pfadinstanzen berechnet werden.

\paragraph*{Traversal Framework}

Das Traversal Framework ist eine Erweiterung der Core API. Es ermöglicht die Definition eines abstrakten Weges und liefert als Ergebnis eine Menge von Instanzen dieses Weges. Die Ausführung der Traversierung erfolgt Iterator-basiert, was bedeutet, dass die eigentliche Berechnung eines Weges erst bei Anfrage der nächsten Instanz ausgeführt wird.\footnote{Diese Strategie wird auch als \textit{Lazy Evaluation} bezeichnet.} Das Framework umfasst mehrere Schnittstellen, mit deren Hilfe der Nutzer den abstrakten Weg beschreiben und das Verhalten der Traversierung beeinflussen kann. Es ist ausschließlich der lesende Zugriff auf die Datenbasis möglich.

Ausgangspunkt einer Traversierung ist die \texttt{TraversalDescription}, eine Schnittstelle zur Beschreibung und Initialisierung einer Traversierung. Zunächst lässt sich mit Hilfe eines \texttt{PathExpander} festlegen, welche Kantenlabels bei der Traversierung zu berücksichtigen sind. Das Weglassen dieser Information, führt zur Traversierung aller Kanten. Die Angabe eines Labels ermöglicht zudem das optionale Festlegen einer Richtung der zugehörigen Kanteninstanzen. Stehen mehrere Kantenlabels zur Auswahl, so kann durch die Reihenfolge ihrer Aufzählung die Priorität bei der Traversierung bestimmt werden. Durch das Whitelist-Prinzp ist das Ausschließen definierter Kantenlabels nicht möglich.\\
Eine weitere wichtige Schnittstelle ist \texttt{Path}, diese erfüllt zwei Aufgaben: Zum Einen sind die Ergebnisse der Traversierung Instanzen dieser Schnittstelle und zum Anderen wird sie für die Evaluation der aktuellen Position innerhalb des Graphen während der Traversierung verwendet. Im Rahmen der Evaluation wird entschieden, ob der aktuelle Knoten in das Ergebnis aufgenommen und ob die Traversierung ausgehend von der aktuellen Position fortgesetzt werden soll. Es handelt sich somit um ein Filter- und Abbruchkriterium für die Traversierung. Die Entscheidungslogik wird unter Verwendung der Schnittstelle \texttt{Evaluator} implementiert.

Neben den genannten Schnittstellen zur Definition des abstrakten Weges, lässt sich das Verhalten der Traversierung durch weitere Schnittstellen beeinflussen. Der Graph kann mittels Breiten- oder Tiefensuche durchlaufen werden, alternativ kann ein beliebiges Vorgehen, wie zum Beispiel das randomisierte, durch die Implementierung einer\linebreak~\texttt{BranchOrderingPolicy} beschrieben werden. Durch die Implementierung der Schnittstelle \texttt{BranchSelector} wird dabei festgelegt, welche Kante als nächstes traversiert wird. An dieser Stelle können zum Beispiel Heuristiken in die Entscheidung einbezogen werden.\\
Mittels \texttt{Uniqueness} lässt sich festlegen, wie oft ein Objekt während der Traversierung besucht werden darf. Objekte sind Knoten oder Kanten, diese können entweder global oder innerhalb des bisher traversierten Pfades eindeutig sein. Die Festlegung ist insbesondere in zyklischen Graphen notwendig, standardmäßig wird die globale Eindeutigkeit von Knoten gefordert.

Eine den Anforderungen entsprechend definierte \texttt{TraversalDescription} wird unter Angabe eines Startknotens instanziiert. Das Ergebnis dieses Aufrufs ist ein \texttt{Traverser}-Objekt, welches den Iterator zur Verfügung stellt. In Anhang \ref{anh:neo4j_traversal_framework} findet sich ein Beispiel für die Traversierung.

Das Traversal Framework erweitert die Core API um ein grundsätzlich deklaratives Hilfskonstrukt mit welchem die Datenbasis beliebig traversiert werden kann.  Die Implementierung der Abbruch- und Filterkriterien erfolgt imperativ unter Verwendung der Core API. Hinsichtlich der Programmierbarkeit steht somit ein universelles Werkzeug für die Verarbeitung von Graphen zur Verfügung. Dies stellt jedoch gleichzeitig ein entscheidendes Defizit hinsichtlich des Zugriffs auf die Datenbasis für Nicht-Programmierer dar. Neo4j bietet mit der Anfragesprache Cypher eine entsprechende Alternative.

\paragraph*{Cypher}

Cypher ist eine deklarative, graphenorientierte Anfragesprache für den lesenden und schreibenden Zugriff auf die Datenbasis. Es handelt sich um eine nicht standardisierte Sprache, welche aktuell in Neo4j und in abgeänderter Form im GDBMS-Prototypen GraphPack zur Verfügung steht. Syntaktisch ist Cypher an SQL und SPARQL angelehnt, viele der dort vorhandenen Sprachkonstrukte und Ansätze werden konsequent wiederverwendet. Kernelement der Sprache ist das Beschreiben von Mustergraphen zur Informationsextraktion. Das Prüfen der Erreichbarkeit und insbesondere das Berechnen kürzester Pfade ist darüber hinaus ebenfalls möglich. Nachfolgend wird der grundlegende Umfang der Sprache dargestellt, eine detaillierte Beschreibung kann der offiziellen Dokumentation entnommen werden\cite{Neo4j_manual:2013}.

Eine rein lesende Anfrage setzt sich aus den folgenden Komponenten zusammen:

\texttt{[START] [MATCH] [WHERE]\newline
[WITH [ORDER BY] [SKIP] [LIMIT]]\newline
RETURN [ORDER BY] [SKIP] [LIMIT]}.

In der optionalen \texttt{START}-Klausel werden Bezeichner festgelegt und an Knoten- oder Kanteninstanzen gebunden. Die Auswahl einer Instanz erfolgt dabei entweder unter Angabe ihrer Identität oder mittels indexbasierter Suche. Zum Beispiel führt die Anweisung 

\texttt{START a=node:Employees(name=\string"Alice\string")} 

zur Suche nach einem Knoten mit der Eigenschaft \texttt{name=\string"Alice\string"} innerhalb des Index\linebreak \texttt{Employees}. Existiert eine entsprechende Instanz, erfolgt die Bindung an den Bezeichner \texttt{a}. Trifft die Bedingung auf mehrere Instanzen zu, so verweist \texttt{a} auf die entsprechende Menge. Alle gebundenen Bezeichner können in den nachfolgenden Teilen der Anfrage verwendet werden. Zulässige Datentypen für Bezeichner und Variablen sind generell Knoten, Kanten, Pfade und Literale bzw. Mengen der genannten.

Wird keine \texttt{START}-Klausel definiert, ist die nachfolgende \texttt{MATCH}-Klausel obligatorisch. Sie ermöglicht die Definition eines Mustergraphen zum Auslesen von Informationen aus der Datenbasis. Ein Mustergraph besteht aus einer beliebigen Anzahl Variablen, welche beim Finden einer Übereinstimmung an Objektinstanzen gebunden werden. Mit dem Ziel, einen Mustergraphen in Textform zu repräsentieren, wird dieser in Fragmente zerlegt, wobei jedes Fragment der Definition eines abstrakten Weges entspricht. Der in Abbildung \ref{fig:neo4j_pattern_graph} gezeigte Mustergraph lässt sich durch zwei Fragmente beschreiben:

\texttt{MATCH\newline
c:Employee---a-[:WORKS\_WITH]->b:Employee-[:WORKS\_WITH]->c, // 1\newline
b-[:RESPONSIBLE\_FOR]->d:Project // 2}

Innerhalb des Musters sind die in der \texttt{START}-Klausel definierten Bezeichner die Konstanten und stellen somit die Verbindungen zwischen Muster und Datenbasis her. Neo4j bezeichnet diese als \textit{bound pattern elements}, im Beispiel ist dies der Knoten \texttt{a}. Die Variablen \texttt{b}, \texttt{c} und \texttt{d} werden beim Finden einer Übereinstimmung an Knoten- bzw. Kanteninstanzen gebunden, alle Variablen stehen in den nachfolgenden Teilen der Anfrage zur Verfügung. Am Beispiel wird die Verwendung der Knotenlabel deutlich: Die Variablen \texttt{b} und \texttt{c} legen das Label gebundener Knoteninstanzen auf \texttt{Employee} fest, während die Variable \texttt{d} die Menge möglicher Instanzen auf Projekte einschränkt. Die Angabe eines Kantenlabels ist optional, so verlangt das erste Fragment im Beispiel eine Kante mit beliebiger Richtung und beliebigem Label zwischen den Knoten \texttt{c} und \texttt{a}, wohingegen zwischen den Knoten \texttt{b} und \texttt{d} eine gerichtete Kante mit dem Label \texttt{RESPONSIBLE\_FOR} existieren muss. Es besteht darüber hinaus die Möglichkeit, mehrere Kantenlabel zwischen zwei Knoten zu erlauben und einen Bereich für die Länge des Weges zwischen den Knoten festzulegen. Dies ermöglicht das Finden von Pfaden beliebiger und fester Länge und führt zu einer hohen Flexibilität bei der Analyse von Beziehungsmustern. Der kürzeste Pfad kann ebenfalls als Fragment eines Mustergraphen definiert werden. So bindet zum Beispiel der Ausdruck

\texttt{MATCH p = shortestPath(a:Employee-[*..5]-b:Project)}

die Variable \texttt{p} an die Instanz des kürzesten Pfades zwischen Mitarbeiter \texttt{a} und Projekt \texttt{b}. Die Länge des Pfades muss zwischen 0 und 5 sein, Kantenlabel und -richtung  werden nicht berücksichtigt. Alternativ liefert die Funktion \texttt{allShortestPaths} alle kürzesten Pfade zwischen zwei Knoten.\\
Steht die \texttt{MATCH}-Klausel am Beginn der Anfrage, dann ist in diesem Abschnitt kein Bezeichner gebunden. Folglich wird entweder die vollständige Datenbasis nach dem Muster durchsucht, oder anhand von eventuell definierten Labels die Menge der Objekte eingeschränkt. Alternativ können Prädikate in der nachfolgenden \texttt{WHERE}-Klausel zur Einschränkung des Suchraums genutzt werden.
	 
Die \texttt{WHERE}-Klausel entspricht der Selektion in der relationalen Algebra. Sie ist optional und ermöglicht die Filterung von Ergebnistupeln mittels Prädikaten. Cypher bietet eine Vielzahl mathematischer, vergleichender und boolescher Operatoren für die Definition und Verknüpfung von Prädikaten an. Soll zum Beispiel im Mustergraphen das Attribut \texttt{age} der an die Variable \texttt{b} gebundenen Instanzen eingeschränkt werden, so ist dies mit folgender Anweisung möglich:

\texttt{WHERE b.age? > 23 AND b.age? < 42}

Da Properties keinem Schema unterliegen, kann mittels \texttt{?}-Operator geprüft werden, ob die entsprechende Instanz diesen Attributschlüssel besitzt. Ist dies nicht der Fall, wird \texttt{True} zurückgegeben.

Die ebenfalls optionale \texttt{WITH}-Klausel besitzt kein Pendant in der relationalen Algebra, sondern entspricht der Funktionsweise des Pipe-Operators der Linux-Shell. Mit dessen Hilfe lassen sich Operationen verketten: Die Ausgabe einer Operation kann als Eingabe der Folgeoperation verwendet werden. Dies ist in Cypher genau dann erforderlich, wenn zum Beispiel Aggregate innerhalb einer \texttt{WHERE}-Bedingung verwendet werden sollen oder wenn lesende und schreibende Anfragen verkettet ausgeführt und die Sichtbarkeit der Variablen in Folgeoperationen gegeben sein muss.

Am Ende einer rein lesenden Cypher-Anfrage befindet sich die obligatorische \texttt{RETURN}-Klausel, diese entspricht der Projektion in der relationalen Algebra. Sie legt fest, aus welchen Variablen sich das Anfrageergebnis zusammensetzt und ermöglicht die Umformung der gesamten Ergebnismenge bzw. einzelner Variablenwerte. Analog zu SQL kann das Ergebnis mit \texttt{ORDER BY} sortiert, sowie durch \texttt{SKIP} und \texttt{LIMIT} eingeschränkt werden.

Cypher ermöglicht die Berechnung von Aggregaten sowohl in der \texttt{RETURN}- als auch in der \texttt{WITH}-Klausel, verschiedene Aggregatfunktionen, wie zum Beispiel \texttt{min}, \texttt{max} und \texttt{avg}, stehen zur Verfügung. Darüber hinaus ermöglicht Cypher die Verwendung von skalaren (z.B. \texttt{LENGTH} und \texttt{TYPE}), mathematischen (z.B. \texttt{ABS} und \texttt{ROUND}), string-basierten (z.B. \texttt{SUBSTRING} und \texttt{LOWER}) und mengenorientierten (z.B. \texttt{FILTER} und \texttt{REDUCE}) Funktionen.

\texttt{MATCH}-, \texttt{WITH}- und \texttt{WHERE}-Klauseln lassen sich beliebig oft in beliebiger Reihenfolge kombinieren, so können zum Beispiel Ergebnismengen oder Aggregate in einer nachfolgenden Musterdefinition verwendet werden. Analog zum Traversal Framework werden rein lesende Anfragen erst ausgeführt, wenn der Nutzer auf die Ergebnisse zugreift, dies ist insbesondere dann sinnvoll, wenn ein Muster keine Bindung zur Datenbasis besitzt und diese folglich komplett durchsucht werden muss.

Neben rein lesenden Anfragen ist auch die Modifikation der Datenbasis mit Cypher möglich. Unter Verwendung der \texttt{CREATE}-Klausel lassen sich Knoten- und Kanteninstanzen mit Labels und Properties erzeugen, 
mit der \text{SET}-Klausel Properties und Knotenlabel aktualisieren und die \texttt{DELETE} Klausel ermöglicht das Löschen von Instanzen.

Die Sprache befindet sich in permanenter Weiterentwicklung, was bedeutet, dass mit Änderungen und Erweiterungen der Syntax zu rechnen ist. Schwerpunkt der Version 2.0 ist unter anderem die automatische Anfrageoptimierung. Eine manuelle Anfrageoptimierung ist möglich, der Ausführungsplan einer Cypher-Anfrage lässt sich im eingebetteten Betrieb zusammen mit dem Anfrageergebnis abrufen und evaluieren.\\ Ein Vorteil gegenüber den bisher vorgestellten Zugriffsmöglichkeiten ist der rein deklarative Charakter der Sprache. Im Gegensatz zur Core API wird in Cypher festgelegt \textit{was} gesucht wird und nicht \textit{wie} es gesucht wird. Dies ermöglicht zum Einen eine abstrakte Anfrageformulierung und zum Anderen mehr Möglichkeiten der systemseitigen Anfrageoptimierung. Demgegenüber ermöglichen es Core API und Traversal Framework eigene Algorithmen zu implementieren und somit spezielle Anwendungsfälle abzudecken. Die Aufgabe der Abstraktion erfordert dabei einen höheren Entwicklungsaufwand und eine engere Kopplung an die Struktur der hinterlegten Daten, kann jedoch zu höherer Performance führen, da gezielt optimiert werden kann und die Schritte Anfrageübersetzung und -optimierung entfallen.

\paragraph*{Transaktionen}

Alle Zugriffe auf die Datenbasis müssen innerhalb einer Transaktion erfolgen. Bei der Verwendung von Cypher erfolgt das Starten einer Transaktion implizit, ist bereits eine Transaktion im aktuellen Kontext aktiv, wird diese genutzt. Bei Verwendung der Core API müssen Transaktionen explizit gestartet werden. Nach einer Reihe von Lese- und Schreiboperationen wird die Transaktion entweder erfolgreich beendet (Commit) oder bei Eintritt eines Fehlers zurückgesetzt (Rollback). Um eventuell gehaltene Sperren freizugeben, muss die Transaktion grundsätzlich finalisiert werden.\footnote{Dies orientert sich am \texttt{try-catch-finally}-Prinzip zur Behandlung von Ausnahmen in Java.}

In Neo4j werden flache Transaktionen unterstützt, die sich im Quellcode jedoch auch beliebig schachteln lassen. Diese als \textit{Flat Nested Transactions} bezeichnete Umsetzung zeichnet sich dadurch aus, dass ein Rollback einer untergeordneten Transaktion nicht isoliert, sondern nur über den Rollback der übergeordneten Transaktion erfolgen kann. Dieser rekursive Ansatz hat bei Abbruch einer beliebigen untergeordneten Transaktion den Abbruch der Gesamttransaktion zur Folge.

Zur Vermeidung von Mehrbenutzeranomalien werden pessimistische RX-Sperrverfahren\footnote{Beim RX-Sperrverfahren sind Lesesperren verschiedener Transaktionen auf dem gleichen Objekt kompatibel zueinander. Ist hingegen eine Schreibsperre auf einem Objekt gesetzt, so ist dieses exklusiv für eine Transaktion gesperrt, Lese- oder Schreibanforderungen auf das gesperrte Objekt werden ablehnt\cite{DBLP:books/sp/HarderR01}.} eingesetzt. Bei einem schreibenden Zugriff auf ein Objekt wird eine exklusive Sperre für das entsprechende Objekt gesetzt und bis zum Ende der Transaktion gehalten. Lesesperren werden hingegen nur für die Dauer des Lesevorgangs gehalten. Eine Transaktion sieht folglich nur eigene Änderungen und die Änderungen bereits beendeter Transaktionen. Entsprechend dem strikten Zwei-Phasen-Sperrprotokoll\footnote{Im Zwei-Phasen-Sperrprotokoll werden in einer Wachstumsphase zunächst alle benötigten Sperren angefordert. Nachdem die erste Sperre wieder freigegeben wurde, dürfen keine neuen Anforderungen erfolgen, es beginnt die Schrumpfungsphase in der Sperren nur noch freigegeben werden. Mit dem Ziel, Dirty Reads und kaskadierende Rücksetzungen infolge von Systemfehlern zu vermeiden, werden beim strikten Zwei-Phasen-Sperrprotokoll alle Sperren gleichzeitig freigegeben\cite{DBLP:books/sp/HarderR01}.} werden alle Schreibsperren am Ende der Transaktion gleichzeitig freigegeben.\\
Die langen Schreibsperren vermeiden das Problem der \textit{Dirty Reads}, durch die kurzen Lesesperren sind jedoch die Anomalien \textit{Non-Repeatable Read}, \textit{Phantom Problem} und vor allem auch \textit{Lost Update} möglich. Dieser Zustand entspricht der Isolationsebene \texttt{READ COMMITTED}, sollen höhere Isolationsebenen wie zum Beispiel \texttt{REPEATABLE READ} oder\linebreak \texttt{SERIALIZABLE} erreicht werden, so liegt dies in der Verantwortung des Programmierers. Neo4j stellt Funktionen bereit, manuell Lese- bzw. Schreibsperren auf Knoten oder Kanten zu setzen.\\
Beim Einsatz exklusiver Sperren können wechselseitige Abhängigkeiten und somit Deadlocks entstehen. Neo4j begegnet diesem Problem mit Deadlock-Erkennung: Wird beim Anfordern einer exklusiven Sperre ein potentieller Deadlock erkannt, wird die anfordernde Transaktion zurückgesetzt.

Änderungen von Transaktionen erfolgen zunächst ausschließlich im Hauptspeicher. Neo4j implementiert eine NoSteal-Strategie\cite{DBLP:books/sp/HarderR01}, bei der das Ausschreiben geänderter Objekte auf den Hintergrundspeicher vor dem Commit einer Transaktion nicht zulässig ist. Diese Strategie führt dazu, dass nach einem Ausfall des GDBMS keine inkonsistenten Änderungen in der Datenbasis vorhanden sein können und somit keine UNDO-Informationen während der Transaktionsausführung gespeichert werden müssen. Die Atomarität von Transaktionen wird durch dieses Vorgehen sichergestellt. Ein Nachteil dieser Strategie ist, dass sehr umfangreiche Änderungstransaktionen durch den verfügbaren Hauptspeicher limitiert sind, ihre Aufspaltung in mehrere kleinere Änderungstransaktion kann erforderlich sein.\\
Neben der Atomarität ist auch die Dauerhaftigkeit von Änderungen ein wesentliches Ziel von Transaktionen. Damit diese erreicht werden kann, führt Neo4j ein Transaktions-Log, in dem alle Änderungen protokolliert werden. Beim erfolgreichen Beenden einer Transaktion wird ein Commit-Eintrag in die Log-Datei geschrieben, welcher dazu führt, dass alle transienten Änderungen der Log-Datei auf dem Hintergrundspeicher persistiert werden. Beim Ausfall des GDBMS können somit alle bis dahin erfolgreich beendeten Transaktionen wiederhergestellt werden. Das Ausschreiben der Änderungen in die Datenbasis kann somit verzögert erfolgen. Dieses Vorgehen wird auch als NoForce-Strategie bezeichnet\cite{DBLP:books/sp/HarderR01} und ermöglicht gegenüber dem unmittelbaren Ausschreiben beim Commit einen höheren Durchsatz von Schreiboperationen.

Die Bewahrung der Konsistenz innerhalb der Datenbasis ist ebenfalls ein entscheidendes Kriterium bei der Ausführung von Transaktionen. Die bereits erwähnten modellinhärenten Integritätsbedingungen sind hierfür maßgeblich verantwortlich.

\subsection{Persistenz- und Cacheverwaltung}

Neo4j ist ein natives GDBMS, was bedeutet, dass die physische Repräsentation der Datenbasis für die graphenorientierte Verarbeitung optimiert ist. Mit dem Ziel, indexfreie Adjazenz zu erreichen, wird die Datenbank auf mehrere Dateien sog. Stores aufgeteilt. Dabei soll durch die Trennung von Topologie und Nutzdaten das performante Traversieren des Graphen ermöglicht werden. Es existieren Stores für Knoten, Kanten, Properties und Knoten- bzw. Kantenlabels. Die Stores werden zusammen in einem benutzerdefinierten Verzeichnis gespeichert, welches gleichzeitig die Identität der Datenbank darstellt.\\
Die Einträge in den Stores, die nachfolgend als Satz bzw. Datensatz bezeichnet werden, besitzen ein festes Format und somit eine feste Satzlänge. Dies hat den Vorteil, dass bei Angabe einer Identität, z.B. der Knoten-Identität 23, die Position des Knotens innerhalb des Stores durch Multiplikation mit der Satzlänge in $\mathcal{O}(1)$ berechnet werden kann. Nachfolgend werden die Stores für Knoten, Kanten und Properties kurz beschrieben. Die zur Persistenz verfügbare Dokumentation bezieht sich auf die stabile Version 1.9 des GDBMS, in dieser sind Knotenlabel nicht implementiert. Die folgenden Informationen stammen zum Teil aus dem Quellcode der Version 2.0.0-M04, dies wird an entsprechender Stelle gekennzeichnet.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=0.75]{neo4j_node_record.pdf}
	\caption[Neo4j: Datensatz eines Knotens]{Physische Repräsentation eines Knotens in Neo4j. Der Datensatz hat eine feste Länge von 14 Byte.}
	\label{fig:neo4j-node-record}
\end{figure}

In Abbildung \ref{fig:neo4j-node-record} wird der schematische Aufbau eines Datensatzes im Knoten-Store dargestellt, jeder Datensatz besitzt eine Länge von 14 Byte.\footnote{\url{https://github.com/neo4j/neo4j/blob/86b3c3e9b7c133011831cc1a7a9d8537e2b949f2/community/kernel/src/main/java/org/neo4j/kernel/impl/nioneo/store/NodeStore.java\#L68}} Das erste Byte beinhaltet ein Flag, welches signalisiert, ob der entsprechende Knoten aktuell verwendet wird oder überschrieben werden kann. Eine Liste freier Identitäten wird in einer dedizierten Datei geführt, beim Löschen eines Knotens wird dessen Identität der Liste hinzugefügt und das Flag entsprechend gesetzt. Die folgenden vier Byte speichern die Identität der ersten Kante, die sich anschließenden vier Byte die Identität der ersten Property des Knotens. In den letzten fünf Byte werden entweder die Label-Identitäten des Knotens direkt gespeichert oder auf eine Property verwiesen, welche die Knotenlabels beinhaltet. Das Format ist somit sehr leichtgewichtig und enthält fast ausschließlich Zeiger auf zugehörige Datensätze.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=0.75]{neo4j_edge_record.pdf}
	\caption[Neo4j: Datensatz einer Kante]{Physische Repräsentation einer Kante in Neo4j. Der Datensatz hat eine feste Länge von 33 Byte.}
	\label{fig:neo4j-edge-record}
\end{figure}

Wie Abbildung \ref{fig:neo4j-edge-record} zu entnehmen ist, besitzt der Datensatz einer Kante im Vergleich zum Datensatz eines Knotens einen deutlich komplexeren Aufbau. Ziel ist es, ausgehend von einer Kante möglichst effizient an weitere inzidente Kanten der Start- und Zielknoten zu gelangen. Zu diesem Zweck wird für beide Knoten je eine doppelt verkettete Liste inzidenter Kanten verwaltet. Jede Kante ist Element in zwei doppelt verketteten Listen und besitzt einen Verweis auf die vorhergehende und nachfolgende inzidente Kante des Start- bzw. Zielknotens. Durch die feste Satzlänge im Kanten-Store, ist das Berechnen der Position in $\mathcal{O}(1)$, das Traversieren der Nachbarschaft eines Knotens $v$ folglich in $\mathcal{O}(\left|N(v)\right|)$ möglich. Das Einfügen und Löschen in doppelt verketteten Listen erfolgt ebenfalls in $\mathcal{O}(1)$ \cite{ottmann2002algorithmen}.

Das Flag am Beginn des Satzes besitzt den gleichen Zweck wie im bereits beschriebenen Knotenformat. In den sich anschließenden acht Byte werden die Identitäten des Start- und Zielknotens gespeichert und somit die Richtung der Kante festgelegt. Die nächsten vier Byte beinhalten die Identität des Kantenlabels, welches in einem entsprechenden Store hinterlegt ist. In den nachfolgenden 16 Byte werden die Identitäten adjazenter Kanten gespeichert. Der Verweis auf die erste Property befindet sich am Ende des Satzes. Durch die feste Satzlänge in Label- und Property-Stores ist der Zugriff auf einzelne Elemente ebenfalls in konstanter Zeit möglich, die Komplexität der Traversierung wird demnach nicht durch die Einschränkung auf bestimmte Labels oder Properties beeinflusst.

\begin{figure}[h]
	\centering	
	\subfigure[Vollständiger Datensatz]{\label{fig:neo4j-property-record}\includegraphics[scale=0.75]{neo4j_property_record.pdf}}\qquad	
	\subfigure[Einzelner Property-Block]{\label{fig:neo4j-property-block-record}\includegraphics[scale=0.75]{neo4j_property_block_record.pdf}}	
	\caption[Neo4j: Datensatz einer Property]{Physische Repräsentation von Properties in in Neo4j. Der komplette Datensatz hat eine feste Länge von 41 Byte wobei 32 Byte für vier Property-Blöcke zur Verfügung stehen.}
\end{figure}

Knoten- und Kantenproperties werden ebenfalls in einer doppelt verketteten Liste verwaltet. Abbildung \ref{fig:neo4j-property-record} zeigt den schematischen Aufbau eines entsprechenden Datensatzes.\footnote{\url{https://github.com/neo4j/neo4j/blob/86b3c3e9b7c133011831cc1a7a9d8537e2b949f2/community/kernel/src/main/java/org/neo4j/kernel/impl/nioneo/store/PropertyStore.java\#L57-L60}} In den ersten neun Byte werden vorhergehende und nachfolgende Property referenziert. Für Nutzdaten stehen insgesamt 32 Byte zur Verfügung, diese werden in vier Blöcke zu je acht Byte aufgeteilt. Jeder Block ermöglicht das Speichern einer Property und ist wie folgt aufgebaut (Abbildung \ref{fig:neo4j-property-block-record}): Die ersten vier Byte beinhalten einen Index-Schlüssel, mit dessen Hilfe sich der Property-Schlüssel aus einem Property-Index abrufen lässt. Das nächste Byte speichert den Typ des Property-Wertes, für letzteren sind die übrigen drei Byte des Blocks reserviert. Reichen diese nicht aus, können bis zu drei weitere Blöcke innerhalb des Datensatzes verwendet werden. Folglich lassen sich maximal vier Properties in einem Datensatz speichern. Für große Zeichenketten und Arrays werden spezielle dynamische Stores verwaltet, auf diese wird in den letzten drei Byte eines Blocks referenziert. Der erwähnte Property-Index dient der Reduktion des Speicherbedarfs, da mehrfach verwendete Property-Schlüssel nur einmal im Index gespeichert werden und ihr zugehöriger Index-Schlüssel in den Property-Blöcken referenziert wird.
	
Aus den Ausführungen geht hervor, dass sich die Position eines Datensatzes in konstanter Zeit berechnen lässt. Der wahlfreie Zugriff auf Elemente innerhalb des Graphen bedingt jedoch auch den wahlfreien Zugriff auf die Stores und damit auf den langsamen Hintergrundspeicher. Wie für disk-zentrierte DBMS üblich, besitzt auch Neo4j Caches bzw. Puffer um einen möglichst großen Teil der Datenbasis im Hauptspeicher vorzuhalten. In der Architektur werden zwei Caches unterschieden: Der Filesystem-Cache und der Object-Cache.

Der Filesystem-Cache beschleunigt sowohl Lese- und Schreibzugriffe. Jedem Store wird ein dedizierter Cache zugewiesen, dieser teilt den Store in eine feste Anzahl Bereiche gleicher Größe auf und hält einige dieser Bereiche im Hauptspeicher. Die Cache-Größen können manuell konfiguriert werden, erfolgt dies nicht, orientiert sich die Größe am verfügbaren Hauptspeicher, der JVM-Heap-Größe und der Größe der Stores. Als Ersetzungsverfahren wird Least Frequently Used (LFU) implementiert. Es handelt sich um ein Verfahren, welches jene Bereiche verdrängt, auf die selten zugegriffen wird\cite{DBLP:books/sp/HarderR01}. Neo4j nutzt standardmäßig Memory Mapped Files des Betriebssystems und überlässt somit diesem die Entscheidung, welche Teile des virtuellen Speichers im Hauptspeicher gehalten und welche auf den Hintergrundspeicher geschrieben werden.

Das Instanziieren von Java-Objekten aus der physischen Repräsentation kostet Zeit, häufig verwendete Objekte sollen demnach innerhalb des Object-Caches vorgehalten werden. Dieser soll insbesondere Lesezugriffe und das damit verbundene Traversieren beschleunigen. Alle Objekte innerhalb des Graphen werden beim ersten Zugriff instanziiert. Das bedeutet, dass zum Beispiel die inzidenten Kanten eines Knotens erst beim Abfragen der Nachbarschaft geladen und im Cache gruppiert nach Label und Richtung am Knoten abgelegt werden. Properties werden satzweise geladen, ausgelagerte Properties, wie lange Zeichenketten oder Arrays, erst beim direkten Zugriff. Der Object-Cache benötigt im Gegensatz zum Filesystem-Cache mehr Hauptspeicher für das Verwalten der gleichen Anzahl an Objekten.\footnote{Die Repräsentation eines Knotens ohne Kanten und Properties als Java-Objekt benötigt zum Beispiel 344 Byte im Hauptspeicher. Der entsprechende Datensatz umfasst 14 Byte.} In der Community-Edition überlässt Neo4j der JVM die Verwaltung des Caches. Dies hat zwei wesentliche Nachteile: Zum Einen teilt sich ein eingebettetes GDBMS den verfügbaren Speicher mit der Anwendung und zum Anderen entscheidet der Garbage Collector der JVM zu welchem Zeitpunkt Referenzen freigegeben werden. Letzteres erfolgt außerhalb der Kontrolle des GDBMS und kann in ungünstigen Situationen zu starken Leistungseinbrüchen führen. Die Enterprise-Edition beinhaltet eine eigene Cache-Implementierung mit fester Cache-Größe und manueller Objekt-Ersetzung, was mehr Kontrolle über die gepufferten Objekte ermöglicht.

\subsection{Möglichkeiten der Verteilung}

Blubb

\section{HypergraphDB}

Blubb

\subsection{Datenmodell und Konsistenzerhaltung}

Blubb

\subsection{Zugriffsmechanismen und graphenspezifische Operationen}

Blubb

\subsection{Persistenz und Indexierung}

Blubb

\subsection{Verteilung}

Blubb

\section{OrientDB}

Blubb

\subsection{Datenmodell}

Blubb

\subsection{Zugriffsmechanismen}

Blubb

\subsection{Persistenz}

Blubb

\subsection{Verteilung}

Blubb

\section{Titan}

Blubb

\subsection{Datenmodell}

Blubb

\subsection{Zugriffsmechanismen}

Blubb

\subsection{Persistenz}

Blubb

\subsection{Verteilung}

Blubb


\section{Gegenüberstellung}

\subsection{Unterstützung graphenspezifischer Operationen}

\paragraph*{Neo4j}

Kritik:

- Weg der Länge $k$ führt zu $\mathcal{O}(\left|N(v_1)\right| \times \left|N(v_2)\right| \times \cdots \times \left|N(v_k)\right|)$
- Fragmentierung der Stores

allShortestPaths -> grundlage für centrality maße

- CRUD
	- in nativer API und Cypher möglich

- Traversierung
	- algorithmische Traversierung mittels Traversal Framework

- Erreichbarkeit
	- native API stellt Algorithmen zur Verfügung
	- Cypher bietet shortestPath allShortestPath-Funktionen an

- Mustersuche
	- Cypher ermöglicht die Definition beliebiger Mustergraphen

- Aggregation und Summierung
	- Aggregation von Werten ist möglich
	- Summierung von topologischen Strukturen ist nicht möglich


