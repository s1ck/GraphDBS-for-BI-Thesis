\chapter{Evaluation von Graphdatenbanksystemen}
\label{cha:evaluation}

Dieses Kapitel setzt sich mit konkreten GDBMS-Implementierungen auseinander. Mit der Zielstellung, aus der Vielzahl existierender Systeme geeignete auszuwählen, werden zunächst funktionale Anforderungen definiert. Diese ergeben sich aus aktuellen Forschungsvorhaben am Lehrstuhl Datenbanken der Universität Leipzig. Die ausgewählten Systeme werden anschließend im Detail betrachtet, die Schwerpunkte dabei sind: Datenmodellierung und Konsistenzerhaltung, Zugriffsmechanismen und angebotene graphenspezifische Operationen, physische Repräsentation des Graphen und Möglichkeiten der Indexierung und Verteilung. Das Kapitel schließt mit einer Gegenüberstellung der Systeme.

\section{Aktuelle Forschungsvorhaben}
\label{sec:anforderungen}

Wie bereits im vorhergehenden Kapitel erläutert, ist ein Informationsnetzwerk der Netzwerktypus, in welchem Informationen in Form von Begriffen oder konkreten Daten miteinander verknüpft sind. Die Struktur des Netzwerkes ist dabei die Grundlage für Analysen, deren Ziel es ist, aus bestehenden Informationen neue Informationen abzuleiten, aus denen wiederum neues Wissen generiert werden soll. Im Bereich der Unternehmensdaten werden diese analytischen Verfahren und damit verbundene Anwendungen unter dem Begriff Business Intelligence (BI) zusammengefasst\cite{Watson:2007:CSB:1300761.1301970}. Unternehmen setzen BI ein, um möglichst gewinnbringende Informationen aus vorhandenen Daten zu extrahieren. Auf Basis dieser Informationen können der Zustand des Unternehmens eingeschätzt und Entscheidungen getroffen werden.

Verschiedene Bereiche eines Unternehmens nutzen unterschiedliche Systeme zur Bewältigung ihrer Aufgaben. So unterscheidet man beispielsweise ERP-, PM- und CRM-Systeme, welche sich in technologischer, struktureller und semantischer Hinsicht unterscheiden können. BI setzt voraus, dass Daten aus heterogenen Systemen zunächst in ein System integriert werden, zu diesem Zweck werden Data Warehouses (DWH) eingesetzt\cite{Chaudhuri:2011:OBI:1978542.1978562, Watson:2007:CSB:1300761.1301970}. Ein DWH ist eine zentrale Datenbank, welche für Analysezwecke optimiert ist und in welcher Daten aus mehreren, i.A. heterogenen Quellen zusammengeführt, ggf. bereinigt und transformiert werden\cite{}. Im Rahmen der Transformation werden die Daten in ein einheitliches Schema überführt. Fakten werden in einer zentralen Tabelle hinterlegt und mit Dimensionstabellen verknüpft. Ein Fakt kann zum Beispiel der Kauf eines Produktes und der daraus resultierende Umsatz sein, mögliche Dimensionen sind das Produkt, der Kaufzeitpunkt, der Kunde und die Filiale. Auf dieser Datenbasis sind vielfältige Analysen möglich, so können zum Beispiel der Umsatz in bestimmten Regionen, die Beliebtheit von Produkten oder die Rentabilität einzelner Filialen bestimmt werden.

Wie aus dem Beispiel des DWH hervorgeht, erfordert die Transformation das Definieren eines einheitlichen Schemas. Das bedeutet, dass die für die Analyse relevanten Beziehungen zwischen Dimensionen und Fakten vorab festgelegt werden müssen und somit jeder relevante Zusammenhang zwischen Fakt und Dimension bekannt sein und im Schema abgebildet werden muss. Dieser Sachverhalt schränkt jedoch die analytischen Möglichkeiten ein, da nur Zusammenhänge analysiert werden können, die im Schema definiert wurden. Unbekannte, eventuell nicht intuitiv erkennbare Zusammenhänge können in der Analyse nicht berücksichtigt werden.

Eines der Projekte am Lehrstuhl Datenbanken befasst sich mit der Entwicklung und Untersuchung von Methoden zur graphenbasierten Business Intelligence. Eine graphenbasierte Repräsentation von Unternehmensdaten weist die beschriebene Einschränkung eines vordefinierten Schemas nicht auf, vielmehr erlaubt sie die flexible Evaluation der Beziehungen zwischen einzelnen Objekten innerhalb der Unternehmensdaten. Diese lassen sich in zwei Kategorien einteilen: Transaktionale Daten und Stammdaten.
Zu den transaktionalen Daten gehören zum Beispiel Rechnungen im ERP-System, Meeting-Protokolle im PM-System oder Kundenkontakte im CRM-System, sie entstehen innerhalb von Geschäftsprozessen und sowohl untereinander als auch mit Stammdaten verknüpft. Beispiele für Stammdaten sind Informationen über Kunden, Produkte, Mitarbeiter oder Filialen. Aus diesem Zusammenhang lässt sich ein Graph ableiten: Transaktionale Daten und Stammdaten bilden die Knoten, der kausale Zusammenhang zwischen ihnen wird durch Kanten beschrieben. Stammdaten weisen die Eigenschaft auf, dass sie in mehreren Systemen hinterlegt sein können, transaktionale Daten beschränken sich auf das System, in dem sie erzeugt wurden. Beziehungen zwischen Objekten können generell systemübergreifend sein. Eine mögliche Analyse ist das Finden häufiger Muster. So lassen sich zum Beispiel Teilgraphen zu bestimmten Geschäftsprozessen extrahieren und hinsichtlich des Zusammenhangs zwischen erzeugtem Mehrwert und beteiligten Mitarbeitern untersuchen. Abbildung \ref{fig:bi-graph} zeigt ein Beispiel für einen aus Geschäftsdaten erzeugten Graphen.

Das Projekt verfolgt drei Ziele: Zunächst ist die Integration von Unternehmensdaten aus heterogenen Systemen in einen Graph erforderlich. Auf der Grundlage des integrierten Graphen werden in einer zweiten Phase Algorithmen für die graphenorientierte Analyse entwickelt. In der letzten Phase sollen Ansätze untersucht werden, die Datenbasis möglichst effizient für Analysten nutzbar zu machen, hierbei spielen insbesondere Anfragesprachen und Möglichkeiten zur Visualisierung eine Rolle. Für das Erreichen der Ziele sollen GDBMS die technologische Grundlage bilden, da sie eine flexible, graphenorientierte Datenmodellierung erlauben und Operationen zur Verfügung stellen unter deren Verwendung sich BI-orientierte Algorithmen implementieren lassen. Einige der verfügbaren Systeme beinhalten darüber hinaus bereits Anfragesprachen, welche als Basis für eigene Entwicklungen dienen können.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=0.45]{exa_docgraph.pdf}
	\caption[Beispiel: BI-Graph]{Informationsnetzwerk, welches die Beziehungen zwischen den Objekten eines ERP- und eines CRM-Systems darstellt. Transaktionale Daten sind weiß,  Stammdaten grau dargestellt. Bezeichner und Richtung einer Kante beschreiben den kausalen Zusammenhang zwischen transaktionalen Daten (z.B. \texttt{basedOn}, \texttt{serves}) sowie zwischen transaktionalen Daten und Stammdaten (z.B. \texttt{sentBy}, \texttt{doneFor}). Der gezeigte Teilgraph bildet einen vollständigen Geschäftsprozess ab, dessen erzeugter Mehrwert sich aus den Einnahmen (engl. \textit{Revenue}) und Ausgaben (engl. \textit{Expense}) der transaktionalen Daten bestimmen lässt. Am Beispiel des Knotens \texttt{Employee (E01)} wird deutlich, dass Stammdaten in mehreren Systemen vorhanden sein können.}
	\label{fig:bi-graph}
\end{figure}

\section{Vorauswahl von Graphdatenbanksystemen}
\label{sec:vorauswahl}

Nachfolgend werden die Anforderungen an ein GDBMS für den Einsatz innerhalb des beschriebenen Projektes kategorisiert vorgestellt und vorhandene Implementierungen hinsichtlich der Erfüllung jener Anforderungen bewertet. Die Auswahl der Systeme erfolgte auf Grundlage von Literatur- und Webrecherche. Die Informationen zu den einzelnen GDBMS stammen von den Webseiten der Hersteller oder den primären Publikationen zu den jeweiligen Systemen. Eine Liste der Webseiten befindet sich in Anhang \ref{anh:vendor_list}.

Innerhalb jeder Kategorie werden obligatorische und optionale bzw. rein informative Anforderungen definiert. Ein GDBMS, welches eine verpflichtende Anforderung erfüllt, wird in der nachfolgenden Kategorie weiter betrachtet. Sollte nach der Betrachtung aller Kategorien die Kandidatenmenge zu groß sein, um im Rahmen dieser Arbeit evaluiert werden zu können, werden die optionalen Anforderungen in den Entscheidungsprozess einbezogen. Ziel ist die Auswahl von fünf GDBMS, welche die obligatorischen Anforderungen erfüllen, eine möglichst breite Verteilung über die vorgestellten GDBMS-Kategorien ist wünschenswert.

\paragraph*{Nutzbarkeit und Produktreife}

Eine der wichtigsten Anforderungen in dieser ersten Kategorie (Tabelle \ref{tab:nutzung}) ist die Quelloffenheit des GDBMS. Quellcode ist eine Dokumentationsart von Software, welche das Studium der exakten Funktionsweise ermöglicht. Widersprüche und Ungenauigkeiten innerhalb textueller Dokumentation können durch das Studium des Quellcodes ausgeglichen werden. Darüber hinaus soll das ausgewählte GDBMS als technologische Grundlage für Weiterentwicklungen innerhalb des Projektes dienen. Dies setzt ebenfalls Quelloffenheit und ein für die Nutzung geeignetes Lizenzmodell voraus. Eine ausreichende textuelle Dokumentation des Datenbanksystems ist ebenfalls erforderlich. Diese sollte wenigstens einen Überblick über die Architektur des GDBMS, die Zugriffsmechanismen und Installationsanweisungen enthalten.

Mit dem Ziel, eine möglichst stabile Software als Ausgangssituation nutzen zu können, wurde bei der Diskussion der Anforderungen festgelegt, dass es sich um ein Produktivsystem handeln muss, welches eine nachvollziehbar aktive Entwicklung aufweist. Ein Produktivsystem definiert sich dadurch, dass es mindestens einen stabilen Release aufweisen muss, die Aktivität kann anhand der Quelloffenheit der Systeme leicht nachvollzogen werden. Um als aktiv zu gelten, wurde ein Zeitraum von sechs Monaten festgelegt, in dem die Software Aktualisierungen erfahren haben muss.

Ein rein informatives Kriterium ist die Programmiersprache, in der das System entwickelt wird. Auffällig ist dabei, dass ein Großteil der GDBMS in Java implementiert ist. Generell ist Java aufgrund der persönlichen Erfahrung der Projektteilnehmer die bevorzugte Sprache, dies bedeutet jedoch nicht, dass objektiv bessere Systeme aufgrund ihrer Programmiersprache ausgeschlossen werden. Eine optionale Anforderung innerhalb dieser Kategorie ist die Unterstützung von Linux-basierten Betriebssystemen. Sollte das Projekt erfolgreich sein, ist eine Ausgründung vorgesehen. Aus diesem Grund soll vermieden werden, potentielle Kunden an eine proprietäre Plattform, wie zum Beispiel Microsoft Windows, zu binden.

Es kann nicht festgestellt werden, dass einzelne Anforderungen besonders häufig nicht erfüllt werden. Insgesamt werden die gestellten obligatorischen Anforderungen von neun GDBMS erfüllt, deren Evaluation in der nächsten Kategorie fortgesetzt wird.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{1.5cm}|>{\centering}m{2.5cm}|>{\centering}m{2.0cm}|c|c|>{\centering\arraybackslash}m{2cm}|}
	\hline
	\multicolumn{7}{|c|}{\textbf{Nutzbarkeit und Produktreife}} \\
	\hline
   	GDBMS & Quell-\newline~offen & Dokumentation & Produktiv-\newline~system & Sprache* & Aktiv & GNU/Linux* \\   
   	\hline
   	Affinity		& \checkmark	& \checkmark	& \checkmark	& C++	& \checkmark 	& \checkmark \\
   	ArangoDB		& \checkmark	& \checkmark	& \checkmark	& C/C++	& \checkmark	& \checkmark \\	
   	Bitsy			& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	DEX				& - 			& \checkmark	& \checkmark	& C++	& \checkmark	& \checkmark \\
   	Filament		& \checkmark	& \checkmark	& -				& Java	& \checkmark	& \checkmark \\
   	FlockDB			& \checkmark	& (\checkmark)	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	GraphBase		& -				& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	GraphPack		& \checkmark	& -				& -				& Java	& -				& \checkmark \\
   	G-Store			& -				& \checkmark	& -				& C/C++	& -				& - \\
   	Horton			& -				& -				& k.A.\tablefootnote{keine Angabe}	& k.A.	& k.A.			& - \\
   	HypergraphDB	& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	InfiniteGraph	& -				& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	Infogrid		& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	Fallen-8		& \checkmark	& -				& -				& C\#	& \checkmark	& \checkmark \\
   	Neo4j			& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	OQGRAPH			& \checkmark	& \checkmark	& \checkmark	& C		& \checkmark	& \checkmark \\
   	OrientDB		& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	RedisGraph		& \checkmark	& - 			& -				& Javascript & \checkmark	& \checkmark \\
   	SGDB3			& \checkmark	& -				& -				& Java	& -				& \checkmark \\
   	Titan			& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	Trinity			& -				& -				& k.A.			& k.A.	& k.A.			& - \\
   	VertexDB		& \checkmark	& \checkmark	& -				& C		& -				& \checkmark \\
   	\hline
   	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Nutzbarkeit und Produktreife]{Anforderungen an die Nutzbarkeit und Produktreife verschiedener GDBMS-Implementierungen. Mit * gekennzeichnete Anforderungen sind optional bzw. besitzen rein informativen Charakter.}
	\label{tab:nutzung}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Datenverwaltung und Datenmodellierung}

Datenmodell - grundsätzlich ist die Modellierung auch mit anderen Datenmodellen möglich (z.B. Zwischenknoten), wird jedoch hier nicht berücksichtigt um die Menge der zu vergleichenden Systeme einzuschränken
Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{3.5cm}|>{\centering}m{2.25cm}|>{\centering}m{1.5cm}|>{\centering}m{1.25cm}|>{\centering\arraybackslash}m{2.25cm}|}
	\hline
	\multicolumn{6}{|c|}{\textbf{Datenverwaltung und Datenmodellierung}} \\
	\hline
   	GDBMS & Datenmodell & Mehrere\newline~Datenbanken* & Schema* & ACID* & Integritäts-\newline bedingungen* \\   
   	\hline
   	Affinity		& Gerichteter, knotenattributierter Multigraph	& - & -	& \checkmark & \checkmark \\
   	ArangoDB		& PGM	& \checkmark & - & \checkmark & \checkmark \\
   	Bitsy			& PGM	& -	& -	& \checkmark & \checkmark \\
   	FlockDB			& Gerichteter, knotenattributierter, kantenbezeichneter Graph & \checkmark	& -	& -	& \checkmark \\
   	HypergraphDB	& PHGM	& -	& \checkmark & \checkmark & \checkmark \\
   	Infogrid		& Gerichteter, knotenattributierter, kantenbezeichneter Multigraph	& -	& \checkmark & \checkmark & \checkmark \\
   	Neo4j			& PGM	& -	& -	& \checkmark	& \checkmark \\
   	OQGRAPH			& Gerichteter, gewichteter Multigraph	& -	& -	& -	& \checkmark \\
   	OrientDB		& PGM	& -	& \checkmark	& \checkmark	& \checkmark \\
   	Titan			& PGM	& -	& \checkmark	& \checkmark	& \checkmark \\
   	\hline
   	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Datenverwaltung und Datenmodellierung]{Anforderungen hinsichtlich der Datenverwaltung und -modellierung innerhalb von GDBMS. (*optional/informativ)}
	\label{tab:verwaltung}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Zugriffsmechanismen}

Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{1.65cm}|>{\centering}m{1.25cm}|>{\centering}m{1.25cm}|>{\centering}m{1.25cm}|>{\centering\arraybackslash}m{2cm}|>{\centering}m{1.5cm}|>{\centering\arraybackslash}m{1.25cm}|}
	\hline
	\multicolumn{8}{|c|}{\textbf{Zugriffsmechanismen}} \\
	\hline
   	GDBMS & Embedded\newline API & Remote \newline API* & Plugin \newline API* & CRUD & Traversierung & Anfrage-\newline sprache* & Bulk\newline Load \\   
   	\hline   
   	ArangoDB		& -				& \checkmark 	& - 			& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	Bitsy			& \checkmark	& \checkmark	& -				& \checkmark 	& \checkmark & \checkmark	& -				\\
   	HypergraphDB	& \checkmark	& -				& - 			& \checkmark 	& \checkmark & - 			& -				\\
   	Neo4j			& \checkmark	& \checkmark	& \checkmark	& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	OrientDB		& \checkmark	& \checkmark	& -				& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	Titan			& \checkmark	& \checkmark	& \checkmark	& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	\hline
   	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Zugriffsmechanismen]{Anforderungen an die Zugriffsmechanismen von GDBMS. (*optional/informativ)}
	\label{tab:zugriff}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Speicherung}

Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{2.5cm}|>{\centering}m{2.5cm}|>{\centering}m{2.5cm}|>{\centering\arraybackslash}m{2.5cm}|}
	\hline
	\multicolumn{5}{|c|}{\textbf{Speicherung}} \\
	\hline
   	GDBMS & Persistenz & Native Speicherung*  & Hauptspeicher-\newline~zentriert* & Index-\newline unterstützung \\
   	\hline   
   	Bitsy			& \checkmark	& -				& \checkmark	& \checkmark 	\\
   	HypergraphDB	& \checkmark	& \checkmark	& - 			& \checkmark 	\\
   	Neo4j			& \checkmark	& \checkmark	& -				& \checkmark	\\
   	OrientDB		& \checkmark	& \checkmark	& -				& \checkmark	\\
   	Titan			& \checkmark	& -				& -				& \checkmark	\\
   	\hline
	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Speicherung]{Anforderungen an die Datenspeicherung in GDBMS. (*optional/informativ)}
	\label{tab:speicherung}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Skalierbarkeit und Verfügbarkeit}

Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{2.5cm}|>{\centering}m{2.5cm}|>{\centering\arraybackslash}m{2.5cm}|}
	\hline
	\multicolumn{4}{|c|}{\textbf{Skalierbarkeit und Verfügbarkeit}} \\
	\hline
   	GDBMS & Partitionierung* & Replikation*  & Backup* \\
   	\hline   
   	Bitsy			& -				& -				& \checkmark \\
   	HypergraphDB	& -				& \checkmark	& \checkmark \\
   	Neo4j			& -				& \checkmark	& \checkmark \\
   	OrientDB		& -				& \checkmark	& \checkmark \\
   	Titan			& \checkmark	& \checkmark	& \checkmark \\
   	\hline
	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Skalierbarkeit und Verfügbarkeit]{Anforderungen an die Skalierbarkeit und Verfügbarkeit von GDBMS. (*optional/informativ)}
	\label{tab:skalierbarkeit}
\end{table}
\renewcommand{\arraystretch}{1}

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.

\section{Neo4j}

Neo4j ist ein quelloffenes GDBMS, welches von der Firma Neo Technology\footnote{\url{http://www.neotechnology.com/}} entwickelt wird. Version 1.0 wurde 2010 veröffentlicht, zum aktuellen Zeitpunkt befindet sich Version 2.0 in Entwicklung. Die Implementierung des Systems erfolgt ausschließlich in der Programmiersprache Java. Neo4j ist ein natives GDBMS, es unterstützt eine graphenorientierte Verarbeitung entsprechend der beschriebenen indexfreien Adjazenz und implementiert eine graphenorientierte physische Repräsentation der Datenbasis. Die Verwendung des Systems erfolgt entweder in Form einer eingebetteten Bibliothek innerhalb von Java-Anwendungen oder in einer Client-Server-Konfiguration. Letzteres erfordert den client-seitigen Zugriff über REST-Schnittstellen, entsprechende Clients stehen in vielen Programmiersprachen zur Verfügung\footnote{\url{http://www.neo4j.org/develop/drivers}}. Neo4j kann sowohl als zentrales GDBMS als auch in einer verteilten Konfiguration eingesetzt werden. Eine vollständige Replikation ermöglicht dabei die Skalierbarkeit lesender Anfragen und erhöht gleichzeitig die Ausfallsicherheit des Gesamtsystems. Die Speicherung der Datenbasis erfolgt disk-zentriert, ein hauptspeicher-zentrierter Betrieb ist nicht möglich.

Neo Technology bietet das Datenbanksystem in drei verschiedenen Ausführungen an: Community, Advanced und Enterprise. Die Community-Version bietet den grundlegendsten Funktionsumfang, während die Advanced-Version Monitoring-Funktionalität hinzufügt und die Enterprise-Version diese um Online-Backups und Hochverfügbarkeits-Mecha-nismen erweitert. Advanced- und Enterprise-Version eignen sich für den kommerziellen Einsatz, da sie zusätzliche Service-Leistungen durch Neo Technology beinhalten und ihre Lizenz die Verwendung in unfreier Software erlaubt. Die Community-Version darf nur in freier, quelloffener Software eingesetzt werden, Service-Anfragen werden durch die Neo4j-Community im Web beantwortet.

Die nachfolgenden Ausführungen beziehen sich auf Version 2.0.0-M04 des GDBMS, diese Version beinhaltet Erweiterungen hinsichtlich des Datenmodells und der Anfragesprache. Die Informationen stammen aus der offiziellen Neo4j-Dokumentation\cite{Neo4j_manual:2013} sowie aus den Ausführungen in \cite{robinson2013graph}.

\subsection{Datenmodell und Konsistenzerhaltung}

Neo4j implementiert das Property-Graph-Modell, dieses wird in der aktuellen Version um Knotenbezeichner erweitert. Mit deren Hilfe lassen sich Knoten zu Gruppen zusammenfassen. Ein Knoten kann keiner oder beliebig vielen Gruppen zugeordnet werden. Knoten- und Kantenbezeichner werden in Neo4j als Labels bezeichnet. Die Erweiterung um Knoten-Labels bietet verschiedene Vorteile: Anfragen lassen sich durch Einbeziehen von Labels auf einen Teilgraphen einschränken, was zum Einen die Formulierung von Anfragen stark vereinfacht und zum Anderen deren effizientere Ausführung ermöglichen kann. Labels sind jedoch nicht gleichbedeutend mit einer Relation in der relationalen Algebra, ein Label wird lediglich durch seinen Namen definiert, es wird kein Schema der zugeordneten Elemente vorgegeben. Sie sind jedoch ein nützliches Werkzeug in der strukturierten Anwendungsmodellierung und können zur Laufzeit an Knoten hinzugefügt und entfernt werden. 

Beziehungen zwischen Knoten werden durch Kanten beschrieben. In Neo4j sind diese grundsätzlich gerichtet, besitzen also immer Start- und Endknoten, Schleifen\footnote{Eine Kante ist eine Schleife, wenn Start- und Endknoten identisch sind\cite{DBLP:books/daglib/0030488}.} sind ebenfalls zulässig. Kanten lassen sich in beiden Richtungen traversieren, d.h. eine bidirektionale Beziehung erfordert nicht zwingend die Definition von zwei Kanten unterschiedlicher Richtung. Eine Kante besitzt immer ein Label, welches zusammen mit der Richtung der Kante deren Semantik festlegt. Genau wie Knoten besitzen auch Kanten eine eindeutige Identität, diese wird vom GDBMS verwaltet und kann nicht durch die Anwendung geändert werden. Die Identität einer Kante ermöglicht die Definition paralleler Kanten mit gleichen Labels.

Knoten und Kanten lassen sich in Neo4j mit optionalen Attributen in Form von Schlüssel-Wert-Paaren versehen, sie werden in Neo4j als Properties bezeichnet. Schlüssel sind vom Typ \texttt{String}, zulässige  Werte müssen Instanzen eines primitiven Java-Datentypen (z.B. \texttt{int}, \texttt{float}) sein. Arrays von primitiven Datentypen sind ebenfalls zulässige Werte. Weist eine Instanz einen Wert nicht auf, so wird dies durch das Weglassen des entsprechenden Schlüssel-Wert-Paares definiert und nicht durch die Verwendung von \texttt{null} als Wert.

Mit dem Ziel, Datenintegrität zu gewährleisten, sieht das Modell verschiedene Mechanismen vor. Eine Kante kann nur zwischen existierenden Knoten erzeugt werden, das Löschen eines Knotens erfordert das vorherige Löschen aller inzidenten Kanten des Knotens. Diese Zusicherung kann als Analogie zur referentiellen Integrität\cite{vossen2008datenmodelle} in relationalen Datenbanksystemen verstanden werden. Neo4j unterstützt darüber hinaus auch attributbezogene Integritätsbedingungen. Die Festlegung einer eindeutigen Identität durch das GDBMS entspricht einer Primärschlüssel-Definition, die Definition eines Datentyps für Attributwerte stellt eine Wertebereichs-Einschränkung dar und darüber hinaus unterstützt Neo4j die Definition einer \texttt{UNIQUE}-Bedingung für Knotenattribute. Letztere legt fest, dass ein Wert in der Menge aller Werte eines Schlüssels einzigartig sein muss. Diese Bedingung lässt sich nur in Verbindung mit Knoten-Labels definieren.

Neo4j verwaltet exakt eine Graphdatenbank, alle Knoten und Kanten sind dieser Datenbank zugeordnet. Eine logische Partitionierung der Knotenmenge ist durch Labels oder dedizierte Attribute möglich, soll auch die Kantenmenge partitioniert werden, so ist dies ausschließlich über Attribute möglich. 

Aus den Ausführungen wird deutlich, dass Neo4j in Version 2.0 eine schema-optionale Datenbank darstellt. Es besteht die Möglichkeit, die Datenbank ohne jegliche Berücksichtigung eines Schemas zu verwenden, durch die optionalen Knoten-Labels ist es jedoch möglich, ein solches zu definieren und von den Vorteilen, wie strukturierter Anwendungsmodellierung, vereinfachten Anfragen und effizienter Anfrageausführung zu profitieren. Das Datenmodell eignet sich somit in Anwendungen, bei denen die Anforderungen nicht zu Beginn vollständig erfasst werden können und eine hohe Flexibilität hinsichtlich Schemaänderungen erforderlich ist.

\subsection{Zugriffsmechanismen und graphenspezifische Operationen}

Neo4j bietet vier Möglichkeiten unterschiedlicher Mächtigkeit für den Zugriff auf die Datenbasis an: Native API, Traversal Framework sowie die Anfragesprachen Cypher und Gremlin. Alle Zugriffsmechanismen lassen sich sowohl im eingebetteten Betrieb als auch in der Client-Server-Konfiguration via REST verwenden. Cypher ist die primäre Anfragesprache von Neo4j und wird von Neo Technology entwickelt. Gremlin entstand hingegen im Rahmen des Blueprints-Projektes\footnote{https://github.com/tinkerpop/blueprints/wiki}. Es handelt sich dabei um eine Sammlung von Schnittstellen und Implementierungen, welche die Verarbeitung von Graphen unterstützen und sich dabei am PGM orientieren. Gremlin ist Teil dieser Sammlung und wird unter anderem von Titan und Bitsy als primäre Anfragesprache eingesetzt. Die  Erläuterung von Gremlin erfolgt im Zusammenhang mit den zwei genannten Systemen.

\paragraph*{Native API}

Die native API stellt die grundlegendsten CRUD-Operationen für den lesenden und schreibenden Zugriff auf die Datenbasis zur Verfügung. Knoten können erzeugt und optional mit Labels und Properties versehen werden. Kanten werden unter Angabe existierender Knoten erstellt, dabei impliziert die Knotenreihenfolge die Richtung der Kante, ein Label ist obligatorisch. Letzteres kann innerhalb der Anwendung statisch hinterlegt oder dynamisch zur Laufzeit erzeugt werden. Eine Kanteninstanz erlaubt das Auslesen des Start- und Endknotens, des Labels und - sofern vorhanden - der Properties. Das Aktualisieren von Knoten und Kanten ist ebenfalls mit der nativen API möglich, Knotenlabels können jederzeit angefügt oder entfernt werden, Knoten- und Kantenproperties lassen sich unter Berücksichtigung der zulässigen Datentypen beliebig manipulieren. Das Löschen von Knoten und Kanten ist unter Beachtung der referentiellen Integrität ebenfalls möglich.

Es sollte deutlich werden, dass sich ausgehend von der nativen API beliebige Graphalgorithmen anwendungsseitig implementieren lassen. Ein Beispiel für die Verwendung der nativen API befindet sich in Anhang \ref{anh:neo4j_native_api}.

\paragraph*{Traversal Framework}

Das Traversal Framework ist eine Erweiterung der nativen API. Es ermöglicht die Definition eines abstrakten Weges und liefert als Ergebnis eine Menge von Instanzen dieses Weges. Die Ausführung der Traversierung erfolgt Iterator-basiert, was bedeutet, dass die eigentliche Berechnung eines Weges erst bei Anfrage der nächsten Instanz ausgeführt wird.\footnote{Diese Strategie wird auch als \textit{Lazy Evaluation} bezeichnet.} Das Framework umfasst mehrere Schnittstellen, mit deren Hilfe der Nutzer den abstrakten Weg beschreiben und das Verhalten der Traversierung beeinflussen kann. Es ist ausschließlich der lesende Zugriff auf die Datenbasis möglich.

Ausgangspunkt einer Traversierung ist die \texttt{TraversalDescription}, eine Schnittstelle zur Beschreibung und Initialisierung einer Traversierung. Zunächst lässt sich mit Hilfe eines \texttt{PathExpander} festlegen, welche Kantenlabels bei der Traversierung zu berücksichtigen sind. Das Weglassen dieser Information, führt zur Traversierung aller Kanten. Die Angabe eines Labels ermöglicht zudem das optionale Festlegen einer Richtung der zugehörigen Kanteninstanzen. Stehen mehrere Kantenlabels zur Auswahl, so kann durch die Reihenfolge ihrer Aufzählung die Priorität bei der Traversierung bestimmt werden. Durch das Whitelist-Prinzp ist das Ausschließen definierter Kantenlabels nicht möglich.\\
Eine weitere wichtige Schnittstelle ist \texttt{Path}, diese erfüllt zwei Aufgaben: Zum Einen sind die Ergebnisse der Traversierung Instanzen dieser Schnittstelle und zum Anderen wird sie für die Evaluation der aktuellen Position innerhalb des Graphen während der Traversierung verwendet. Im Rahmen der Evaluation wird entschieden, ob der aktuelle Knoten in das Ergebnis aufgenommen und ob die Traversierung ausgehend von der aktuellen Position fortgesetzt werden soll. Es handelt sich somit um ein Filter- und Abbruchkriterium für die Traversierung. Die Entscheidungslogik wird unter Verwendung der Schnittstelle \texttt{Evaluator} implementiert.

Neben den genannten Schnittstellen zur Definition des abstrakten Weges, lässt sich das Verhalten der Traversierung durch weitere Schnittstellen beeinflussen. Der Graph kann mittels Breiten- oder Tiefensuche durchlaufen werden, alternativ kann ein beliebiges Vorgehen, wie zum Beispiel das randomisierte, durch die Implementierung einer\linebreak~\texttt{BranchOrderingPolicy} beschrieben werden. Durch die Implementierung der Schnittstelle \texttt{BranchSelector} wird dabei festgelegt, welche Kante als nächstes traversiert wird. An dieser Stelle können zum Beispiel Heuristiken in die Entscheidung einbezogen werden.\\
Mittels \texttt{Uniqueness} lässt sich festlegen, wie oft ein Objekt während der Traversierung besucht werden darf. Objekte sind Knoten oder Kanten, diese können entweder global oder innerhalb des bisher traversierten Pfades eindeutig sein. Die Festlegung ist insbesondere in zyklischen Graphen notwendig, standardmäßig wird die globale Eindeutigkeit von Knoten gefordert.

Eine den Anforderungen entsprechend definierte \texttt{TraversalDescription} wird unter Angabe eines Startknotens instanziiert. Das Ergebnis dieses Aufrufs ist ein \texttt{Traverser}-Objekt, welches den Iterator zur Verfügung stellt. In Anhang \ref{anh:neo4j_traversal_framework} findet sich ein Beispiel für die Traversierung.

Das Traversal Framework erweitert die native API um ein Hilfskonstrukt mit welchem die Datenbasis beliebig traversiert werden kann. Durch die Möglichkeit, Abbruch- und Filterkriterien in Java zu implementieren, steht hinsichtlich der Programmierbarkeit ein universelles Werkzeug für die Verarbeitung von Graphen zur Verfügung. Dies stellt jedoch gleichzeitig ein entscheidendes Defizit hinsichtlich des Zugriffs auf die Datenbasis für Nicht-Programmierer dar. Neo4j bietet mit der Anfragesprache Cypher eine entsprechende Alternative.

\paragraph*{Cypher}

Cypher ist eine deklarative, graphenorientierte Anfragesprache für den lesenden und schreibenden Zugriff auf die Datenbasis. Es handelt sich um eine nicht standardisierte Sprache, welche aktuell in Neo4j und in abgeänderter Form im GDBMS-Prototypen GraphPack zur Verfügung steht. Syntaktisch ist Cypher an SQL und SPARQL angelehnt, viele der dort vorhandenen Sprachkonstrukte und Ansätze werden konsequent wiederverwendet. Kernelement der Sprache ist das Beschreiben von Mustergraphen zur Informationsextraktion. Das Prüfen der Erreichbarkeit und insbesondere das Berechnen kürzester Pfade ist darüber hinaus ebenfalls möglich. Nachfolgend wird der grundlegende Umfang der Sprache beschrieben, eine detaillierte Beschreibung kann der offiziellen Dokumentation entnommen werden\cite{Neo4j_manual:2013}. 

Eine rein lesende Anfrage setzt sich aus den folgenden Komponenten zusammen:

\texttt{[START] [MATCH] [WHERE]\newline
[WITH [ORDER BY] [SKIP] [LIMIT]]\newline
RETURN [ORDER BY] [SKIP] [LIMIT]}.

In der optionalen \texttt{START}-Klausel werden Bezeichner festgelegt und an Knoten- oder Kanteninstanzen gebunden. Die Auswahl einer Instanz erfolgt dabei entweder unter Angabe ihrer Identität oder mittels indexbasierter Suche. Zum Beispiel führt die Anweisung 

\texttt{START a=node:Employees(name=\string"Alice\string")} 

zum Durchsuchen des Knotenindex \texttt{Employees} nach dem Schlüssel-Wert-Paar\linebreak \texttt{name=\string"Alice\string"}. Existiert eine entsprechende Instanz, erfolgt die Bindung an den Bezeichner \texttt{a}. Trifft die Bedingung auf mehrere Instanzen zu, so verweist \texttt{a} auf die entsprechende Menge. Alle gebundenen Bezeichner können in den nachfolgenden Teilen der Anfrage verwendet werden. Zulässige Datentypen für Bezeichner und Variablen sind generell Knoten, Kanten, Pfade und Literale bzw. Mengen der genannten.

Wird keine \texttt{START}-Klausel definiert, ist die nachfolgende \texttt{MATCH}-Klausel obligatorisch. Sie ermöglicht die Definition eines Mustergraphen zur Informationsextraktion aus der Datenbasis. Mit dem Ziel, einen Mustergraphen in Textform zu repräsentieren, wird dieser in Fragmente zerlegt. Jedes dieser Fragmente entspricht der Definition eines abstrakten Weges. Der in Abbildung \ref{fig:neo4j_pattern_graph} gezeigte Mustergraph lässt sich durch zwei Fragmente beschreiben:

\texttt{MATCH\newline
c:Employee-[:WORKS\_WITH]-a-[:WORKS\_WITH]->b:Employee-[:WORKS\_WITH]->c,\newline
b---d:Project}

Innerhalb des Musters sind die in der \texttt{START}-Klausel definierten Bezeichner die Konstanten und stellen somit die Verbindungen zwischen Muster und Datenbasis her. Neo4j bezeichnet diese als \textit{bound pattern elements}, im Beispiel ist dies der Knoten \texttt{a}. Die Variablen \texttt{b}, \texttt{c} und \texttt{d} werden beim Finden einer Übereinstimmung an Knoten- bzw. Kanteninstanzen gebunden, alle Variablen stehen in weiteren Operationen zur Verfügung. Am Beispiel wird die Verwendung der Knotenlabel deutlich: Die Variablen \texttt{b} und \texttt{c} legen das Label gebundener Knoteninstanzen auf \texttt{Employee} fest, während die Variable \texttt{d} die Menge möglicher Instanzen auf alle Projekte einschränkt. Die Angabe eines Kantenlabels ist optional, so verlangt das zweite Fragment bspw. eine Kante mit beliebiger Richtung und beliebigem Label zwischen den Knoten \texttt{b} und \texttt{d}, wohingegen zwischen den Knoten \texttt{a} und \texttt{b} eine gerichtete Kante mit dem Label \texttt{WORKS\_WITH} existieren muss. Steht die \texttt{MATCH}-Klausel am Beginn der Anfrage, dann ist in diesem Abschnitt kein Bezeichner gebunden. Folglich wird entweder die vollständige Datenbasis nach dem Muster durchsucht, oder anhand von eventuell definierten Labels die Menge der Objekte eingeschränkt. Alternativ können Prädikate in der nachfolgenden \texttt{WHERE}-Klausel zur Einschränkung des Suchraums genutzt werden.
	 
Die \texttt{WHERE}-Klausel entspricht der Selektion in der relationalen Algebra. Sie ist optional und ermöglicht die Filterung von Ergebnistupeln mittels Prädikaten. Cypher bietet eine Vielzahl mathematischer, vergleichender und boolescher Operatoren für die Definition und Verknüpfung von Prädikaten an. Soll zum Beispiel im Mustergraphen das Attribut \texttt{age} der an die Variable \texttt{b} gebundenen Instanzen eingeschränkt werden, so ist dies mit folgender Anweisung möglich:

\texttt{WHERE b.age? > 23 AND b.age? < 42}

Da Properties keinem Schema unterliegen, kann mittels \texttt{?}-Operator geprüft werden, ob die entsprechende Instanz diesen Attributschlüssel besitzt. Ist dies nicht der Fall, wird \texttt{True} zurückgegeben.

Die ebenfalls optionale \texttt{WITH}-Klausel besitzt kein Pendant in der relationalen Algebra, sondern entspricht der Funktionsweise des Pipe-Operators der Linux-Shell. Mit dessen Hilfe lassen sich Operationen verketten: Die Ausgabe einer Operation kann als Eingabe der Folgeoperation verwendet werden. Dies ist in Cypher genau dann sinnvoll, wenn zum Beispiel Aggregate innerhalb einer \texttt{WHERE}-Bedingung verwendet werden müssen oder zum Verketten lesender und schreibender Anfragen, wobei letztere auf die Ergebnisse der erstgenannten zugreifen.

Am Ende einer rein lesenden Cypher-Anfrage befindet sich die obligatorische \texttt{RETURN}-Klausel, diese entspricht der Projektion in der relationalen Algebra. Sie legt fest, welche Variablen zurückgegeben werden und ermöglicht die Umformung der Ergebnismenge. Analog zu SQL kann das Ergebnis mit \texttt{ORDER BY} sortiert sowie durch \texttt{SKIP} und \texttt{LIMIT} eingeschränkt werden.

Cypher ermöglicht die Berechnung von Aggregaten sowohl in der \texttt{RETURN}- als auch in der \texttt{WITH}-Klausel. Dabei stehen verschiedene Aggregatfunktionen, wie zum Beispiel \texttt{min}, \texttt{max} und \texttt{avg}, zur Verfügung. Darüber hinaus ermöglicht Cypher die Verwendung von skalaren (z.B. \texttt{LENGTH} und \texttt{TYPE}), mathematischen (z.B. \texttt{ABS} und \texttt{ROUND}), string-basierten (z.B. \texttt{SUBSTRING} und \texttt{LOWER}) und mengenorientierten (z.B. \texttt{FILTER} und \texttt{REDUCE}) Funktionen.

\texttt{MATCH}-, \texttt{WITH}- und \texttt{WHERE}-Klauseln lassen sich beliebig oft in beliebiger Reihenfolge kombinieren, so können zum Beispiel Ergebnismengen oder Aggregate in einer nachfolgenden Musterdefinition verwendet werden. Analog zum Traversal Framework werden rein lesende Anfragen erst ausgeführt, wenn der Nutzer auf die Ergebnisse zugreift, dies ist insbesondere dann sinnvoll, wenn Muster ohne Bindung zur Datenbasis definiert werden und diese komplett durchsucht werden muss. 

Neben den rein lesenden Anfragen sind auch schreibende Anfragen möglich. Unter Verwendung der \texttt{CREATE}-Klausel werden Knoten- und Kanteninstanzen mit Labels und Properties erzeugt, 
mit der \text{SET}-Klausel werden Properties und Knotenlabel aktualisiert und mit der \texttt{DELETE} Klausel werden Instanzen gelöscht.

Klarer Vorteil gegenüber den bisher vorgestellten Zugriffsmöglichkeiten ist der deklarative Charakter der Sprache. Im Gegensatz zum Traversal Framework wird in Cypher festgelegt \textit{was} gesucht wird und nicht \texttt{wie} es gesucht wird. Dies ermöglicht zum Einen die einfachere Anfrageformulierung und zum Anderen natürlich auch zusätzliches Optimierungspotential. Die Sprache steht unter permanenter Weiterentwicklung, was bedeutet, dass mit Änderungen und Erweiterungen der Syntax zu rechnen ist. Schwerpunkt der Version 2.0 ist unter anderem die automatische Anfrageoptimierung. Eine manuelle Anfrageoptimierung ist möglich, der Ausführungsplan lässt sich über die Java API zusammen mit dem Anfrageergebnis abrufen.

\paragraph*{Graphenspezifische Operationen}

\paragraph*{Transaktionen}

- (schreibende?) native Anfrage / Traversal muss explizit in Transaktion gekapselt werden
- Transaktionen für schreibenden Cypher-Anfragen werden implizit erzeugt

\subsection{Persistenz und Indexierung}

Blubb

\subsection{Möglichkeiten der Verteilung}

Blubb

\section{HypergraphDB}

Blubb

\subsection{Datenmodell und Konsistenzerhaltung}

Blubb

\subsection{Zugriffsmechanismen und graphenspezifische Operationen}

Blubb

\subsection{Persistenz und Indexierung}

Blubb

\subsection{Verteilung}

Blubb

\section{OrientDB}

Blubb

\subsection{Datenmodell}

Blubb

\subsection{Zugriffsmechanismen}

Blubb

\subsection{Persistenz}

Blubb

\subsection{Verteilung}

Blubb

\section{Titan}

Blubb

\subsection{Datenmodell}

Blubb

\subsection{Zugriffsmechanismen}

Blubb

\subsection{Persistenz}

Blubb

\subsection{Verteilung}

Blubb

\section{Bitsy}

Blubb

\subsection{Datenmodell}

Blubb

\subsection{Zugriffsmechanismen}

Blubb

\subsection{Persistenz}

Blubb

\subsection{Verteilung}

Blubb

\section{Gegenüberstellung}

Blubb

