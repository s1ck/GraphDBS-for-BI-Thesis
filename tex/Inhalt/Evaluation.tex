\chapter{Evaluation von Graphdatenbanksystemen}
\label{cha:evaluation}

Dieses Kapitel setzt sich mit konkreten GDBMS-Implementierungen auseinander. Mit der Zielstellung, aus der Vielzahl existierender Systeme geeignete auszuwählen, werden zunächst funktionale Anforderungen definiert. Diese ergeben sich aus aktuellen Forschungsvorhaben am Lehrstuhl Datenbanken der Universität Leipzig. Die ausgewählten Systeme werden anschließend im Detail betrachtet, die Schwerpunkte dabei sind: Datenmodellierung und Konsistenzerhaltung, Zugriffsmechanismen und angebotene graphenspezifische Operationen, physische Repräsentation des Graphen und Möglichkeiten der Indexierung und Verteilung. Das Kapitel schließt mit einer Gegenüberstellung der Systeme.

\section{Aktuelle Forschungsvorhaben}
\label{sec:anforderungen}

Wie bereits im vorhergehenden Kapitel erläutert, ist ein Informationsnetzwerk der Netzwerktypus, in welchem Informationen in Form von Begriffen oder konkreten Daten miteinander verknüpft sind. Die Struktur des Netzwerkes ist dabei die Grundlage für Analysen, deren Ziel es ist, aus bestehenden Informationen neue Informationen abzuleiten, aus denen wiederum neues Wissen generiert werden soll. Im Bereich der Unternehmensdaten werden diese analytischen Verfahren und damit verbundene Anwendungen unter dem Begriff Business Intelligence (BI) zusammengefasst\cite{Watson:2007:CSB:1300761.1301970}. Unternehmen setzen BI ein, um möglichst gewinnbringende Informationen aus vorhandenen Daten zu extrahieren. Auf Basis dieser Informationen können der Zustand des Unternehmens eingeschätzt und Entscheidungen getroffen werden.

Verschiedene Bereiche eines Unternehmens nutzen unterschiedliche Systeme zur Bewältigung ihrer Aufgaben. So unterscheidet man beispielsweise ERP-, PM- und CRM-Systeme, welche sich in technologischer, struktureller und semantischer Hinsicht unterscheiden können. BI setzt voraus, dass Daten aus heterogenen Systemen zunächst in ein System integriert werden, zu diesem Zweck werden Data Warehouses (DWH) eingesetzt\cite{Chaudhuri:2011:OBI:1978542.1978562, Watson:2007:CSB:1300761.1301970}. Ein DWH ist eine zentrale Datenbank, welche für Analysezwecke optimiert ist und in welcher Daten aus mehreren, i.A. heterogenen Quellen zusammengeführt, ggf. bereinigt und transformiert werden\cite{}. Im Rahmen der Transformation werden die Daten in ein einheitliches Schema überführt. Fakten werden in einer zentralen Tabelle hinterlegt und mit Dimensionstabellen verknüpft. Ein Fakt kann zum Beispiel der Kauf eines Produktes und der daraus resultierende Umsatz sein, mögliche Dimensionen sind das Produkt, der Kaufzeitpunkt, der Kunde und die Filiale. Auf dieser Datenbasis sind vielfältige Analysen möglich, so können zum Beispiel der Umsatz in bestimmten Regionen, die Beliebtheit von Produkten oder die Rentabilität einzelner Filialen bestimmt werden.

Wie aus dem Beispiel des DWH hervorgeht, erfordert die Transformation das Definieren eines einheitlichen Schemas. Das bedeutet, dass die für die Analyse relevanten Beziehungen zwischen Dimensionen und Fakten vorab festgelegt werden müssen und somit jeder relevante Zusammenhang zwischen Fakt und Dimension bekannt sein und im Schema abgebildet werden muss. Dieser Sachverhalt schränkt jedoch die analytischen Möglichkeiten ein, da nur Zusammenhänge analysiert werden können, die im Schema definiert wurden. Unbekannte, eventuell nicht intuitiv erkennbare Zusammenhänge können in der Analyse nicht berücksichtigt werden.

Eines der Projekte am Lehrstuhl Datenbanken befasst sich mit der Entwicklung und Untersuchung von Methoden zur graphenbasierten Business Intelligence. Eine graphenbasierte Repräsentation von Unternehmensdaten weist die beschriebene Einschränkung eines vordefinierten Schemas nicht auf, vielmehr erlaubt sie die flexible Evaluation der Beziehungen zwischen einzelnen Objekten innerhalb der Unternehmensdaten. Diese lassen sich in zwei Kategorien einteilen: Transaktionale Daten und Stammdaten.
Zu den transaktionalen Daten gehören zum Beispiel Rechnungen im ERP-System, Meeting-Protokolle im PM-System oder Kundenkontakte im CRM-System, sie entstehen innerhalb von Geschäftsprozessen und sowohl untereinander als auch mit Stammdaten verknüpft. Beispiele für Stammdaten sind Informationen über Kunden, Produkte, Mitarbeiter oder Filialen. Aus diesem Zusammenhang lässt sich ein Graph ableiten: Transaktionale Daten und Stammdaten bilden die Knoten, der kausale Zusammenhang zwischen ihnen wird durch Kanten beschrieben. Stammdaten weisen die Eigenschaft auf, dass sie in mehreren Systemen hinterlegt sein können, transaktionale Daten beschränken sich auf das System, in dem sie erzeugt wurden. Beziehungen zwischen Objekten können generell systemübergreifend sein. Eine mögliche Analyse ist das Finden häufiger Muster. So lassen sich zum Beispiel Teilgraphen zu bestimmten Geschäftsprozessen extrahieren und hinsichtlich des Zusammenhangs zwischen erzeugtem Mehrwert und beteiligten Mitarbeitern untersuchen. Abbildung \ref{fig:bi-graph} zeigt ein Beispiel für einen aus Geschäftsdaten erzeugten Graphen.

Das Projekt verfolgt drei Ziele: Zunächst ist die Integration von Unternehmensdaten aus heterogenen Systemen in einen Graph erforderlich. Auf der Grundlage des integrierten Graphen werden in einer zweiten Phase Algorithmen für die graphenorientierte Analyse entwickelt. In der letzten Phase sollen Ansätze untersucht werden, die Datenbasis möglichst effizient für Analysten nutzbar zu machen, hierbei spielen insbesondere Anfragesprachen und Möglichkeiten zur Visualisierung eine Rolle. Für das Erreichen der Ziele sollen GDBMS die technologische Grundlage bilden, da sie eine flexible, graphenorientierte Datenmodellierung erlauben und Operationen zur Verfügung stellen unter deren Verwendung sich BI-orientierte Algorithmen implementieren lassen. Einige der verfügbaren Systeme beinhalten darüber hinaus bereits Anfragesprachen, welche als Basis für eigene Entwicklungen dienen können.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=0.45]{exa_docgraph.pdf}
	\caption[Beispiel: BI-Graph]{Informationsnetzwerk, welches die Beziehungen zwischen den Objekten eines ERP- und eines CRM-Systems darstellt. Transaktionale Daten sind weiß,  Stammdaten grau dargestellt. Bezeichner und Richtung einer Kante beschreiben den kausalen Zusammenhang zwischen transaktionalen Daten (z.B. \texttt{basedOn}, \texttt{serves}) sowie zwischen transaktionalen Daten und Stammdaten (z.B. \texttt{sentBy}, \texttt{doneFor}). Der gezeigte Teilgraph bildet einen vollständigen Geschäftsprozess ab, dessen erzeugter Mehrwert sich aus den Einnahmen (engl. \textit{Revenue}) und Ausgaben (engl. \textit{Expense}) der transaktionalen Daten bestimmen lässt. Am Beispiel des Knotens \texttt{Employee (E01)} wird deutlich, dass Stammdaten in mehreren Systemen vorhanden sein können.}
	\label{fig:bi-graph}
\end{figure}

\section{Vorauswahl von Graphdatenbanksystemen}
\label{sec:vorauswahl}

Nachfolgend werden die Anforderungen an ein GDBMS für den Einsatz innerhalb des beschriebenen Projektes kategorisiert vorgestellt und vorhandene Implementierungen hinsichtlich der Erfüllung jener Anforderungen bewertet. Die Auswahl der Systeme erfolgte auf Grundlage von Literatur- und Webrecherche. Die Informationen zu den einzelnen GDBMS stammen von den Webseiten der Hersteller oder den primären Publikationen zu den jeweiligen Systemen. Eine Liste der Webseiten befindet sich in Anhang \ref{anh:vendor_list}.

Innerhalb jeder Kategorie werden obligatorische und optionale bzw. rein informative Anforderungen definiert. Ein GDBMS, welches eine obligatorische Anforderung erfüllt, wird in der nachfolgenden Kategorie weiter betrachtet. Sollte nach der Betrachtung aller Kategorien die Kandidatenmenge zu groß sein, um im Rahmen dieser Arbeit evaluiert werden zu können, werden die optionalen Anforderungen in den Entscheidungsprozess einbezogen. Ziel ist die Auswahl von vier GDBMS, welche die obligatorischen Anforderungen erfüllen, eine möglichst breite Verteilung innerhalb der vorgestellten GDBMS-Kategorien ist wünschenswert.

\paragraph*{Nutzbarkeit und Produktreife}

Eine der wichtigsten Anforderungen in dieser ersten Kategorie (Tabelle \ref{tab:nutzung}) ist die Quelloffenheit des GDBMS. Quellcode ist eine Dokumentationsart von Software, welche das Studium der exakten Funktionsweise ermöglicht. Widersprüchen und Ungenauigkeiten innerhalb textueller Dokumentation kann durch die Untersuchung des Quellcodes begegnet werden. Darüber hinaus soll das ausgewählte GDBMS als technologische Grundlage für Weiterentwicklungen innerhalb des beschriebenen Projektes dienen. Dies setzt ebenfalls Quelloffenheit und ein für die Nutzung geeignetes Lizenzmodell voraus. Ungeachtet dessen ist eine grundlegende textuelle Dokumentation des Datenbanksystems ebenfalls eine Pflichtanforderung. Sie sollte wenigstens einen Überblick über die Architektur des GDBMS, eine Beschreibung der Zugriffsmechanismen und Installationsanweisungen beinhalten.

Mit dem Ziel, eine möglichst stabile Software als Ausgangssituation nutzen zu können, wurde bei der Diskussion der Anforderungen festgelegt, dass es sich um ein Produktivsystem handeln muss, welches eine nachvollziehbar aktive Entwicklung erkennen lässt. Ein Produktivsystem definiert sich dadurch, dass es mindestens einen stabilen Release aufweist, die Aktivität kann anhand der Quelloffenheit der Systeme leicht nachvollzogen werden: Um als aktiv zu gelten, wurde ein Zeitraum von sechs Monaten festgelegt, in dem die Software Aktualisierungen erfahren haben muss.

Ein rein informatives Kriterium ist die Programmiersprache, in der das System entwickelt wird. Auffällig ist dabei, dass ein Großteil der GDBMS in Java implementiert ist. Generell ist Java aufgrund der persönlichen Erfahrung der Projektteilnehmer die bevorzugte Sprache, dies bedeutet jedoch nicht, dass objektiv bessere Systeme aufgrund ihrer Programmiersprache ausgeschlossen werden. Eine optionale Anforderung innerhalb dieser Kategorie ist die Unterstützung von Linux-basierten Betriebssystemen. Sollte das Projekt erfolgreich sein, ist eine Ausgründung vorgesehen. Aus diesem Grund soll vermieden werden, potentielle Kunden an eine proprietäre Plattform, wie zum Beispiel Microsoft Windows, zu binden.

Es kann nicht festgestellt werden, dass einzelne Anforderungen besonders häufig nicht erfüllt werden. Insgesamt werden die gestellten obligatorischen Anforderungen von zehn GDBMS erfüllt, deren Evaluation in der nächsten Kategorie fortgesetzt wird.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{1.5cm}|>{\centering}m{2.5cm}|>{\centering}m{2.0cm}|c|c|>{\centering\arraybackslash}m{2cm}|}
	\hline
	\multicolumn{7}{|c|}{\textbf{Nutzbarkeit und Produktreife}} \\
	\hline
   	GDBMS & Quell-\newline~offen & Dokumentation & Produktiv-\newline~system & Sprache* & Aktiv & GNU/Linux* \\   
   	\hline
   	Affinity		& \checkmark	& \checkmark	& \checkmark	& C++	& \checkmark 	& \checkmark \\
   	ArangoDB		& \checkmark	& \checkmark	& \checkmark	& C/C++	& \checkmark	& \checkmark \\	
   	Bitsy			& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	DEX				& - 			& \checkmark	& \checkmark	& C++	& \checkmark	& \checkmark \\
   	Filament		& \checkmark	& \checkmark	& -				& Java	& \checkmark	& \checkmark \\
   	FlockDB			& \checkmark	& (\checkmark)	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	GraphBase		& -				& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	GraphPack		& \checkmark	& -				& -				& Java	& -				& \checkmark \\
   	G-Store			& -				& \checkmark	& -				& C/C++	& -				& - \\
   	Horton			& -				& -				& k.A.\tablefootnote{keine Angabe}	& k.A.	& k.A.			& - \\
   	HypergraphDB	& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	InfiniteGraph	& -				& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	Infogrid		& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	Fallen-8		& \checkmark	& -				& -				& C\#	& \checkmark	& \checkmark \\
   	Neo4j			& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	OQGRAPH			& \checkmark	& \checkmark	& \checkmark	& C		& \checkmark	& \checkmark \\
   	OrientDB		& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	RedisGraph		& \checkmark	& - 			& -				& Javascript & \checkmark	& \checkmark \\
   	SGDB3			& \checkmark	& -				& -				& Java	& -				& \checkmark \\
   	Titan			& \checkmark	& \checkmark	& \checkmark	& Java	& \checkmark	& \checkmark \\
   	Trinity			& -				& -				& k.A.			& k.A.	& k.A.			& - \\
   	VertexDB		& \checkmark	& \checkmark	& -				& C		& -				& \checkmark \\
   	\hline
   	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Nutzbarkeit und Produktreife]{Anforderungen an die Nutzbarkeit und Produktreife verschiedener GDBMS-Implementierungen. Die mit * gekennzeichnete Anforderungen sind optional bzw. besitzen nur informativen Charakter.}
	\label{tab:nutzung}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Datenverwaltung und Datenmodellierung}

Die einzige obligatorische Anforderung in dieser Kategorie (Tabelle \ref{tab:verwaltung}) bezieht sich auf das Datenmodell: Die Eigenschaften des Property-Graph-Modell werden als Mindestvoraussetzung festgelegt, das Property-Hyper-\linebreak~graph-Modell ist ebenfalls zulässig, da es das PGM um n-äre Beziehungen erweitert. Annähernd die Hälfte der aufgeführten GDBMS verzichtet auf Kantenattribute, Kantenbezeichner oder parallele Kanten, dies sind jedoch relevante Werkzeuge für die Modellierung innerhalb des Projektes.

Einige der durchzuführenden Analysen basieren auf der Extraktion von Geschäftsprozessen in Form von Subgraphen. In diesem Zusammenhang ist es von Vorteil, wenn sich diese Subgraphen systemseitig logisch getrennt in mehreren Datenbanken verwalten lassen. Diese optionale Anforderung wird jedoch nur von zwei Systemen erfüllt.\\
Die Möglichkeit zur Definition eines Schemas ist ein rein informatives Kriterium. Es wird deutlich, dass viele der Systeme auf die anwendungsseitige Umsetzung eines Schemas ausgerichtet sind und keine bzw. nur wenige Werkzeuge für die systemseitige Schemaverwaltung anbieten.\\
Die Erfüllung der ACID-Eigenschaften im Zusammenhang mit der Transaktionsausführung in operativen Systemen spielt in Unternehmensdaten eine wichtige Rolle. Da das auszuwählende GDBMS jedoch vorrangig für die Analyse und weniger für den operativen Betrieb genutzt werden soll, wird diese Anforderung als optional deklariert.\\
Im Zusammenhang mit ACID hat die Möglichkeit zur Definition von Integritätsbedingungen große Bedeutung: Modellinhärente Bedingungen, wie zum Beispiel die referentielle Integrität, bei der eine Kante mindestens einen Start- und einen Zielknoten besitzen muss, werden von allen Systemen implementiert. Die Möglichkeit zur Definition von Integritätsbedingungen wird als optionale Anforderung gewertet.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{3.5cm}|>{\centering}m{2.25cm}|>{\centering}m{1.5cm}|>{\centering}m{1.25cm}|>{\centering\arraybackslash}m{2.25cm}|}
	\hline
	\multicolumn{6}{|c|}{\textbf{Datenverwaltung und Datenmodellierung}} \\
	\hline
   	GDBMS & Datenmodell & Mehrere\newline~Datenbanken* & Schema* & ACID* & Integritäts-\newline bedingungen* \\   
   	\hline
   	Affinity		& Gerichteter, knotenattributierter Multigraph	& - & -	& \checkmark & \checkmark \\
   	ArangoDB		& PGM	& \checkmark & - & \checkmark & \checkmark \\
   	Bitsy			& PGM	& -	& -	& \checkmark & \checkmark \\
   	FlockDB			& Gerichteter, knotenattributierter, kantenbezeichneter Graph & \checkmark	& -	& -	& \checkmark \\
   	HypergraphDB	& PHGM	& -	& \checkmark & \checkmark & \checkmark \\
   	Infogrid		& Gerichteter, knotenattributierter, kantenbezeichneter Multigraph	& -	& \checkmark & \checkmark & \checkmark \\
   	Neo4j			& PGM	& -	& (\checkmark)	& \checkmark	& \checkmark \\
   	OQGRAPH			& Gerichteter, gewichteter Multigraph	& -	& -	& -	& \checkmark \\
   	OrientDB		& PGM	& -	& \checkmark	& \checkmark	& \checkmark \\
   	Titan			& PGM	& -	& \checkmark	& \checkmark	& \checkmark \\
   	\hline
   	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Datenverwaltung und Datenmodellierung]{Anforderungen hinsichtlich der Datenverwaltung und -modellierung innerhalb von GDBMS. Die mit * gekennzeichnete Anforderungen sind optional bzw. besitzen nur informativen Charakter.}
	\label{tab:verwaltung}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Zugriffsmechanismen}

Tabelle \ref{tab:zugriff} vergleicht die verbliebenen acht Systeme hinsichtlich ihrer Zugriffsmechanismen.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{1.65cm}|>{\centering}m{1.25cm}|>{\centering}m{1.25cm}|>{\centering}m{1.25cm}|>{\centering\arraybackslash}m{2cm}|>{\centering}m{1.5cm}|>{\centering\arraybackslash}m{1.25cm}|}
	\hline
	\multicolumn{8}{|c|}{\textbf{Zugriffsmechanismen}} \\
	\hline
   	GDBMS & Embedded\newline API & Remote \newline API* & Plugin \newline API* & CRUD & Traversierung & Anfrage-\newline sprache* & Bulk\newline Load \\   
   	\hline   
   	ArangoDB		& -				& \checkmark 	& - 			& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	Bitsy			& \checkmark	& \checkmark	& -				& \checkmark 	& \checkmark & \checkmark	& -				\\
   	HypergraphDB	& \checkmark	& -				& - 			& \checkmark 	& \checkmark & - 			& -				\\
   	Neo4j			& \checkmark	& \checkmark	& \checkmark	& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	OrientDB		& \checkmark	& \checkmark	& -				& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	Titan			& \checkmark	& \checkmark	& \checkmark	& \checkmark	& \checkmark & \checkmark	& \checkmark	\\
   	\hline
   	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Zugriffsmechanismen]{Anforderungen an die Zugriffsmechanismen von GDBMS. (*optional/informativ)}
	\label{tab:zugriff}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Speicherung}

Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{2.5cm}|>{\centering}m{2.5cm}|>{\centering}m{2.5cm}|>{\centering\arraybackslash}m{2.5cm}|}
	\hline
	\multicolumn{5}{|c|}{\textbf{Speicherung}} \\
	\hline
   	GDBMS & Persistenz & Native Speicherung*  & Hauptspeicher-\newline~zentriert* & Index-\newline unterstützung \\
   	\hline   
   	Bitsy			& \checkmark	& -				& \checkmark	& \checkmark 	\\
   	HypergraphDB	& \checkmark	& \checkmark	& - 			& \checkmark 	\\
   	Neo4j			& \checkmark	& \checkmark	& -				& \checkmark	\\
   	OrientDB		& \checkmark	& \checkmark	& -				& \checkmark	\\
   	Titan			& \checkmark	& -				& -				& \checkmark	\\
   	\hline
	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Speicherung]{Anforderungen an die Datenspeicherung in GDBMS. (*optional/informativ)}
	\label{tab:speicherung}
\end{table}
\renewcommand{\arraystretch}{1}

\paragraph*{Skalierbarkeit und Verfügbarkeit}

Lorem ipsum dolor sit amet, ex mei tale aliquip. Dolore labitur legimus est et, mea commune nominati ei. Tantas molestiae conclusionemque ad vix, nec cu meliore admodum intellegam. Qui facer facete imperdiet ut. Ea sit feugait referrentur.

\renewcommand{\arraystretch}{1.25}
\begin{table}[h]
	\centering
	\begin{footnotesize}
   	\begin{tabular}{|m{2.25cm}|>{\centering}m{2.5cm}|>{\centering}m{2.5cm}|>{\centering\arraybackslash}m{2.5cm}|}
	\hline
	\multicolumn{4}{|c|}{\textbf{Skalierbarkeit und Verfügbarkeit}} \\
	\hline
   	GDBMS & Partitionierung* & Replikation*  & Backup* \\
   	\hline   
   	Bitsy			& -				& -				& \checkmark \\
   	HypergraphDB	& -				& \checkmark	& \checkmark \\
   	Neo4j			& -				& \checkmark	& \checkmark \\
   	OrientDB		& -				& \checkmark	& \checkmark \\
   	Titan			& \checkmark	& \checkmark	& \checkmark \\
   	\hline
	\end{tabular} 
	\end{footnotesize}
	\setlength{\belowcaptionskip}{0.25cm}	
	\caption[Anforderungen: Skalierbarkeit und Verfügbarkeit]{Anforderungen an die Skalierbarkeit und Verfügbarkeit von GDBMS. (*optional/informativ)}
	\label{tab:skalierbarkeit}
\end{table}
\renewcommand{\arraystretch}{1}

Id scripta fastidii vix. Id pri case dicunt definitiones. Quo lorem mediocrem moderatius et, ut his sapientem dignissim, alterum albucius delicata eos id. Nec id doctus fastidii pertinacia, nam no veniam petentium definitionem, iusto mnesarchum has ne. Per eu ubique aliquid voluptatum. Id cum deserunt convenire, quando abhorreant duo ut, ius ad molestiae dignissim hendrerit.

Pro eu justo tantas dolores. Albucius salutatus cum ea. Et delicata omittantur per, in cum wisi definitionem, vis in nulla nihil graecis. Vix habeo praesent torquatos ei, te vel indoctum deterruisset. Ei qui erat ipsum neglegentur.

Est cu modus partem persius. Usu no doctus utroque, eu eam clita ubique, ut possit epicurei explicari vix. In vim error scribentur. Sea iracundia intellegam te, summo dolor delectus ne has, per in atomorum democritum. Ex ullum utinam habemus qui, eam nulla inciderint no. Cu ferri maiorum quo.

Cu unum perfecto usu, sed an natum prompta aliquid, no pri meis illum integre. Cu audire feugiat fastidii sit, te mea salutandi consulatu consetetur. Duo dicat verterem no. Vel an atqui forensibus, vix et eros maluisset scripserit.


Überleitung:

- physische Speicherung, Transaktionen und Indexierung werden nur bei nativen GDBMS beschrieben

\section{Neo4j}

Neo4j ist ein quelloffenes GDBMS, das von der Firma Neo Technology\footnote{\url{http://www.neotechnology.com/}} entwickelt wird. Version 1.0 wurde 2010 veröffentlicht, zum aktuellen Zeitpunkt befindet sich Version 2.0 in Entwicklung. Die Implementierung des Systems erfolgt in den Programmiersprachen Java und Scala, die Ausführung erfolgt dementsprechend auf der Java Virtual Machine (JVM). Neo4j ist ein natives GDBMS, es unterstützt eine graphenorientierte Verarbeitung gemäß der beschriebenen indexfreien Adjazenz und implementiert eine graphenorientierte physische Repräsentation der Datenbasis. Die Verwendung des Systems erfolgt entweder in Form einer eingebetteten Bibliothek innerhalb von Java-Anwendungen oder in einer Client-Server-Konfiguration, letzteres erfordert den client-seitigen Zugriff über REST-Schnittstellen. Entsprechende Clients stehen in vielen Programmiersprachen zur Verfügung\footnote{\url{http://www.neo4j.org/develop/drivers}}. Neo4j kann sowohl als zentrales GDBMS als auch in einer verteilten Konfiguration eingesetzt werden. Eine vollständige Replikation der Datenbasis ermöglicht dabei die Skalierbarkeit lesender Anfragen und erhöht gleichzeitig die Ausfallsicherheit des Gesamtsystems. Die Speicherung der Datenbasis erfolgt disk-zentriert, ein hauptspeicher-zentrierter Betrieb ist nicht möglich.

Neo Technology bietet das Datenbanksystem in drei verschiedenen Ausführungen an: Community, Advanced und Enterprise. Die Community-Edition bietet grundlegenden Funktionsumfang, die Advanced-Edition fügt Monitoring-Funktionalität hinzu und die Enterprise-Edition erweitert diese diese nochmals um Online-Backups und Hochverfüg-barkeits-Mechanismen. Advanced- und Enterprise-Edition eignen sich für den kommerziellen Einsatz, da sie zusätzliche Service-Leistungen durch Neo Technology beinhalten und ihre Lizenz die Verwendung in unfreier Software erlaubt. Die Community-Edition darf nur in freier, quelloffener Software eingesetzt werden, Service-Anfragen werden durch die Neo4j-Community im Web beantwortet.

Die nachfolgenden Erläuterungen beziehen sich auf Version 2.0.0-M04 des GDBMS, diese Version beinhaltet Erweiterungen hinsichtlich des Datenmodells und der Anfragesprache. Die Informationen stammen aus der offiziellen Neo4j-Dokumentation\cite{Neo4j_manual:2013} sowie aus den Ausführungen in \cite{robinson2013graph}.

\subsection{Datenmodell und Konsistenzerhaltung}

Neo4j implementiert das Property-Graph-Modell, dieses wird in der aktuellen Version um Knotenbezeichner erweitert, mit deren Hilfe sich Knoten zu Gruppen zusammenfassen lassen. Ein Knoten kann keiner oder einer Gruppe, aber auch beliebig vielen Gruppen zugeordnet werden. Knoten- und Kantenbezeichner werden in Neo4j als Labels bezeichnet. Die Modell-Erweiterung um Knoten-Labels bietet verschiedene Vorteile: Anfragen lassen sich durch Einbeziehen von Labels auf einen Teilgraphen einschränken, was die Formulierung von Anfragen stark vereinfacht und deren effizientere Ausführung ermöglichen kann. Labels sind nicht gleichbedeutend mit einer Relation in der relationalen Algebra, ein Label wird lediglich durch seinen Namen definiert, es wird kein Schema der zugeordneten Elemente vorgegeben. Label können zur Laufzeit an Knoten hinzugefügt und entfernt werden. Insgesamt betrachtet sind sie ein nützliches Werkzeug in der strukturierten Anwendungsmodellierung.

Beziehungen zwischen Knoten werden durch Kanten beschrieben. In Neo4j sind diese grundsätzlich gerichtet, besitzen also immer Start- und Zielknoten, Schleifen\footnote{Eine Kante ist eine Schleife, wenn Start- und Endknoten identisch sind\cite{DBLP:books/daglib/0030488}.} sind ebenfalls zulässig. Kanten lassen sich in beiden Richtungen traversieren, d.h. eine bidirektionale Beziehung erfordert nicht zwingend die Definition von zwei Kanten unterschiedlicher Richtung. Eine Kante besitzt immer ein Label, welches zusammen mit der Richtung der Kante deren Semantik festlegt. Genau wie Knoten besitzen auch Kanten eine eindeutige Identität in Form einer 64-Bit-Ganzzahl, die vom GDBMS verwaltet wird und nicht durch die Anwendung geändert werden kann. Die Identität einer Kante ermöglicht die Definition paralleler Kanten mit identischem Label.

Knoten und Kanten lassen sich in Neo4j mit optionalen Attributen in Form von Schlüssel-Wert-Paaren versehen, diese werden in Neo4j als Properties bezeichnet. Property-Schlüssel sind vom Typ \texttt{String}, zulässige  Property-Werte müssen Instanzen eines primitiven Java-Datentypen, zum Beispiel \texttt{int} oder \texttt{float}, sein. Arrays von primitiven Datentypen sind ebenfalls zulässige Werte. Weist eine Instanz keinen Wert auf, so wird dies durch das Weglassen des entsprechenden Schlüssel-Wert-Paares definiert und nicht durch die Verwendung von \texttt{null} als Wert.

Zur Gewährleistung der Datenintegrität hält das Modell verschiedene Mechanismen vor: Eine Kante kann allein zwischen existierenden Knoten erzeugt werden, das Löschen eines Knotens erfordert das vorherige Löschen aller inzidenten Kanten des Knotens. Diese Einschränkung kann als Analogie zur referentiellen Integrität\cite{vossen2008datenmodelle} in relationalen Datenbanksystemen verstanden werden. Neo4j unterstützt darüber hinaus auch attributbezogene Integritätsbedingungen. Die Festlegung einer eindeutigen Identität durch das GDBMS entspricht einer Primärschlüssel-Definition, die Definition eines Datentyps für Attributwerte stellt eine Wertebereichs-Einschränkung dar und darüber hinaus unterstützt Neo4j die Definition einer \texttt{UNIQUE}-Bedingung für Knotenattribute. Letztere legt fest, dass ein Wert in der Menge aller Werte eines Schlüssels einzigartig sein muss. Diese Bedingung lässt sich nur in Verbindung mit Knoten-Labels definieren.

Neo4j verwaltet exakt eine Graphdatenbank, alle Knoten und Kanten sind dieser Datenbank zugeordnet. Eine logische Partitionierung der Knotenmenge ist durch Labels oder dedizierte Attribute möglich, für den Fall, dass auch die Kantenmenge partitioniert werden soll, ist dies ausschließlich über Attribute möglich. 

Die Definition von Kanten-Labels ist obligatorisch, die Definition von Knoten-Labels ist optional. Die Berücksichtigung von Labels beim Zugriff auf die Datenbank ist hingegen generell optional: Es besteht die Möglichkeit, die Datenbank zu verwenden, ohne dass das Schema beachtet wird. Durch Einbeziehen des Schemas ist es jedoch möglich, von den Vorteilen, wie strukturierter Anwendungsmodellierung, vereinfachten Anfragen und effizienter Anfrageausführung zu profitieren. Das Datenmodell eignet sich somit in Anwendungen, bei denen die Anforderungen zu Beginn nicht vollständig erfasst werden können und in denen daher eine hohe Flexibilität hinsichtlich Schemaänderungen erforderlich ist.

\subsection{Zugriffsmechanismen, Transaktionen und Indexverwaltung}

Neo4j bietet vier Varianten unterschiedlicher Mächtigkeit für den Zugriff auf die Datenbasis an: Core API, Traversal Framework sowie die Anfragesprachen Cypher und Gremlin. Alle Zugriffsmechanismen lassen sich sowohl im eingebetteten Betrieb als auch in der Client-Server-Konfiguration via REST verwenden. Cypher ist die primäre Anfragesprache in Neo4j, sie wird von Neo Technology entwickelt. Gremlin hingegen entstand im Rahmen des Blueprints-Projektes\footnote{https://github.com/tinkerpop/blueprints/wiki}. Es handelt sich dabei um eine Sammlung von Schnittstellen und Implementierungen, welche die Verarbeitung von Graphen unterstützen und sich dabei am PGM orientieren. Gremlin ist Teil dieser Sammlung und wird unter anderem von Titan und OrientDB als primäre oder sekundäre Anfragesprache eingesetzt. Auf Gremlin wird im Zusammenhang mit den zwei genannten Systemen eingegangen.

\paragraph*{Core API}

Die Core API ist eine imperative Java-API und stellt CRUD-Operationen für den Lese- und Schreibzugriff auf Knoten, Kanten und Properties zur Verfügung. Knoten können erzeugt und optional mit Labels und Properties versehen werden. Kanten werden unter Angabe existierender Knoten erstellt, dabei gibt die Knotenreihenfolge die Richtung der Kante vor, ein Label ist obligatorisch. Dieses kann innerhalb der Anwendung statisch hinterlegt oder dynamisch zur Laufzeit erzeugt werden. Eine Kanteninstanz erlaubt das Auslesen des Start- und Endknotens, des Labels und - sofern vorhanden - der Properties. Das Aktualisieren von Knoten und Kanten ist ebenfalls mit der nativen API möglich, Knotenlabels können jederzeit angefügt oder entfernt werden, Knoten- und Kantenproperties lassen sich unter Berücksichtigung der zulässigen Datentypen beliebig manipulieren. Das Löschen von Knoten und Kanten ist unter Beachtung der referentiellen Integrität ebenfalls möglich.

Es wird deutlich, dass sich ausgehend von der nativen API beliebige Graphalgorithmen anwendungsseitig implementieren lassen. Ein Beispiel für die Verwendung der nativen API findet sich in Anhang \ref{anh:neo4j_native_api}. Neo4j bietet in der nativen Java-API bereits eine Algorithmensammlung zur Berechnung von Pfaden an. Hierbei können Pfade fester und beliebiger Länge, sowie kürzeste Pfade in ungewichteten und gewichteten Graphen berechnet werden. Für letztere steht eine  Implementierung des Dijkstra-Algorithmus zur Verfügung. Der ebenfalls implementierte A*-Algorithmus erlaubt die Definition beliebiger Heuristiken zur Priorisierung von Kanten, die Berechnung in ungewichteten Graphen erfolgt mittels Breitensuche. In allen Fällen können die zu traversierenden Kantenlabel vorgegeben und einzelne oder alle Pfadinstanzen berechnet werden.

\paragraph*{Traversal Framework}

Das Traversal Framework ist eine Erweiterung der Core API. Es ermöglicht die Definition eines abstrakten Weges und liefert als Ergebnis eine Menge von Instanzen dieses Weges. Die Ausführung der Traversierung erfolgt Iterator-basiert, was bedeutet, dass die eigentliche Berechnung eines Weges erst bei Anfrage der nächsten Instanz ausgeführt wird.\footnote{Diese Strategie wird auch als \textit{Lazy Evaluation} bezeichnet.} Das Framework umfasst mehrere Schnittstellen, mit deren Hilfe der Nutzer den abstrakten Weg beschreiben und das Verhalten der Traversierung beeinflussen kann. Es ist ausschließlich der lesende Zugriff auf die Datenbasis möglich.

Ausgangspunkt einer Traversierung ist die \texttt{TraversalDescription}, eine Schnittstelle zur Beschreibung und Initialisierung einer Traversierung. Zunächst lässt sich mit Hilfe eines \texttt{PathExpander} festlegen, welche Kantenlabels bei der Traversierung zu berücksichtigen sind. Das Weglassen dieser Information, hat zur Folge, dass alle Kanten traversiert werden. Die Angabe eines Labels ermöglicht zudem das optionale Festlegen einer Richtung der zugehörigen Kanteninstanzen. Stehen mehrere Kantenlabels zur Auswahl, kann durch die Reihenfolge ihrer Aufzählung die Priorität bei der Traversierung bestimmt werden. Aufgrund das Whitelist-Prinzips ist das Ausschließen definierter Kantenlabels nicht möglich.\\
Eine weitere wichtige Schnittstelle ist \texttt{Path}, diese erfüllt zwei Aufgaben: Zum Einen sind die Ergebnisse der Traversierung Instanzen dieser Schnittstelle und zum Anderen wird sie für die Evaluation der aktuellen Position innerhalb des Graphen während der Traversierung verwendet. Im Rahmen der Evaluation wird entschieden, ob der aktuelle Knoten in das Ergebnis aufgenommen werden soll, und ob die Traversierung ausgehend von der aktuellen Position fortgesetzt wird. Es handelt sich somit um ein Filter- und Abbruchkriterium für die Traversierung. Die Entscheidungslogik wird unter Verwendung der Schnittstelle \texttt{Evaluator} implementiert.

Neben den genannten Schnittstellen zur Definition des abstrakten Weges lässt sich das Verhalten der Traversierung durch weitere Schnittstellen beeinflussen. Der Graph kann mittels Breiten- oder Tiefensuche durchlaufen werden, alternativ kann ein beliebiges Vorgehen durch die Implementierung einer \texttt{BranchOrderingPolicy} beschrieben werden. Durch die Implementierung der Schnittstelle \texttt{BranchSelector} wird dabei festgelegt, welche Kante als nächstes traversiert wird. An dieser Stelle können zum Beispiel Heuristiken in die Entscheidung einbezogen werden.\\
Mittels \texttt{Uniqueness} lässt sich festlegen, wie oft ein Objekt während der Traversierung besucht werden darf. Objekte sind Knoten oder Kanten, diese können entweder global oder innerhalb des bisher traversierten Pfades eindeutig sein. Die Festlegung ist insbesondere in zyklischen Graphen notwendig, standardmäßig wird die globale Eindeutigkeit von Knoten gefordert.

Eine den Anforderungen entsprechend definierte \texttt{TraversalDescription} wird unter Angabe eines Startknotens instanziiert. Das Ergebnis dieses Aufrufs ist ein \texttt{Traverser}-Objekt, welches den Iterator zur Verfügung stellt. In Anhang \ref{anh:neo4j_traversal_framework} findet sich ein Beispiel für die Traversierung.

Das Traversal Framework erweitert die Core API um ein grundsätzlich deklaratives Hilfskonstrukt, mit welchem die Datenbasis beliebig traversiert werden kann. Die Implementierung der Abbruch- und Filterkriterien erfolgt imperativ unter Verwendung der Core API. Hinsichtlich der Programmierbarkeit steht damit ein universelles Werkzeug für die Verarbeitung von Graphen zur Verfügung. Für Nicht-Programmierer stellt dies gleichzeitig ein entscheidendes Hindernis hinsichtlich des Zugriffs auf die Datenbasis dar. Neo4j bietet mit der Anfragesprache Cypher einen Lösungsansatz.

\paragraph*{Cypher}

Cypher ist eine deklarative, graphenorientierte Anfragesprache für den lesenden und schreibenden Zugriff auf die Datenbasis. Es handelt sich um eine nicht standardisierte Sprache, welche aktuell in Neo4j und in abgeänderter Form im GDBMS-Prototypen GraphPack zur Verfügung steht. Syntaktisch ist Cypher an SQL und SPARQL angelehnt, viele der dort vorhandenen Sprachkonstrukte und Ansätze werden wiederverwendet. Kernfunktion der Sprache ist das Beschreiben von Mustergraphen zur Informationsextraktion. Das Prüfen der Erreichbarkeit im Allgemeinen und das Berechnen kürzester Pfade im Speziellen ist darüber hinaus ebenfalls möglich. Nachfolgend werden die grundlegenden Komponenten der Sprache dargestellt, eine detaillierte Beschreibung kann der offiziellen Dokumentation entnommen werden\cite{Neo4j_manual:2013}.
\newpage
Eine rein lesende Anfrage setzt sich aus den folgenden Komponenten zusammen:

\texttt{[START] [MATCH] [WHERE]\newline
[WITH [ORDER BY] [SKIP] [LIMIT]]\newline
RETURN [ORDER BY] [SKIP] [LIMIT]}.

In der optionalen \texttt{START}-Klausel werden Bezeichner festgelegt und an Knoten- oder Kanteninstanzen gebunden. Die Auswahl einer Instanz erfolgt dabei entweder unter Angabe ihrer Identität oder mittels indexbasierter Suche. Zum Beispiel führt die Anweisung 

\texttt{START a=node:Employees(name=\string"Alice\string")} 

zur Suche nach einem Knoten mit der Eigenschaft \texttt{name=\string"Alice\string"} innerhalb des Index\linebreak \texttt{Employees}. Existiert eine entsprechende Instanz, erfolgt die Bindung an den Bezeichner \texttt{a}. Trifft die Bedingung auf mehrere Instanzen zu, so verweist \texttt{a} auf die entsprechende Menge. Alle gebundenen Bezeichner können in den nachfolgenden Teilen der Anfrage verwendet werden. Zulässige Datentypen für Bezeichner und Variablen sind generell Knoten, Kanten, Pfade und Literale bzw. deren Mengen.

Wird keine \texttt{START}-Klausel definiert, ist die nachfolgende \texttt{MATCH}-Klausel obligatorisch. Sie ermöglicht die Definition eines Mustergraphen zum Auslesen von Informationen aus der Datenbasis. Ein Mustergraph besteht aus einer beliebigen Anzahl Variablen, welche beim Finden einer Übereinstimmung an Objektinstanzen gebunden werden. Mit dem Ziel, einen Mustergraphen in Textform zu repräsentieren, wird dieser in Fragmente zerlegt, wobei jedes Fragment der Definition eines abstrakten Weges entspricht. Der in Abbildung \ref{fig:neo4j_pattern_graph} gezeigte Mustergraph lässt sich durch zwei Fragmente beschreiben:

\texttt{MATCH\newline
c:Employee---a-[:WORKS\_WITH]->b:Employee-[:WORKS\_WITH]->c, // 1\newline
b-[:RESPONSIBLE\_FOR]->d:Project // 2}

Innerhalb des Musters sind die in der \texttt{START}-Klausel definierten Bezeichner die Konstanten, sie stellen somit die Verbindungen zwischen Muster und Datenbasis her. Neo4j bezeichnet diese als \textit{bound pattern elements}, im Beispiel ist dies der Knoten \texttt{a}. Die Variablen \texttt{b}, \texttt{c} und \texttt{d} werden beim Finden einer Übereinstimmung an Knoten- bzw. Kanteninstanzen gebunden, alle Variablen stehen in den nachfolgenden Teilen der Anfrage zur Verfügung. Am Beispiel wird die Verwendung der Knotenlabel deutlich: Die Variablen \texttt{b} und \texttt{c} legen das Label gebundener Knoteninstanzen auf \texttt{Employee} fest, während die Variable \texttt{d} die Menge möglicher Instanzen auf Projekte einschränkt. Die Angabe eines Kantenlabels ist optional, so verlangt das erste Fragment im Beispiel eine Kante mit beliebiger Richtung und beliebigem Label zwischen den Knoten \texttt{c} und \texttt{a}, wohingegen zwischen den Knoten \texttt{b} und \texttt{d} eine gerichtete Kante mit dem Label \texttt{RESPONSIBLE\_FOR} existieren muss. Es besteht darüber hinaus die Möglichkeit, mehrere Kantenlabel zwischen zwei Knoten zu erlauben und einen Bereich für die Länge des Weges zwischen den Knoten festzulegen. Dies ermöglicht das Finden von Pfaden beliebiger und fester Länge und erlaubt eine hohe Flexibilität bei der Analyse von Beziehungsmustern. Der kürzeste Pfad kann ebenfalls als Fragment eines Mustergraphen definiert werden. So bindet zum Beispiel der Ausdruck

\texttt{MATCH p = shortestPath(a:Employee-[*..5]-b:Project)}

die Variable \texttt{p} an die Instanz des kürzesten Pfades zwischen Mitarbeiter \texttt{a} und Projekt \texttt{b}. Die Länge des Pfades muss zwischen 0 und 5 betragen, Kantenlabel und -richtung  bleiben unberücksichtigt. Alternativ liefert die Funktion \texttt{allShortestPaths} alle kürzesten Pfade zwischen zwei Knoten.\\
Steht die \texttt{MATCH}-Klausel am Beginn der Anfrage, dann ist in diesem Abschnitt kein Bezeichner gebunden. Folglich wird entweder die vollständige Datenbasis nach dem Muster durchsucht, oder anhand von eventuell definierten Labels die Menge der Objekte eingeschränkt. Alternativ können Prädikate in der nachfolgenden \texttt{WHERE}-Klausel zur Einschränkung des Suchraums genutzt werden.
	 
Die \texttt{WHERE}-Klausel entspricht der Selektion in der relationalen Algebra. Sie ist optional und ermöglicht die Filterung von Ergebnistupeln mittels Prädikaten. Cypher bietet eine Vielzahl mathematischer, vergleichender und boolescher Operatoren für die Definition und Verknüpfung von Prädikaten an. Soll zum Beispiel im Mustergraphen das Attribut \texttt{age} der an die Variable \texttt{b} gebundenen Instanzen eingeschränkt werden, so ist dies mit folgender Anweisung möglich:

\texttt{WHERE b.age? > 23 AND b.age? < 42}

Da Properties keinem Schema unterliegen, kann mittels \texttt{?}-Operator geprüft werden, ob die entsprechende Instanz diesen Attributschlüssel besitzt. Ist dies nicht der Fall, wird \texttt{True} zurückgegeben.

Die ebenfalls optionale \texttt{WITH}-Klausel besitzt kein Pendant in der relationalen Algebra, sondern entspricht der Funktionsweise des Pipe-Operators der Linux-Shell. Mit dessen Hilfe lassen sich Operationen verketten: Die Ausgabe einer Operation kann als Eingabe der Folgeoperation verwendet werden. Dies ist in Cypher genau dann erforderlich, wenn Aggregate innerhalb einer \texttt{WHERE}-Bedingung verwendet werden sollen oder wenn lesende und schreibende Anfragen verkettet ausgeführt und die Sichtbarkeit der Variablen in Folgeoperationen gegeben sein muss.

Am Ende einer rein lesenden Cypher-Anfrage befindet sich die obligatorische \texttt{RETURN}-Klausel, diese entspricht der Projektion in der relationalen Algebra. Die Klausel legt fest, aus welchen Variablen sich das Anfrageergebnis zusammensetzt und ermöglicht die Umformung der gesamten Ergebnismenge bzw. einzelner Variablenwerte. Analog zu SQL kann das Ergebnis mit \texttt{ORDER BY} sortiert sowie durch \texttt{SKIP} und \texttt{LIMIT} eingeschränkt werden.

Cypher ermöglicht die Berechnung von Aggregaten sowohl in der \texttt{RETURN}- als auch in der \texttt{WITH}-Klausel, verschiedene Aggregatfunktionen, wie zum Beispiel \texttt{min}, \texttt{max} und \texttt{avg}, stehen zur Verfügung. Darüber hinaus ermöglicht Cypher die Verwendung von skalaren (z.B. \texttt{LENGTH} und \texttt{TYPE}), mathematischen (z.B. \texttt{ABS} und \texttt{ROUND}), string-basierten (z.B. \texttt{SUBSTRING} und \texttt{LOWER}) und mengenorientierten (z.B. \texttt{FILTER} und \texttt{REDUCE}) Funktionen.

\texttt{MATCH}-, \texttt{WITH}- und \texttt{WHERE}-Klauseln lassen sich beliebig oft in beliebiger Reihenfolge kombinieren, so können zum Beispiel Ergebnismengen oder Aggregate in einer nachfolgenden Musterdefinition verwendet werden. Analog zum Traversal Framework werden rein lesende Anfragen erst ausgeführt, wenn der Nutzer auf die Ergebnisse zugreift, dies ist insbesondere dann sinnvoll, wenn ein Muster keine Bindung zur Datenbasis besitzt und diese folglich komplett durchsucht werden muss.

Neben rein lesenden Anfragen ist auch die Modifikation der Datenbasis mit Cypher möglich. Unter Verwendung der \texttt{CREATE}-Klausel lassen sich Knoten- und Kanteninstanzen mit Labels und Properties erzeugen, mit der \texttt{SET}-Klausel Properties und Knotenlabel aktualisieren und die \texttt{DELETE}-Klausel ermöglicht das Löschen von Instanzen.

Die Sprache wird permanent weiterentwickelt, was bedeutet, dass mit Änderungen und Erweiterungen der Syntax zu rechnen ist. Schwerpunkt der Version 2.0 ist unter anderem die automatische Anfrageoptimierung. Eine manuelle Anfrageoptimierung ist möglich, der Ausführungsplan einer Cypher-Anfrage lässt sich im eingebetteten Betrieb zusammen mit dem Anfrageergebnis abrufen und evaluieren.\\ Ein Vorteil gegenüber den bisher vorgestellten Zugriffsmöglichkeiten ist der rein deklarative Charakter der Sprache. Im Gegensatz zur Core API wird in Cypher festgelegt was gesucht wird und nicht wie es gesucht wird. Dies ermöglicht eine abstrakte Anfrageformulierung und eröffnet mehr Möglichkeiten zur systemseitigen Anfrageoptimierung. Demgegenüber ermöglichen es Core API und Traversal Framework eigene Algorithmen zu implementieren und somit spezielle Anwendungsfälle abzudecken. Die Aufgabe der Abstraktion erfordert dabei einen höheren Entwicklungsaufwand und eine engere Kopplung de Implementierung an die Struktur der hinterlegten Daten. Dies erlaubt jedoch eine höhere Performance, da gezielt optimiert werden kann und die Schritte Anfrageübersetzung und -optimierung entfallen.

\paragraph*{Transaktionen}

Alle Zugriffe auf die Datenbasis müssen innerhalb einer Transaktion erfolgen. Bei der Verwendung von Cypher erfolgt das Starten einer Transaktion implizit, ist bereits eine Transaktion im aktuellen Kontext aktiv, wird diese genutzt. Bei Verwendung der Core API müssen Transaktionen explizit gestartet werden. Nach einer Reihe von Lese- und Schreiboperationen wird die Transaktion entweder erfolgreich beendet (Commit) oder bei Eintritt eines Fehlers zurückgesetzt (Rollback). Um eventuell gehaltene Sperren freizugeben, muss die Transaktion grundsätzlich finalisiert werden.\footnote{Dies orientert sich am \texttt{try-catch-finally}-Prinzip zur Behandlung von Ausnahmen in Java.}

In Neo4j werden flache Transaktionen unterstützt, welche sich im Quellcode jedoch auch beliebig schachteln lassen. Diese als \textit{Flat Nested Transactions} bezeichnete Umsetzung bedingt, dass ein Rollback einer untergeordneten Transaktion nicht isoliert, sondern nur über den Rollback der übergeordneten Transaktion erfolgen kann. Dieser rekursive Ansatz hat bei Abbruch einer beliebigen untergeordneten Transaktion den Abbruch der Gesamttransaktion zur Folge.

Zur Vermeidung von Mehrbenutzeranomalien werden pessimistische RX-Sperrverfahren\footnote{Beim RX-Sperrverfahren werden zwei Arten von Sperren unterschieden: Lesesperren und exklusive Schreibsperren. Diese können auf einem Objekt gesetzt werden, um einen konkurrierenden Zugriff auszuschließen. Ist ein Objekt mit einer Lesesperre versehen, kann es von anderen Transaktionen gelesen, jedoch nicht geschrieben werden. Ist hingegen ein Objekt exklusiv gesperrt, so ist der lesende und schreibende Zugriff nur für den Sperrinhaber erlaubt, Lese- oder Schreibanforderungen anderer Transaktionen werden blockiert\cite{DBLP:books/sp/HarderR01}.} eingesetzt. Bei einem schreibenden Zugriff auf ein Objekt wird eine exklusive Sperre für das entsprechende Objekt gesetzt und bis zum Ende der Transaktion gehalten. Lesesperren hingegen werden nur für die Dauer des Lesevorgangs gehalten. Eine Transaktion sieht folglich nur eigene Änderungen und die Änderungen bereits beendeter Transaktionen. Entsprechend dem strikten Zwei-Phasen-Sperrprotokoll\footnote{Im Zwei-Phasen-Sperrprotokoll werden in einer Wachstumsphase zunächst alle benötigten Sperren angefordert. Nachdem die erste Sperre wieder freigegeben wurde, dürfen keine neuen Anforderungen erfolgen, es beginnt die Schrumpfungsphase in der Sperren nur noch freigegeben werden. Mit dem Ziel, Dirty Reads und kaskadierende Rücksetzungen infolge von Systemfehlern zu vermeiden, werden beim strikten Zwei-Phasen-Sperrprotokoll alle Sperren gleichzeitig freigegeben\cite{DBLP:books/sp/HarderR01}.} werden alle Schreibsperren am Ende der Transaktion gleichzeitig freigegeben.\\
Die langen Schreibsperren vermeiden das Problem der \textit{Dirty Reads}, durch die kurzen Lesesperren sind jedoch die Anomalien \textit{Non-Repeatable Read}, \textit{Phantom Problem} und vor allem auch \textit{Lost Update} möglich. Dieser Zustand entspricht der Isolationsebene \texttt{READ COMMITTED}, sollen höhere Isolationsebenen wie zum Beispiel \texttt{REPEATABLE READ} oder\linebreak \texttt{SERIALIZABLE} erreicht werden, so liegt dies in der Verantwortung des Programmierers. Neo4j stellt Funktionen bereit, manuell Lese- bzw. Schreibsperren auf Knoten oder Kanten zu setzen.\\
Beim Einsatz exklusiver Sperren können wechselseitige Abhängigkeiten und somit Deadlocks entstehen. Neo4j begegnet diesem Problem mit Deadlock-Erkennung: Wird beim Anfordern einer exklusiven Sperre ein potentieller Deadlock erkannt, wird die anfordernde Transaktion zurückgesetzt.

Änderungen von Transaktionen erfolgen zunächst ausschließlich im Hauptspeicher. Neo4j implementiert eine NoSteal-Strategie\cite{DBLP:books/sp/HarderR01}, bei der das Ausschreiben geänderter Objekte auf den Hintergrundspeicher vor dem Commit einer Transaktion nicht zulässig ist. Diese Strategie führt dazu, dass nach einem Ausfall des GDBMS keine inkonsistenten Änderungen in der Datenbasis vorhanden sein können und somit keine UNDO-Informationen während der Transaktionsausführung gespeichert werden müssen. Die Atomarität von Transaktionen wird durch dieses Vorgehen sichergestellt. Ein Nachteil dieser Strategie ist, dass sehr umfangreiche Änderungstransaktionen durch den verfügbaren Hauptspeicher limitiert sind. Es kann erforderlich sein, diese in mehrere kleinere Änderungstransaktionen aufzuspalten.\\
Neben der Atomarität ist auch die Dauerhaftigkeit von Änderungen ein wesentliches Ziel von Transaktionen. Damit diese erreicht werden kann, führt Neo4j ein Transaktions-Log, in dem alle Änderungen protokolliert werden. Beim erfolgreichen Beenden einer Transaktion wird ein Commit-Eintrag in die Log-Datei geschrieben, der dazu führt, dass alle transienten Änderungen der Log-Datei auf dem Hintergrundspeicher persistiert werden. Beim Ausfall des GDBMS können somit alle bis dahin erfolgreich beendeten Transaktionen wiederhergestellt werden. Das Ausschreiben der Änderungen in die Datenbasis kann also verzögert erfolgen. Dieses Vorgehen wird auch als NoForce-Strategie bezeichnet und verspricht gegenüber dem unmittelbaren Ausschreiben beim Commit einen höheren Durchsatz von Schreiboperationen\cite{DBLP:books/sp/HarderR01}.

Die Bewahrung der Konsistenz innerhalb der Datenbasis ist ebenfalls ein entscheidendes Kriterium bei der Ausführung von Transaktionen. Die bereits erwähnten modellinhärenten Integritätsbedingungen sind hierfür maßgeblich verantwortlich.

\paragraph*{Indexverwaltung} Für den performanten Zugriff auf Graphelemente anhand ihrer Properties unterstützt Neo4j die Definition von Indizes. Dies ist in Version 1.9 ausschließlich via Core API im eingebetteten und Client-Server-Betrieb möglich. Ein Index wird entweder für Knoten oder für Kanten definiert und besitzt einen eindeutigen Bezeichner. Nach dem Erzeugen lassen sich Knoten- bzw. Kanteninstanzen unter Angabe eines beliebigen Schlüssel-Wert-Paares in den Index einfügen, dieser ist folglich nicht an ein konkretes Paar gebunden. Die Suche innerhalb eines Index erfolgt ebenfalls unter Angabe eines Schlüssel-Wert-Paares, alle zugehörigen Instanzen werden zurückgegeben. Durch die fehlende Bindung an ein konkretes Property findet die Index-Aktualisierung bei Änderung der Datenbasis nicht automatisch statt: Nach dem Erzeugen bzw. Löschen einer Knoten- oder Kanteninstanz muss diese dem Index manuell hinzugefügt bzw. entfernt werden. Für das Löschen einzelner und mehrerer Einträge sowie des gesamten Index stehen Funktionen zur Verfügung. Eine automatische Indexierung wird ebenfalls angeboten: Hierfür verwaltet das GDBMS je einen Index für Knoten und Kanten, welche unter Angabe einer Liste von Property-Schlüsseln systemseitig verwaltet werden.

Seit Version 2.0 unterstützt Neo4j zusätzlich das Erzeugen von Schema-Indizes in Verbindung mit Knotenlabels. Dies ist sowohl in der Core API, als auch via Cypher möglich. Der Cypher-Befehl

\texttt{CREATE INDEX ON :Employee(name)} 

erzeugt einen Index für alle Knoten mit dem Label \texttt{Employee} und indexiert zugehörige Instanzen anhand des Property-Schlüssels \texttt{name}. Im Gegensatz zur bisherigen Umsetzung werden Schema-Indizes generell vom GDBMS verwaltet und automatisch aktualisiert, sobald sich die Datenbasis ändert. Das Löschen eines Schema-Index ist weiterhin manuell möglich.

Neo4j definiert eine Menge von Java-Schnittstellen mittels derer sich eigene Indexstrukturen implementieren lassen. Das GDBMS verwendet Apache Lucene\footnote{\url{http://lucene.apache.org/core/}} als Referenz-Implementierung, es handelt sich dabei um einen quelloffenen Volltext-Index zur Indizierung von Dokumenten auf der Grundlage von Termen. Eine weitere Implementierung ist zum Beispiel Neo4j-Spatial\footnote{\url{https://github.com/neo4j/spatial}}, eine Umsetzung des R-Baumes für räumliche Anfragen. 

\subsection{Persistenz- und Cacheverwaltung}

Neo4j ist ein natives GDBMS, was bedeutet, dass die physische Repräsentation der Datenbasis für die graphenorientierte Verarbeitung optimiert ist. Mit dem Ziel indexfreie Adjazenz zu erreichen, wird die Datenbank auf mehrere Dateien, sog. Stores, aufgeteilt. Dabei soll durch die Trennung von Topologie und Nutzdaten das performante Traversieren des Graphen ermöglicht werden. Es existieren Stores für Knoten, Kanten, Properties und Knoten- bzw. Kantenlabels. Die Stores werden zusammen in einem benutzerdefinierten Verzeichnis gespeichert, das gleichzeitig die Identität der Datenbank darstellt.\\
Die Einträge in den Stores, die nachfolgend als Satz bzw. Datensatz bezeichnet werden, besitzen ein festes Format und somit eine feste Satzlänge. Dies hat den Vorteil, dass bei Angabe einer Identität, z.B. der Knoten-Identität 23, die Position des Knotens innerhalb des Stores durch Multiplikation mit der Satzlänge in $\mathcal{O}(1)$ berechnet werden kann. Nachfolgend werden die Stores für Knoten, Kanten und Properties kurz beschrieben. Die zur Persistenz verfügbare Dokumentation bezieht sich auf die stabile Version 1.9 des GDBMS, in dieser sind Knotenlabel nicht implementiert. Die folgenden Informationen stammen zum Teil aus dem Quellcode der Version 2.0.0-M04, dies wird an entsprechender Stelle kenntlich gemacht.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=0.75]{neo4j_node_record.pdf}
	\caption[Neo4j: Datensatz eines Knotens]{Physische Repräsentation eines Knotens in Neo4j. Der Datensatz hat eine feste Länge von 14 Byte.}
	\label{fig:neo4j-node-record}
\end{figure}

In Abbildung \ref{fig:neo4j-node-record} wird der schematische Aufbau eines Datensatzes im Knoten-Store dargestellt, jeder Datensatz weist eine Länge von 14 Byte auf.\footnote{\url{https://github.com/neo4j/neo4j/blob/86b3c3e9b7c133011831cc1a7a9d8537e2b949f2/community/kernel/src/main/java/org/neo4j/kernel/impl/nioneo/store/NodeStore.java\#L68}} Das erste Byte beinhaltet ein Flag, welches signalisiert, ob der entsprechende Knoten aktuell verwendet wird oder überschrieben werden kann. Eine Liste freier Identitäten wird in einer dedizierten Datei geführt, beim Löschen eines Knotens wird dessen Identität der Liste hinzugefügt und das Flag entsprechend gesetzt. Die folgenden vier Byte speichern die Identität der ersten Kante, die sich anschließenden vier Byte die Identität der ersten Property des Knotens. In den letzten fünf Byte werden entweder die Label-Identitäten des Knotens direkt gespeichert oder es wird auf eine Property verwiesen, welche die Knotenlabels beinhaltet. Das Format ist somit sehr leichtgewichtig und enthält fast ausschließlich Zeiger auf zugehörige Datensätze.

\begin{figure}[h] 
	\centering
		\includegraphics[scale=0.75]{neo4j_edge_record.pdf}
	\caption[Neo4j: Datensatz einer Kante]{Physische Repräsentation einer Kante in Neo4j. Der Datensatz hat eine feste Länge von 33 Byte.}
	\label{fig:neo4j-edge-record}
\end{figure}

Wie Abbildung \ref{fig:neo4j-edge-record} zu entnehmen ist, besitzt der Datensatz einer Kante im Vergleich zum Datensatz eines Knotens einen deutlich komplexeren Aufbau. Ziel ist es, ausgehend von einer Kante möglichst effizient an weitere inzidente Kanten der Start- und Zielknoten zu gelangen. Zu diesem Zweck wird für beide Knoten je eine doppelt verkettete Liste inzidenter Kanten verwaltet. Jede Kante ist Element in zwei doppelt verketteten Listen und besitzt einen Verweis auf die vorhergehende und nachfolgende inzidente Kante des Start- bzw. Zielknotens. Durch die feste Satzlänge im Kanten-Store ist das Berechnen der Position in $\mathcal{O}(1)$, das Traversieren der Nachbarschaft eines Knotens $v$ folglich in $\mathcal{O}(\left|N(v)\right|)$ möglich. Das Einfügen und Löschen in doppelt verketteten Listen erfolgt ebenfalls in $\mathcal{O}(1)$ \cite{ottmann2002algorithmen}.

Das Flag am Beginn eines Datensatzes hat den gleichen Zweck wie sein Pendant im bereits beschriebenen Knotenformat. In den sich anschließenden acht Byte werden die Identitäten des Start- und Zielknotens gespeichert und so die Richtung der Kante festgelegt. Die nächsten vier Byte beinhalten die Identität des Kantenlabels, welches in einem entsprechenden Store hinterlegt ist. In den nachfolgenden 16 Byte werden die Identitäten adjazenter Kanten gespeichert. Der Verweis auf die erste Property befindet sich am Ende des Satzes. Durch die feste Satzlänge in Label- und Property-Stores ist der Zugriff auf einzelne Elemente ebenfalls in konstanter Zeit möglich, die Komplexität der Traversierung wird demnach nicht durch die Einschränkung auf bestimmte Labels oder Properties beeinflusst.

\begin{figure}[h]
	\centering	
	\subfigure[Vollständiger Datensatz]{\label{fig:neo4j-property-record}\includegraphics[scale=0.75]{neo4j_property_record.pdf}}\qquad	
	\subfigure[Einzelner Property-Block]{\label{fig:neo4j-property-block-record}\includegraphics[scale=0.75]{neo4j_property_block_record.pdf}}	
	\caption[Neo4j: Datensatz einer Property]{Physische Repräsentation von Properties in Neo4j. Der komplette Datensatz hat eine feste Länge von 41 Byte, von denen 32 Byte für vier Property-Blöcke zur Verfügung stehen.}
\end{figure}

Knoten- und Kantenproperties werden ebenfalls in einer doppelt verketteten Liste verwaltet. Abbildung \ref{fig:neo4j-property-record} zeigt den schematischen Aufbau eines entsprechenden Datensatzes.\footnote{\url{https://github.com/neo4j/neo4j/blob/86b3c3e9b7c133011831cc1a7a9d8537e2b949f2/community/kernel/src/main/java/org/neo4j/kernel/impl/nioneo/store/PropertyStore.java\#L57-L60}} In den ersten neun Byte werden der vorhergehende und nachfolgende Datensatz referenziert. Für Nutzdaten stehen insgesamt 32 Byte zur Verfügung, diese werden in vier Blöcke zu je acht Byte aufgeteilt. Jeder Block ermöglicht das Speichern einer Property und ist wie in Abbildung \ref{fig:neo4j-property-block-record} gezeigt aufgebaut: Die ersten vier Byte beinhalten einen Index-Schlüssel, mit dessen Hilfe sich der Property-Schlüssel aus einem Property-Index abrufen lässt. Das nächste Byte speichert den Typ des Property-Wertes, für den die übrigen drei Byte des Blocks reserviert sind. Reichen diese nicht aus, können bis zu drei weitere Blöcke innerhalb des Datensatzes verwendet werden. Folglich lassen sich maximal vier Properties in einem Datensatz speichern. Für große Zeichenketten und Arrays werden spezielle dynamische Stores verwaltet, auf diese wird in den letzten drei Byte eines Blocks referenziert. Der erwähnte Property-Index dient der Reduktion des Speicherbedarfs, da mehrfach verwendete Property-Schlüssel nur einmal im Index gespeichert werden und ihr zugehöriger Index-Schlüssel in den Property-Blöcken referenziert wird.
	
\paragraph*{Cacheverwaltung} Die Ausführungen zeigen, dass sich die Position eines Datensatzes in konstanter Zeit berechnen lässt. Der wahlfreie Zugriff auf Elemente innerhalb des Graphen bedingt jedoch auch den wahlfreien Zugriff auf die Stores und damit auf den langsamen Hintergrundspeicher. Wie für disk-zentrierte DBMS üblich, besitzt auch Neo4j Caches bzw. Puffer um einen möglichst großen Teil der Datenbasis im Hauptspeicher vorzuhalten. In der Architektur werden zwei Caches unterschieden: Der Filesystem-Cache und der Object-Cache.

Der Filesystem-Cache beschleunigt sowohl Lese- als auch Schreibzugriffe. Jedem Store wird ein dedizierter Cache zugewiesen, dieser teilt den Store in eine feste Anzahl gleich großer Bereiche auf und hält möglichst viele dieser Bereiche im Hauptspeicher. Die Cache-Größen können manuell konfiguriert werden, erfolgt dies nicht, orientiert sich die Größe am verfügbaren Hauptspeicher, der JVM-Heap-Größe und der Größe der Stores. Als Ersetzungsverfahren wird Least Frequently Used (LFU) implementiert. Es handelt sich um ein Verfahren, welches jene Bereiche verdrängt, auf die im Vergleich zu anderen Bereichen seltener zugegriffen wird\cite{DBLP:books/sp/HarderR01}. Für das Persistieren ausgelagerter Bereiche nutzt Neo4j standardmäßig Memory Mapped Files des Betriebssystems und überlässt somit diesem die Entscheidung, welche Teile des virtuellen Speichers im Hauptspeicher gehalten und welche auf den Hintergrundspeicher geschrieben werden.

Das Instanziieren von Java-Objekten aus der physischen Repräsentation kostet Zeit, häufig verwendete Objekte sollen demnach innerhalb des Object-Caches vorgehalten werden. Dieser soll insbesondere Lesezugriffe und das mit ihnen verbundene Traversieren beschleunigen. Alle Objekte innerhalb des Graphen werden beim ersten Zugriff instanziiert. Das bedeutet, dass zum Beispiel die inzidenten Kanten eines Knotens erst beim Abfragen der Nachbarschaft geladen und im Cache gruppiert nach Label und Richtung am Knoten abgelegt werden. Properties werden satzweise geladen, ausgelagerte Properties, wie lange Zeichenketten oder Arrays, erst beim direkten Zugriff. Der Object-Cache benötigt im Gegensatz zum Filesystem-Cache mehr Hauptspeicher für das Verwalten der gleichen Anzahl an Objekten.\footnote{Die Repräsentation eines Knotens ohne Kanten und Properties als Java-Objekt benötigt zum Beispiel 344 Byte im Hauptspeicher. Der entsprechende Datensatz umfasst 14 Byte.} In der Community-Edition überlässt Neo4j der JVM die Verwaltung des Caches. Dies hat zwei wesentliche Nachteile, ein eingebettetes GDBMS teilt sich den verfügbaren Speicher mit der Anwendung und der Garbage Collector der JVM entscheidet zu welchem Zeitpunkt Referenzen freigegeben werden. Letzteres erfolgt außerhalb der Kontrolle des GDBMS und kann ggf. zu starken Leistungseinbrüchen führen. Die Enterprise-Edition beinhaltet eine eigene Cache-Implementierung mit fester Cache-Größe und manueller Objekt-Ersetzung, was mehr Kontrolle über die gepufferten Objekte ermöglicht.

\subsection{Verteilung und Skalierbarkeit}

Wie bereits erwähnt, bietet Neo4j ausschließlich in der Enterprise Edition unter der Bezeichnung Neo4j High Availability (Neo4j HA) eine Verteilung der Datenbasis an. Die replizierte Datenverwaltung innerhalb des Rechner-Clusters erfolgt gemäß einer Master-Slave-Architektur\cite{rahm_masterslave}. Diese zeichnet sich dadurch aus, dass die Datenbasis im Sinne der vollständigen Replikation auf allen Rechnern im Cluster gespeichert ist, Schreibzugriffe ausgehend von einem Master-Rechner koordiniert und Änderungen an mehrere Slave-Rechner weitergegeben werden. Die Architektur toleriert den Ausfall einzelner Rechner und gewährleistet eine horizontale Skalierbarkeit von Lesezugriffen. Die Funktionsweise wird nachfolgend anhand der internen Ausführung von Änderungs- und Lesetransaktionen beschrieben.

Die Ausführung von Schreibzugriffen im Rahmen von Änderungstransaktionen ist an allen Rechnern des Clusters möglich. Erfolgt die Ausführung an einem Slave, wird zur Vermeidung von Inkonsistenzen dessen Datenbasis zunächst automatisch mit der des Masters synchronisiert. Der Commit einer Transaktion wird zuerst am Master und dann am Slave ausgeführt, anschließend wird der Client über den Erfolg bzw. Misserfolg der Ausführung informiert. Dieses Vorgehen stellt sicher, dass die Daten nach erfolgreicher Beendigung einer Transaktion auf zwei Rechnern gespeichert sind. Erfolgt die Ausführung hingegen direkt am Master, so ist der Ablauf zunächst identisch zum nicht-verteilten Fall. Nach erfolgreicher Beendigung einer Transaktion wird der Client informiert und anschließend die Änderungen asynchron an eine definierte Anzahl Slaves repliziert (sog. Push-Prinzip).\footnote{Die Anzahl wird als \textit{Replication Factor} bezeichnet. Die Auswahl der Slaves kann statisch festgelegt werden oder nach dem Round-Robin-Prinzip erfolgen.} Die Replikation erfolgt optimistisch: Schlägt das Abgleichen mit einem der Slaves fehl, ist die Transaktion dennoch erfolgreich. Das GDBMS stellt sicher, dass letztendlich alle Slaves synchronisiert werden, dieser Ansatz wird auch als \textit{Eventual Consistency}\cite{Vogels:2009:EC:1435417.1435432} bezeichnet.

Lesezugriffe können ebenfalls an allen Rechnern des Clusters durchgeführt werden. Aus den bisherigen Ausführungen geht hervor, dass eine Situation möglich ist, in der Slaves verschiedene Versionsstände in Bezug auf die Datenbasis aufweisen. Dies ist zum Beispiel genau dann der Fall, wenn der Replication Factor kleiner ist, als die Anzahl der Slaves im Cluster. Letztere werden synchronisiert, wenn sie eine Änderungstransaktion entgegennehmen oder, ausgehend vom Master, aktualisiert werden. Zusätzlich lässt sich ein Zeitintervall konfigurieren, in dem Slaves periodisch Änderungen vom Master beziehen (sog. Pull-Prinzip). Sollen Änderungen aus Anwendungssicht sofort wieder lesbar sein, so ist das Ausführen von Änderungs- und Lesetransaktionen am gleichen Slave erforderlich. Dieses Vorgehen resultiert jedoch im Allgemeinen in einer höheren Antwortzeit, da Kommunikation zwischen Slave und Master stattfindet und die Daten synchron an beiden Rechnern geschrieben werden.
		
Jeder Teilnehmer im Cluster besitzt Funktionen zur Koordination bzw. Kommunikation mit dem Cluster. Fällt ein Rechner aus, wird dieser als temporär inaktiv gekennzeichnet. Handelt es sich um einen Slave, ist der Betrieb durch den Ausfall nicht beeinträchtigt, nach der Reaktivierung wird der Rechner zunächst mit dem Master synchronisiert und anschließend wieder in den Betrieb aufgenommen. Fällt jedoch der Master aus, muss aus den vorhandenen Slaves ein neuer Master gewählt werden. Neo4j implementiert hierfür das Paxos-Protokoll\cite{hartung_paxos}, welches auf Basis eines Mehrheits-Votums den neuen Master bestimmt. Änderungstransaktionen, die während des Ausfalls aktiv sind, werden zurückgesetzt, neue Änderungstransaktionen werden solange blockiert, bis der neue Master aktiv ist. Datenverlust ist genau dann möglich, wenn entweder der Master ausfällt und die Änderungen noch nicht auf Slaves repliziert wurden oder wenn die Änderungstransaktion am Slave durchgeführt wird und anschließend Slave und Master gleichzeitig ausfallen. In beiden Fällen hat der neue Master folglich eine konsistente, jedoch veraltete Datenbasis.

\paragraph*{Skalierbarkeit} Die Architektur ist grundsätzlich für die horizontale Skalierbarkeit von Lesezugriffen konzipiert. Der Skalierbarkeit sind jedoch auch Grenzen gesetzt, da ein einzelner Master für die Synchronisation aller Slaves verantwortlich ist. Schreibzugriffe skalieren generell nur vertikal, da jeder Schreibzugriff am Master ausgeführt werden muss und dieser im Cluster einmalig ist. Auch das maximale Datenvolumen ist begrenzt, da die vollständige Datenbasis an jedem Rechner hinterlegt sein muss. Eine systemseitige Partitionierung der Datenbasis ist nicht implementiert. Neo Technology empfiehlt hier die anwendungsseitige Umsetzung unter Einbeziehung von Domänenwissen.

\section{HyperGraphDB}

HyperGraphDB ist ein quelloffenes GDBMS, das von Kobrix Software\footnote{\url{http://kobrix.com/index.jsp}} entwickelt wird. Die Quellcode-Lizenz ist GNU LGPL, die erste stabile Version 1.0 wurde 2010 veröffentlicht. Die Implementierung des Systems erfolgt ausschließlich in Java und sieht den Einsatz als eingebettetes Graphdatenbanksystem vor. Modellierung und Verwendung der Daten erfolgen graphenorientiert, Verarbeitung und Speicherung sind jedoch nicht-nativ: Der Graph wird auf eine Menge assoziativer Arrays abgebildet für deren Speicherung eine beliebige, entsprechend optimierte Speicherlösung eingesetzt werden kann. Standardmäßig nutzt HyperGraphDB hierfür die quelloffene, disk-orientierte Key-Value-Datenbank BerkeleyDB Java Edition\cite{Oracle_BerkeleyDB:2013}. Die Nutzung des Hauptspeichers als primäres Speichermedium ist bei Verwendung einer entsprechenden Speicherschicht möglich, HyperGraphDB bietet hierfür jedoch keine Implementierung an. Das GDBMS kann als zentrales System oder in einer verteilten Konfiguration eingesetzt werden.

Grundlegend betrachtet handelt es sich um ein objektorientiertes Persistenz-Framework zur dauerhaften Speicherung von Java-Objektinstanzen. Die Repräsentation der Daten im Hauptspeicher, Indexierung und Caching sind jedoch für die Unterstützung von Traversierung und Mustersuche ausgelegt. Wesentliche Eigenschaft des GDBMS und gleichzeitig Alleinstellungsmerkmal innerhalb der Evaluation ist die Möglichkeit zur Modellierung n-ärer Beziehungen: Als Datenmodell wird ein erweitertes Property-Hypergraph-Modell in Verbindung mit einem flexiblen Typsystem eingesetzt.\\
Konzipiert wurde das GDBMS für die Verwaltung hochkomplexer Daten, wie sie zum Beispiel in der Wissensverwaltung vorkommen\cite{Iordanov:2010:HGG:1927585.1927589}. Laut Hersteller eignet sich das System darüber hinaus für die Verwaltung sozialer Netzwerke und für den Einsatz in klassischen objektorientierten Geschäftsanwendungen\cite{HGDB_business_applications:2012}. Ein weiteres wichtiges Merkmal ist die offene Architektur, welche die Implementierung und Integration eigener Anfrage-,  Indizierungs-, Persistenz- und Verteilungsmechanismen ermöglicht.

Die nachfolgenden Ausführungen beziehen sich auf Version 1.2 des GDBMS, diese wurde im November 2012 veröffentlicht. Der Großteil der Informationen stammt aus der offiziellen Dokumentation\cite{hypergraph_db_docu:2013} und der primären Publikation zu HyperGraphDB\cite{Iordanov:2010:HGG:1927585.1927589}. Weitere Quellen werden an entsprechender Stelle genannt.

\subsection{Datenmodell und Typsystem}

% Modelltheorie
Die Basiseinheit zur Darstellung von Informationen innerhalb des Datenmodells ist das Atom. Jedem Atom ist ein Tupel bestehend aus Atomen zugeordnet, dieses wird als Zielmenge bezeichnet. Die Kardinalität der Zielmenge ist die Arität: Ein Atom mit Arität Null ist ein Knoten, wohingegen ein Atom mit einer Arität größer Null eine Kante repräsentiert.\footnote{Die Begriffe Kante und Hyperkante werden bei der Beschreibung von HyperGraphDB synonym verwendet.} Eine Kante kann folglich auf eine beliebige Anzahl von Atomen verweisen. Dies stellt eine Erweiterung des in Abschnitt \ref{subsec:hgm} definierten Hypergraph-Modells dar, da eine Kante in HyperGraphDB sowohl auf Knoten, als auch auf andere Kanten verweisen kann. Im Datenmodell werden Beziehungen zwischen Beziehungen als Relationen höherer Ordnung bezeichnet. Die Inzidenzmenge eines Atoms $a$ ist die Menge aller Atome, die $a$ in ihrer Zielmenge enthalten, d.h. die Menge aller gerichteter Kanten, die auf $a$ zeigen.

Neben der Zielmenge ist jedem Atom genau ein typisierter Wert zugeordnet. Der Typ ist beliebig und wird genau wie reguläre Daten innerhalb der Datenbasis als Atom gespeichert. Folglich können Beziehungen zwischen Typen untereinander bzw. zwischen Typen und ihren Instanzen abgebildet und in Operationen verwendet werden. Daraus geht hervor, dass Atome sowohl die Struktur als auch die Semantik des Graphen abbilden. Die Werte entsprechen den Nutzdaten und können beliebig strukturiert oder unstrukturiert sein und zur Laufzeit durch Werte eines anderen Typs ausgetauscht werden. Damit lassen sich Semantik und Struktur unabhängig voneinander ändern, dies entspricht der Schemaevolution innerhalb einer Anwendung und bietet somit eine vergleichbare Flexibilität wie zum Beispiel Neo4j.

\paragraph*{Typsystem} Die wesentliche Aufgabe eines Typen ist die Serialisierung von Laufzeitobjekten in das Format der darunterliegenden Speicherschicht sowie die umgekehrte Deserialisierung. Im Sinne der Objektorientierung ist ein Typ somit eine abstrakte Fabrik und stellt Methoden zum Erzeugen, Speichern und Löschen von Laufzeitrepräsentationen seiner Instanzen zur Verfügung.\footnote{Das Aktualisieren eines Wertes ist nicht möglich, da Werte in HyperGraphDB generell unveränderlich (engl. \textit{immutable}) sind. Dies hat den Vorteil, dass ein Wert mehreren Atomen zugeordnet sein kann, führt jedoch dazu, dass bei der Aktualisierung eines Wertes ein neuer Wert erzeugt werden muss.} Da es sich bei Typen um Atome handelt, besitzen auch diese einen übergeordneten Datentyp. Für jene, die bereits im Typsystem existieren, ist dies ein systemseitiger Datentyp mit der Bezeichnung \texttt{Top}. Wird hingegen ein Objekt, dessen Typ nicht bereits in der Datenbasis hinterlegt ist, zur Laufzeit eingefügt, so ist dessen Typ ein Typkonstruktur. Dieser erzeugt neue aus bestehenden Typen, es handelt sich folglich um einen Datentyp, dessen Instanzen ebenfalls Datentypen sind.\\
Neben den genannten Operationen stellt ein Typ eine weitere Operation zur Verfügung: Das Subsumieren. Eine Instanz A subsumiert eine Instanz B genau dann, wenn A allgemeiner ist als B bzw. wenn B immer dann verwendet werden kann, wenn A verwendet werden kann\cite{HGDB_subsume:2013}. Damit wird zum Beispiel geprüft, ob sich zwei Instanzen gegenseitig enthalten und folglich gleichwertig sind oder ob eine Instanz durch die andere ersetzt werden kann. Handelt es sich bei den Instanzen um Typen, so ermöglicht die Subsumierung die Abbildung von Vererbungshierarchien und somit die Konstruktion beliebiger Typsysteme: Wenn eine Instanz A eine zweite Instanz B subsumiert und A und B Typen sind, so erbt A von B.

Es sollte deutlich werden, dass ein Typ in HyperGraphDB ein Atom mit einer speziellen Rolle ist. Aus Anwendungssicht ermöglicht es die Definition von Knoten- und Kantenbezeichnern sowie das Speichern von Nutzdaten, aus Systemsicht die Verwaltung von Assoziationen sowohl zwischen einem Typ und seinen Instanzen als auch zwischen mehreren Typen. Das GDBMS beinhaltet vordefinierte Typimplementierungen für primitive Datentypen, JavaBeans\footnote{\url{http://www.oracle.com/technetwork/java/javase/documentation/spec-136004.html}}, 
Arrays, Collections, Maps und generell Klassen, welche die Schnittstelle \texttt{Serializable} implementieren.\footnote{Eine vollständige Übersicht befindet sich im Quelltext des GDBMS unter \url{https://code.google.com/p/hypergraphdb/source/browse/tags/release1.2/core/src/config/org/hypergraphdb/types}} Vererbungshierarchien werden ebenfalls persistiert und durch einen dedizierten Kantentyp repräsentiert. Sollen komplexere Datentypen verwendet werden oder ist die Einhaltung der JavaBeans-Spezifikation nicht möglich, lassen sich eigene Datentypen implementieren. Diese werden im Typsystem des GDBMS registriert, anschließend lassen sich deren Instanzen in der Datenbasis verwalten.\\
Ein Typsystem erlaubt die Definition von Integritätsbedingungen und das GDBMS sorgt durch deren Einhaltung für die Wahrung der Konsistenz. So lässt sich zum Beispiel die Zielmenge entsprechend typisierter Kanten auf definierte Typen einschränken, darüber hinaus ist das Definieren von Wertebereichen und Kardinalitäten möglich.

In HyperGraphDB existieren keine Primärschlüssel, die Identität eines Atoms wird durch die Instanz eines sog. Handle repräsentiert. Deren Funktion wird im Zusammenhang mit den Zugriffsmechanismen näher erläutert.

\subsection{Zugriffsmechanismen und Transaktionen}

HyperGraphDB bietet keine dedizierte Anfragesprache an, sondern erlaubt den Zugriff auf die Datenbasis ausschließlich via Java API im eingebetteten Betrieb. In diesem Zusammenhang stehen CRUD- und mengenorientierte Operationen sowie die Möglichkeit zur Traversierung des Graphen zur Verfügung.

\paragraph*{CRUD-Operationen}

Das GDBMS bietet grundlegende Funktionen zum Erzeugen, Auslesen und Löschen von Atomen an. Da Werte innerhalb der Datenbasis unveränderlich sind, erfolgt das Aktualisieren ausschließlich über den Austausch von Werten.

%Knoten
Ein Knoten definiert sich durch eine Objektinstanz innerhalb der Laufzeitumgebung. Diese lässt sich dem Graphen hinzufügen: Ist ihr Datentyp bereits im Typsystem registriert, wird er automatisch mit dem Knoten verbunden, andernfalls zunächst durch einen Typkonstruktor erzeugt. Das Resultat des Anlegens ist ein Handle, welches den Knoten innerhalb der Datenbasis identifiziert. Anhand des Handles kann die Objektinstanz und deren Typ aus der Datenbasis gelesen werden, umgekehrt lässt sich unter Angabe der Objektinstanz das zugehörige Handle laden. Das Löschen eines Atoms ist ausschließlich unter Angabe des zugehörigen Handles möglich.\\
In Verbindung mit dem flexiblen Typsystem und den vorhandenen Typimplementierungen lassen sich beliebige Nutzdaten an einem Knoten speichern. Wird zum Beispiel ein JavaBeans-Objekt dem Graphen hinzugefügt, so wird dieses intern durch eine Record-Struktur repräsentiert, die den schlüsselbasierten Zugriff auf die Attribute des Objektes ermöglicht. Da Attribute wiederum typisierte Werte sind, lassen sich beliebig verschachtelte Objekte hinterlegen.

%Kanten
Kanten werden in HyperGraphDB nicht durch Referenzen zwischen Objektinstanzen, sondern durch spezielle Kantenobjekte modelliert. Letztere sind Implementierungen der Schnittstelle \texttt{HGLink}, das GDBMS stellt drei Implementierungen zur Verfügung: Kanten können ohne jegliche Zusatzinformationen, zum Beispiel ohne eine semantische Bedeutung oder ohne Nutzdaten, angelegt werden. Eine zweite Implementierung erlaubt das Speichern von Nutzdaten, dies können beliebig komplexe Objektinstanzen oder einfache Zeichenketten zur Festlegung eines Kantenbezeichners sein. Ein dritter Typ ermöglicht zudem das Festlegen zulässiger Typen innerhalb der Zielmenge und gestattet damit die Definition von Integritätsbedingungen.\\
Kanten werden unter Angabe ihrer Zielmenge und eventueller Nutzdaten erzeugt und anschließend mittels Handle identifiziert, Auslesen und Löschen erfolgen wie bereits für Knoten beschrieben. Kanten bieten darüber hinaus Funktionen zum Lesen der Zielmenge und der Arität an. Da die Zielmenge ein Tupel und somit geordnet ist, können Handles unter Angabe ihrer Position innerhalb der Zielmenge ausgelesen werden. Dies ermöglicht die Definition von Kantentypen die einzelnen Positionen innerhalb der Zielmenge eine Semantik zuordnen.

\paragraph*{Mengenorientierte Anfragen}

Neben dem Auslesen von Atomen unter Angabe ihres Handles bietet HyperGraphDB die Möglichkeit, deklarative, mengenorientierte Anfragen an die Datenbasis zu stellen. Die hierfür vorhandene API basiert auf der Definition von Prädikaten zur Einschränkung der Ergebnismenge. Prädikate lassen sich konjunktiv bzw. disjunktiv verknüpfen sowie beliebig schachteln und negieren. Sie beziehen sich entweder auf den Wert eines Atoms oder auf die Topologie des Graphen. Die folgende Anfrage definiert zum Beispiel die Menge aller Produkte, deren Attribut \texttt{salesrank} kleiner oder gleich dem Wert 10 ist:

\texttt{hg.and(hg.type(Product.class), hg.lte(\string"salesrank\string", 10))}.

\texttt{hg} ist eine vom GDBMS bereitgestellte Klasse die syntaktisch verkürzte, einfache Methoden für das Formulieren von Anfragen anbietet und diese intern auf eine komplexere API abbildet.\footnote{Die zugrundeliegende API wird an dieser Stelle nicht beschrieben, weil die Methoden der Klasse \texttt{hg} für die Erläuterung ausreichend sind. Weiterführende Informationen sind in der offiziellen Dokumentation enthalten\cite{hypergraph_db_docu:2013}.} In der Anfrage werden die Prädikate \texttt{hg.type(Product.class)} und \texttt{hg.lte(\string"salesrank\string", 10)} durch den logischen Operator \texttt{hg.and} konjunktiv verknüpft. Das erste Prädikat legt den Typ des Atoms auf Produkte fest, während das zweite den Attributwert einschränkt. \texttt{Product} ist im Beispiel eine Klasse nach JavaBeans-Spezifikation.

Neben den Werten lässt sich auch die Topologie des Graphen in einer Anfrage durch Prädikate beschreiben. Das folgende Beispiel definiert die Menge aller Kanten, die zwei gegebene Atome in ihrer Zielmenge enthalten und insgesamt zehn Atome verbinden:

\texttt{hg.and(hg.link(atom1, atom2), hg.arity(10))}.

Im vorhergehenden Abschnitt wurde das Speichern eines Typs innerhalb der Datenbasis beschrieben: Vererbungshierarchien werden durch Subsumierung von Typen ausgedrückt, diese Beziehung lässt sich folglich auch innerhalb von Anfragen verwenden. Nachfolgend wird die Menge aller Atome definiert, deren Datentyp von einer Klasse \texttt{Person} erbt und deren Instanzen nicht 25 Jahre alt sind:

\texttt{hg.and(hg.subsumes(Person.class), hg.not(hg.eq(\string"age\string", 25)))}.

Es handelt sich demnach um eine Anfrage, in der Topologie, Semantik und auch Nutzdaten des Graphen einbezogen werden. Neben den gezeigten stehen weitere Operatoren zum Vergleich von Werten, zur Einschränkung von Typbeziehungen und zur Beschreibung der Topologie zur Verfügung.

Für das Auslesen der Ergebnismenge werden drei Methoden angeboten: Grundsätzlich wird ein Iterator erzeugt, mit dem sich die Ergebnismenge bi-direktional durchlaufen lässt, der Wert eines Atoms wird erst beim Zugriff geladen. Die direkte Verwendung des Iterators bietet sich insbesondere bei umfangreichen Ergebnismengen an. Alternativ stellt die Klasse \texttt{hg} zwei Methoden zur Verfügung, mit denen sich entweder die vollständig deserialisierten Objektinstanzen oder nur deren Handles in einer Liste zurückgeben lassen.\\
Optional kann innerhalb einer Anfrage eine Abbildung definiert und mittels \texttt{hg.apply} auf die Ergebnismenge angewendet werden. Die Abbildung ermöglicht die Realisierung einer Projektion wenn nur bestimmte Attribute der Atomwerte ausgegeben werden sollen. Zusätzlich kann eine Transformation der Elemente erfolgen. Für eine Aggregation der Ergebnismenge stehen außer \texttt{hg.count} keine Operatoren zur Verfügung und müssen folglich bei Bedarf selbst implementiert werden.

An dieser Stelle sei auf die offene Architektur des GDBMS hingewiesen: Neue Operatoren lassen sich durch das Implementieren der Schnittstellen \texttt{HGAtomPredicate} und \texttt{HGQueryCondition} hinzufügen. Dies erlaubt das Definieren beliebiger domänenspezifischer Operatoren im Rahmen des beschriebenen Forschungsprojektes. Ein Beispiel hierfür ist das Prüfen, ob eine gegebene Kante eine kausale Abhängigkeit beschreibt. Dies ist genau dann der Fall, wenn alle in der Zielmenge vorhandenen Typen einen Datentyp zur Beschreibung transaktionaler Daten subsumieren.

\paragraph*{Traversierung}

Vergleichbar mit Neo4j steht in HyperGraphDB eine Menge von Schnittstellen zur Verfügung, mit der sich eine Traversierung innerhalb der Datenbasis beschreiben lässt. Die Reihenfolge, in der ein Graph durchlaufen wird, kann durch die Implementierung der Schnittstelle \texttt{HGTraversal} festgelegt werden. Es handelt sich um einen Iterator, dessen Elemente Paare von Handles sind. Jedes Paar besteht aus einer Kante und einem Atom, auf welches die Kante zeigt. Die Schnittstelle kann darüber hinaus prüfen, ob ein Handle bereits während der Traversierung besucht wurde. HyperGraphDB stellt zwei Implementierungen der Schnittstelle zur Verfügung: \texttt{HGBreadthFirstTraversal} für die Durchführung eines Breitendurchlaufs und \texttt{HGDepthFirstTraversal} für die Durchführung eines Tiefendurchlaufs. 

Neben dem Festlegen einer Reihenfolge kann es notwendig sein, die Menge der relevanten Paare einzuschränken. Hierfür stellt HyperGraphDB die Schnittstelle \texttt{HGALGenerator} zur Verfügung. Diese Schnittstelle ermöglicht es, eine Adjazenzliste (AL) zu generieren, welche jene Paare enthält, die ausgehend von einem Atom von der Traversierung berücksichtigt werden sollen. Auch hier stellt das GDBMS zwei Implementierungen zur Verfügung. Der \texttt{SimpleALGenerator} erzeugt Adjazenzlisten aller benachbarter Atome ohne Berücksichtigung von Kanten- und Knotentypen bzw. deren Werten. Deutlich flexibler ist hingegen der \texttt{DefaultALGenerator}: Unter Verwendung der bereits beschriebenen Prädikate lassen sich sowohl Bedingungen für Kanten, als auch für Knoten\footnote{Semantisch korrekt wäre hier die Bezeichnung Geschwister, da eine Adjazenz auch zwischen Kanten definiert sein kann.} definieren. Das folgende kurze Beispiel verdeutlicht dies:

\texttt{DefaultALGenerator alGen = new DefaultALGenerator(graph,\newline
		hg.and(hg.type(Review.class), hg.gte(\string"helpful\string", 5)), // edge predicate \newline
		hg.and(hg.type(User.class), hg.eq(\string"region\string", \string"Leipzig\string"))); // node predicate}
		
Es wird festgelegt, dass ausschließlich jene Kanten traversiert werden, die vom Typ \texttt{Review} sind und die von mindestens fünf Personen als hilfreich deklariert wurden. Die Reviews selbst sollen nur von Knoten durchgeführt worden sein, die vom Typ \texttt{User} sind und aus der Region Leipzig stammen.\\
Beide Implementierungen von \texttt{HGALGenerator} verbieten das mehrfache Besuchen von Knoten, d.h. wenn mehrere Paare bestehend aus unterschiedlichen Kanten und dem gleichen Knoten existieren, wird nur eines dieser Paare berücksichtigt. Letzteres kann durch eine eigene Implementierung umgangen werden. 

Sind Reihenfolge und eventuelle Einschränkungen definiert, wird die Traversierung unter Angabe eines Start-Handles initialisiert und gestartet. Während der Ausführung werden die relevanten Paare elementweise betrachtet. Dabei stehen im Gegensatz zu Neo4j keine Instanzen bereits berechneter Wege zur Verfügung. Das Berechnen des aktuellen Abstands vom Startknoten oder das Speichern berechneter Wege muss bei Bedarf manuell erfolgen.\\
Zur Berechnung kürzester Pfade steht eine Implementierung des Dijkstra-Algorithmus zur Verfügung. Diese erfordert mindestens die Angabe eines Start- und eines Zielhandle. Darüber hinaus können optional ein \texttt{HGALGenerator} und nicht-negative Kantengewichte in Form eines assoziativen Arrays definiert werden. Soll der Ergebnispfad rekonstruierbar sein, so erfordert dies die Übergabe eines assoziativen Arrays: Dieses ordnet jedem Handle innerhalb des Pfades seinen jeweiligen Vorgänger zu.

\paragraph*{Transaktionen}

% Zugriffsart, explizig, implizit

HyperGraphDB unterstützt die Ausführung von Anfragen innerhalb von Transaktionen. Für Änderungsoperationen ist dies obligatorisch, rein lesende Zugriffe können auch transaktionsunabhängig ausgeführt werden. Bei der Ausführung einer einzelnen Schreiboperation wird eine Transaktion implizit erzeugt, sollen hingegen mehrere Zugriffe innerhalb einer Transaktion erfolgen, muss diese anwendungsseitig explizit erzeugt und verwaltet werden. Das GDBMS stellt hierfür entsprechende Funktionen zur Verfügung. Darüber hinaus besteht die Möglichkeit, Zugriffe an eine aktive Transaktion zu binden.\\ 
Transaktionen können beim Systemstart deaktiviert werden, dies ist zum Beispiel beim Importieren umfangreicher Datenmengen sinnvoll und setzt voraus, dass keine nebenläufigen Zugriffe erfolgen. Bezüglich der ACID-Eigenschaften sind Transaktionen in HyperGraphDB atomar, konsistent und erfolgen isoliert voneinander. Die Dauerhaftigkeit wird nicht garantiert, was bedeutet, dass Änderungen erfolgreich beendeter Transaktionen nach einem Systemfehler verloren sein können. Der Hersteller begründet dies mit dem daraus resultierenden höheren Schreibdurchsatz und mit der geringen Häufigkeit kompletter Abstürze der JVM.

% Schachtelung von Transaktionen

Das GDBMS erlaubt die Schachtelung von Transaktionen: Im Gegensatz zu Neo4j lassen sich dabei untergeordnete Transaktionen isoliert zurücksetzen. Der Abbruch einer übergeordneten Transaktionen führt zum Rollback aller ihr untergeordneten Transaktionen. Dies hat zur Folge, dass ein Fehler in komplexen, lange laufenden Transaktionen isoliert behandelt und der Arbeitsverlust je nach Granularität der Aufteilung minimiert werden kann.

% Mehrbenutzeranomalien

Wie bereits erwähnt, nutzt HyperGraphDB die Key-Value-Datenbank BerkeleyDB für die Speicherung der Datenbasis. Diese verwendet ein pessimistisches RX-Sperrverfahren zur Vermeidung von Lese-Schreib-Konflikten. In BerkeleyDB lassen sich verschiedene Isolationsebenen konfigurieren, standardmäßig wird \texttt{REPEATABLE READ} verwendet\cite{oracle:2013}. Lese- und Schreibsperren werden in dieser Stufe für die Dauer der gesamten Transaktion gehalten. Somit werden die Mehrbenutzeranomalien Dirty Read, Non-Repeatable Read und Lost Update vermieden. Das Phantom Problem beim parallelen Einfügen neuer Datensätze ist weiterhin möglich.\\
% Deadlocks
BerkeleyDB implementiert einen Timeout-Mechanismus\cite{DBLP:books/sp/HarderR01} zur Erkennung von\linebreak~Deadlocks\cite{oracle:2013}. Der Timeout legt fest, wie lange eine Sperre auf einem Objekt gehalten werden kann. Wird dieser Wert überschritten, geht das System von einem Deadlock aus. Da dies nicht zwingend der Realität entsprechen muss, sollte der Wert dem Zugriffsverhalten und der erwarteten Transaktionsdauer entsprechend angepasst werden um unnötige Rücksetzungen zu vermeiden. Wird ein potentieller Deadlock erkannt, benachrichtigt BerkeleyDB die Anwendung, d.h. HyperGraphDB, mittels einer Ausnahme. Die Behandlung dieser Ausnahme wird entweder von HyperGraphDB oder von Anwendung übernommen: Das GDBMS bietet die Möglichkeit eine in Folge eines Deadlocks abgebrochene Transaktion automatisch zu wiederholen bis diese erfolgreich beendet wird. Alternativ wird die Ausnahme an die Anwendung weitergeleitet, welche über die nachfolgenden Schritte individuell entscheidet.

% Logging

HyperGraphDB garantiert standardmäßig keine Dauerhaftigkeit von Transaktionen. Um dies zu erläutern,  muss kurz auf die Interna von BerkeleyDB eingegangen werden: BerkeleyDB bildet eine Datenbank innerhalb eines B-Baumes ab. Es handelt sich um eine spezielle Form, in der Nutzdaten ausschließlich in den Blättern hinterlegt sind. Änderungsoperationen beeinflussen sowohl die Struktur des Baumes als auch die Einträge in den Blättern. Zur Gewährleistung von Dauerhaftigkeit nutzt BerkeleyDB ein Transaktions-Log, in dem alle logischen Änderungsoperationen registriert werden. Dies bedeutet, dass sich durch sequentielles Ausführen der Log-Einträge der B-Baum rekonstruieren lässt. Folglich ist das Transaktions-Log die Datenbasis. Um den Wiederherstellungsaufwand im Fehlerfall zu minimieren, werden periodisch Sicherungspunkte geschrieben in denen der B-Baum vollständig gespeichert ist\cite{oracle_bdb:2013}.\\
Das Transaktions-Log wird permanent im Hauptspeicher gehalten. Kommt es während der Ausführung einer Transaktion zum Ausfall des GDBMS, sind die bis dahin erfolgten Änderungen ausschließlich im Hauptspeicher und somit verloren. Die Atomarität einer Transaktion ist damit sichergestellt und eine UNDO-Recovery nicht erforderlich. Für die Wiederholbarkeit erfolgreicher Transaktionen wird beim Commit  ein entsprechender Eintrag in das Log geschrieben. In der Standardeinstellung von BerkeleyDB führt dieser Eintrag zum Ausschreiben des Logs auf den Hintergrundspeicher, eine REDO-Recovery ist folglich möglich. HyperGraphDB initialisiert BerkeleyDB standardmäßig mit einer Konfiguration, die es der Datenbank erlaubt, das Transaktions-Log asynchron auf den Hintergrundspeicher zu schreiben, was bedeutet, dass Änderungen zum Commit-Zeitpunkt nicht unmittelbar persistiert werden.\footnote{Die Initialisierung kann im Quelltext unter \url{https://code.google.com/p/hypergraphdb/source/browse/tags/release1.2/storage/bdb-je/src/java/org/hypergraphdb/storage/bje/BJEConfig.java} in Zeile 64 nachvollzogen werden} Kommt es zwischen Commit und Persistieren des Logs zum Systemausfall, sind die Änderungen der Transaktion verloren.

\subsection{Persistenz-, Index- und Cacheverwaltung}

Wie anfangs erwähnt, ist HyperGraphDB ein nicht-natives GDBMS, welches den Graphen auf assoziative Arrays abbildet und diese im Rahmen der Anfrageausführung und der physischen Repräsentation der Datenbasis verwendet. Die Organisation erfolgt dabei innerhalb des GDBMS in zwei Schichten: Der primitiven Speicherschicht, welche direkt auf das eingesetzte Speichersystem zugreift, und der Modellschicht, welche von der primitiven Speicherschicht abstrahiert und die darin enthaltenen Informationen als Elemente des Datenmodells darstellt. Das eingesetzte Speichersystem wird nachfolgend als physische Speicherschicht bezeichnet, da es letztendlich die Persistenz der Daten sicherstellt, standardmäßig ist dies BerkeleyDB Java Edition.

Die primitive Speicherschicht repräsentiert einen Graphen bestehend aus Identitäten und ihnen zugeordneter Rohdaten, eine semantische Zuordnung findet in dieser Schicht nicht statt. Für die Speicherung werden zwei assoziative Arrays verwendet:

\texttt{LinkStore: ID $\rightarrow$ List<ID>}\newline
\texttt{DataStore: ID $\rightarrow$ byte[]}

Der \texttt{LinkStore} bildet die Topologie des Graphen ab, indem er Identitäten (IDs) eine Liste weiterer Identitäten zuordnet. Im \texttt{DataStore} werden einer Identität Rohdaten in Form eines Byte-Arrays zugewiesen. Jeder Datensatz in der primitiven Speicherschicht ist folglich ein Schlüssel-Wert-Paar. Der Schlüssel wird in HyperGraphDB durch ein spezielles Handle repräsentiert, das sog. \texttt{HGPersistentHandle}. Dieses ordnet jeder Entität eine UUID fester Länge zu. Innerhalb der primitiven Speicherschicht ist somit der \texttt{LinkStore} eine Liste von Instanzen des genannten Handles.

Die Modellschicht wandelt die Informationen der primitiven Speicherschicht in die abstrakten Elemente des Datenmodells um. Nachfolgend sind alle ID-Bezeichner als Instanzen von \texttt{HGPersistentHandle} zu verstehen. 

\texttt{AtomID $\rightarrow$ [TypeID, ValueID, TargetID, ..., TargetID]}\newline
\texttt{ValueID $\rightarrow$ [ID, ID, ..., ID] | byte[]}\newline
\texttt{TypeID $\rightarrow$ AtomID}\newline
\texttt{TargetID $\rightarrow$ AtomID}

Ein Eintrag im \texttt{LinkStore} wird in der Modellschicht entweder als Atom oder als Wert eines zusammengesetzten, nicht-primitiven Datentyps interpretiert. Im ersten Fall verweist die \texttt{TypeID} auf den Typ des Atoms während die \texttt{ValueID} den zugehörigen Wert referenziert. Anschließend wird die Zielmenge des Atoms aus einer Menge von \texttt{TargetIDs} definiert. Da ein Knoten im Datenmodell ein Atom mit Arität Null ist, enthält seine physische Repräsentation im Gegensatz zu einer Kante nur den Verweis auf seinen Typ und den Wert. Da sowohl der Typ eines Atoms als auch die Einträge in der Zielmenge Atome sind, referenzieren \texttt{TypeID} und \texttt{TargetID} eine \texttt{AtomID}.\\
Alternativ repräsentiert ein Eintrag im \texttt{LinkStore} den Wert eines zusammengesetzten, nicht-primitiven Datentyps und wird mittels \texttt{ValueID} referenziert. Wird hingegen nur der Wert eines primitiven Datentyps am Atom gespeichert verweist die \texttt{ValueID} direkt auf das entsprechende Byte-Array im \texttt{DataStore}. An dieser Stelle wird deutlich, warum Werte an Atomen grundsätzlich unveränderlich sind und eine Wertänderung nur durch den Austausch des Wertes erfolgen kann.\\
Die Deserialisierung der Werte erfolgt nicht in der Modellschicht, sondern wird von der jeweiligen Typimplementierung bzw. vom jeweiligen Typkonstruktur durchgeführt. Im Zusammenhang mit dem Typsystem wurde bereits erwähnt, dass Typen abstrakte Fabriken sind und unter anderem eine Methode zum Erzeugen der entsprechenden Instanzen zur Verfügung stellen. Diese Methode nimmt die \texttt{ValueID} entgegen und führt die Deserialisierung durch.\footnote{Dies lässt sich im Quelltext des \texttt{HGAtomType} nachvollziehen: \url{https://code.google.com/p/hypergraphdb/source/browse/tags/release1.2/core/src/java/org/hypergraphdb/type/HGAtomType.java}, Zeile 65.}

In der physischen Speicherschicht (BerkeleyDB) werden die Werte von \texttt{LinkStore} und \texttt{DataStore} als Byte-Arrays abgelegt. Die Deserialisierung der Identitäten erfolgt in der primitiven Speicherschicht, ermöglicht wird dies durch die feste Länge der UUIDs. Die Byte-Arrays im \texttt{DataStore} können erst in der Modellschicht deserialisiert werden, da erst hier Informationen zum Datentyp vorhanden sind. Es sollte deutlich werden, dass sich die Schlüsselmengen von \texttt{LinkStore} und \texttt{DataStore} überlappen können und diese somit in zwei getrennten Key-Value-Datenbanken gespeichert werden müssen.

% Index

\paragraph*{Indexverwaltung}

Für die effiziente Ausführung mengenorientierter und traversierender Anfragen beinhaltet die Modellschicht drei zusätzliche Indexstrukturen, welche jeweils in einer Key-Value-Datenbank der physischen Speicherschicht persistiert werden:

\texttt{IncidenceIndex: UUID $\rightarrow$ SortedSet<UUID>}\newline
\texttt{TypeIndex: UUID $\rightarrow$ SortedSet<UUID>}\newline
\texttt{ValueIndex: UUID $\rightarrow$ SortedSet<UUID>}

Der \texttt{IncidenceIndex} ordnet jedem Atom seine Inzidenzmenge zu, d.h. die Menge aller Kanten die auf das Atom zeigen. Der \texttt{TypeIndex} verweist auf die Menge aller Instanzen eines gegebenen Datentyps und der \texttt{ValueIndex} weist einem Wert die Menge der Atome zu, die ihn besitzen. Bei zusammengesetzten Werten wird der Wert auf höchster Ebene indexiert. Zu beachten ist, dass die zugeordneten Werte geordnete Mengen sind auf denen sich Mengenoperationen effizient ausführen lassen. Folglich lassen sich mit Hilfe der Indexstrukturen graphenspezifische Operationen effizient ausführen. Zum Beispiel lässt sich anhand der Schnittmenge der Inzidenzlisten zweier Knoten prüfen, ob diese adjazent sind.

Neben den systemseitigen Indexstrukturen können auch von der Anwendung zusätzliche Indizes definiert werden. Mit diesen ist das Indexieren sowohl der Topologie des Graphen als auch der hinterlegten Nutzdaten möglich. Indizes sind immer an einen Typ gebunden, gelten jedoch für alle Typen, welche diesen subsumieren. Auch im Zusammenhang mit Indexstrukturen wird die offene Architektur des GDBMS deutlich: Das Implementieren der Schnittstelle \texttt{HGIndexer} ermöglicht das Hinzufügen eigener Datenstrukturen. HyperGraphDB beinhaltet bereits Implementierungen zur Indexierung der Attribute eines Datentyps oder zur Indexierung vollständiger Werte eines Atoms. Für den effizienten Zugriff auf Teilgraphen ermöglicht eine weitere Implementierung die Indexierung der kompletten Zielmenge eines Atoms. Ein weiterer topologischer Index indexiert Kanten anhand eines Atoms an einer expliziten Position innerhalb der Zielmenge. Wie bereits erwähnt, ist diese geordnet, die Positionen können somit anwendungsseitig mit einer Semantik versehen werden.

Aus den bisherigen Ausführungen geht hervor, dass HyperGraphDB mindestens fünf Key-Value-Datenbanken zur Abbildung der primitiven Speicherschicht und der obligatorischen Indexstrukturen einsetzt. Für jeden anwendungsseitig definierten Index wird eine zusätzliche Datenbank benötigt. Die Komplexität der einzelnen Operationen ist dabei im Wesentlichen von der Implementierung des Speichersystems abhängig. Wie bereits im Zusammenhang mit Transaktionen beschrieben, speichert BerkeleyDB die Daten einer Datenbank in den Blättern eines B-Baumes. Der Zugriff auf diese Daten ist somit logarithmisch von der Anzahl der Einträge und der Ordnung des Baumes abhängig\cite{ottmann2002algorithmen}. Die indexfreie Adjazenz ist hingegen nur möglich, wenn sich die Daten in konstanter Zeit lesen lassen. BerkeleyDB verfügt über Caches um den Zugriff auf die Datenbasis zu beschleunigen\cite{oracle_bdb:2013}. Da es sich jedoch um ein austauschbares Speichersystem handelt, wird nachfolgend nur die Cacheverwaltung von HyperGraphDB beschrieben.

% Caching

\paragraph*{Cacheverwaltung}

Für den performanten, wahlfreien Zugriff auf die Elemente innerhalb des Graphen bietet auch HyperGraphDB Caches an: Den Atom-Cache und einen Cache für Inzidenzmengen. Der Atom-Cache ermöglicht den effizienten Zugriff sowohl auf die Objektinstanz unter Angabe des zugehörigen Handles als auch für den umgekehrten Fall. Realisiert wird der Cache durch zwei Hashtabellen und die Verwendung schwacher Referenzen. Letztere zeichnen sich dadurch aus, dass sich die von ihnen referenzierten Objektinstanzen vom Garbage Collector aus dem Speicher verdrängen lassen\cite{oracle_weak_references:2013}, beim Zugriff auf die Referenz wird das Objekt wiederhergestellt. Ein Atom wird folglich genau dann aus dem Cache verdrängt, wenn es entweder manuell durch die Anwendung oder automatisch durch die JVM entfernt wird.\\
Der zweite Cache beschleunigt den Zugriff auf die Inzidenzmengen der Atome und wird ebenfalls durch eine Hashtabelle realisiert. Hierfür implementiert HyperGraphDB einen Least Recently Used Cache (LRU), welcher jene Objekte vorhält, auf die als letztes zugegriffen wurde. Bei der Instanziierung kann festgelegt werden, welcher Anteil des freien Speichers vom Cache genutzt werden darf und wie groß der Anteil zu verdrängender Elemente bei Überschreiten der Speichergrenze sein soll.

% Cache Synchronisation
Alle Transaktionen in HyperGraphDB greifen auf den Atom-Cache zu, die ACID-\linebreak~Eigenschaften müssen somit auch bei der Verwendung des Caches gegeben sein. Das in diesem Zusammenhang eingesetzte Verfahren ist Multiversion Concurrency Control (MVCC), ein optimistisches Synchronisationsverfahren für nebenläufige Transaktionen\cite{DBLP:books/sp/HarderR01}. Das Verfahren verzichtet auf das Setzen von Lese- und Schreibsperren, stattdessen werden zu ändernde Objekte dupliziert und Änderungen an den Duplikaten durchgeführt. Lesetransaktionen haben somit immer eine konsistente Sicht auf die Datenbasis und können ohne Blockierungen durchgeführt werden. Änderungstransaktionen werden erst beim Commit auf eventuell vorhandene Konflikte mit nebenläufigen Transaktionen überprüft. Dies erfolgt über den Vergleich von Versionsnummern der geänderten Objekte: Stimmt die Versionsnummer des Objektes zum Commit-Zeitpunkt mit der Versionsnummer bei der Duplikaterstellung überein, liegt kein Konflikt vor. Sind die Versionen hingegen verschieden, hat eine nebenläufige Transaktion das Objekt geändert und dabei die Versionsnummer geändert. Die aktuelle Transaktion muss folglich zurückgesetzt werden. Ist hingegen die beschriebene Übereinstimmung der Versionen für alle geänderten Objekte gegeben, so ist die Transaktion valide und ihre Änderungen können im Cache sichtbar gemacht werden.\\
In Verbindung mit der Transaktionsausführung in der physischen Speicherschicht lässt sich der Ablauf beim Commit einer Transaktion in HyperGraphDB anhand der folgenden Schritte zusammenfassen:

\begin{enumerate}
	\item Anfordern einer Commit-Sperre um nebenläufige Commits zu blockieren
	\item Prüfen, ob die Transaktion im Cache valide ist
	\item Ausführung des Commit in der physischen Speicherschicht (BerkeleyDB)
	\item Schreiben der Änderungen im Cache
	\item Freigabe der Commit-Sperre
\end{enumerate}

Ist die Transaktion bereits im Cache nicht valide oder führt das Commit in der physischen Speicherschicht zum Abbruch der Transaktion, werden die Änderungen im Cache verworfen und die Transaktion ist zurückgesetzt.\footnote{Die Erläuterung der Transaktionsverwaltung innerhalb des Caches ist nicht Teil der offiziellen Dokumentation, sondern basiert auf der Recherche innerhalb des Quelltextes von HyperGraphDB. Die dabei dokumentierten internen Abläufe wurden im Austausch mit dem Entwickler bestätigt: \url{https://groups.google.com/forum/?hl=de\#!topic/hypergraphdb/fmjdVtDxf-g.}} Für die Verwaltung der Duplikate nutzt HyperGraphDB Versioned Boxes\cite{Cachopo:2006:VBB:1228561.1228566}, das Vermitteln der Funktionsweise überschreitet jedoch den Rahmen der vorliegenden Evaluation und ist für das Verständnis der Transaktions- und Cacheverwaltung nicht erforderlich.

\subsection{Verteilung und Skalierbarkeit}

Die Verteilung der Datenbasis erfolgt in HyperGraphDB unter Verwendung eines integrierten Peer-to-Peer-Frameworks, welches verschiedene Mechanismen zur Kommunikation zwischen verteilten Datenbankinstanzen bereitstellt. Eine Peer-to-Peer-Kommunikation zeichnet sich im Gegensatz zur Client-Server-Kommunikation dadurch aus, dass alle Teilnehmer gleichberechtigt sind und innerhalb des Netzes keine zentrale Instanz existiert\cite{Tanenbaum:2002:CN:572404}. Für die Kommunikation zwischen den Peers setzt HyperGraphDB die standardisierte Agent Communication Language\footnote{\url{http://www.fipa.org/repository/aclspecs.html}} ein, die Übertragung erfolgt in Form von Nachrichten auf Grundlage des XMPP-Protokolls\footnote{\url{http://xmpp.org/xmpp-protocols/rfcs/}}. Die Kommunikation selbst ist  asynchron, was bedeutet, dass Nachrichten von Peers empfangen, in einem Pool gesammelt und anschließend in beliebiger Reihenfolge verarbeitet werden.

Intention von HyperGraphDB ist das Definieren einer Datenverteilung innerhalb der Anwendung, da diese unter Berücksichtigung von Domänenwissen besser entscheiden kann, wie die Daten zu partitionieren bzw. zu replizieren sind. Das Framework ist somit ausschließlich als Mittel zur Umsetzung konkreter Verteilungsalgorithmen gedacht. Auf eine detaillierte Beschreibung des Frameworks wird an dieser Stelle verzichtet, da dies nicht dem Schwerpunkt der Evaluation entspricht. Sollte HyperGraphDB für das Forschungsprojekt eingesetzt und dabei eine Verteilung realisiert werden, so findet sich eine ausführliche Beschreibung des Frameworks in der offiziellen Dokumentation.

In \cite{Iordanov:2010:HGG:1927585.1927589} wird ein sehr abstraktes Beispiel für die Umsetzung einer Replikation in HyperGraphDB vorgestellt. Auf dieser Grundlage wird nachfolgend - stark vereinfacht -  die mögliche Realisierung einer fragmentierten Replikation beschrieben: Ein Peer kann durch die Definition von Prädikaten die für ihn interessanten Atome festlegen. Zum Beispiel kann durch die Verwendung von Typ-Prädikaten bestimmt werden, welcher Peer die Instanzen eines Typs speichert. Folglich lässt sich durch Partitionierung des Schemas festlegen, welche Atome zusammen gespeichert sind. Die Anzahl der Peers, die das gleiche Typ-Prädikat besitzen, entspricht der Anzahl der Replikate der jeweiligen Instanzen. Die Prädikate aller Peers sind jedem Teilnehmer innerhalb des Netzwerkes bekannt. Sobald ein Atom ein definiertes Prädikat erfüllt, werden alle daran interessierten Peers benachrichtigt. Die Prüfung erfolgt event-basiert beim Erzeugen, Löschen oder Aktualisieren eines Atoms innerhalb einer Transaktion. Die Nachricht selbst beinhaltet die zugehörige Transaktion. Trifft die Nachricht beim Interessent ein, bestätigt er diese und entscheidet selbst, ob er die Transaktion ausführt oder verwirft. Die Konsistenz muss dabei durch Festlegen einer Ausführungsreihenfolge sichergestellt werden, dies erfolgt durch die Vergabe einer Versionsnummer. In \cite{Iordanov:2010:HGG:1927585.1927589} wird nicht definiert, wie diese innerhalb des Netzwerkes erzeugt wird, das Framework stellt jedoch sicher, dass letztendlich alle Peers eine konsistente Sicht auf die Daten aufweisen.\\
Durch eine anwendungsseitige Aufteilung des Schemas und die mehrfache Definition identischer Prädikate lässt sich somit eine fragmentierte Replikation umsetzen.

\section{OrientDB}

Blubb

\subsection{Datenmodell}

Blubb

\subsection{Zugriffsmechanismen}

Blubb

\subsection{Persistenz}

Blubb

\subsection{Verteilung}

Blubb

\section{Titan}

Blubb

\subsection{Datenmodell}

Blubb

\subsection{Zugriffsmechanismen}

Blubb

\subsection{Persistenz}

Blubb

\subsection{Verteilung}

Blubb


\section{Gegenüberstellung}

\subsection{Unterstützung graphenspezifischer Operationen}

\paragraph*{Neo4j}

Kritik:

- Weg der Länge $k$ führt zu $\mathcal{O}(\left|N(v_1)\right| \times \left|N(v_2)\right| \times \cdots \times \left|N(v_k)\right|)$
- Fragmentierung der Stores
- Verteilung: was passiert bei Partitionierung des Netzwerkes

allShortestPaths -> grundlage für centrality maße

- CRUD
	- in Java API möglich

- Traversierung
	- algorithmische Traversierung mittels Traversal Framework

- Erreichbarkeit
	- selber implementieren oder Dijkstra

- Mustersuche
	- nicht möglich

- Aggregation und Summierung
	- nicht möglich
	
\paragraph*{HyperGraphDB}

- CRUD
	- in nativer API und Cypher möglich

- Traversierung
	- algorithmische Traversierung mittels Traversal Framework

- Erreichbarkeit
	- native API stellt Algorithmen zur Verfügung
	- Cypher bietet shortestPath allShortestPath-Funktionen an

- Mustersuche
	- Cypher ermöglicht die Definition beliebiger Mustergraphen

- Aggregation und Summierung
	- Aggregation von Werten ist möglich
	- Summierung von topologischen Strukturen ist nicht möglich
	
\subsection{Speicherung}

\paragraph*{HyperGraphDB}

- logarithmische Komplexität beim Zugriff auf die B-Bäume
	- indexfreie Adjazenz: Caches sind Hashtabellen, können aber nicht immer die komplette Datenbasis aufnehmen
- Verhungern langer Transaktionen (First-Come-First-Serve Prinzip)

