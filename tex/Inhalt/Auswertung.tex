\chapter{Zusammenfassung, Fazit und Ausblick}

% Blick in Bachelorarbeit

% Zusammenfassung
- Ziel war es ...

% Theoretische Grundlagen
- Nach der Diskussion verwandter Arbeiten in Kapitel x wurden zunächst die für die Arbeit relevanten graphentheoretischen Begriffe definiert.
- graphentheoretische Grundlagen (Definitionen)
- Anwendungszenarien / Arten von Netzwerken -> Schwerpunkt auf Informations- und Wissensnetzwerke
- Die Betrachtung verschiedener Netzwerkarten hat verdeutlicht, dass es graphenbasierte Softwaresysteme mit verschiedenen Schwerpunkten geben muss ...

- Top Down Prinzip!: graphenbasierte Softwaresysteme -> Graphdatenbanksystemen -> Vorauswahl -> funktionaler Vergleich -> Auswahl -> Benchmark

- Kategorisierung: Graphdatenbanksysteme, Graph Processing Systems, Analyse- und Visualisierungssoftware
	- weiter auf GDBMS eingegangen -> Definition und weitere Unterteilung
		- Def: OLTP-artig (Mehrbenutzerfähigkeit, transaktionale Performance, Integrität, Verfügbarkeit)
			- nativ / nicht-nativ
			- zentral / verteilt
			- eingebettet / Client-Server
			- disk- / hauptspeicherzentriert
			
- Datenmodelle (betrachtet: PGM, PHGM, RDF)
	- PGM: gerichteter, kantenbezeichneter, attributierter Multigraph
		- flexibel -> für viele Anwendungsfälle einsetzbar
		- Verantwortung bzgl. Schemaverwaltung an Anwendung übergeben
		- semistrukturierte Daten (Schemaevolution) -> Integration heterogener Datenquellen
	- PHGM: Erweiterung um n-äre Beziehungen .. seltenes, sehr spezielles Datenmodell
	- RDF in Verbindung mit SPARQL:
		- Schwerpunkte Inferenz und virtuelles Integrieren entsprechen nicht den Schwerpunkten des Forschungsvorhabens
		- fehlende modellinhärente Differenzierung in eine Beziehung zwischen Ressourcen und einer Beschreibung einzelner Ressourcen zwischen Attribut und Beziehung erschwert das Formulieren analytischer Anfragen
		- keine dynamischen Pfadinstanzen
	-> PGM und (P)HGM für das Forschungsvorhaben geeignet
	
- Operationen:
	- grundlegend: 
		- CRUD zur Definition, Manipulation und Auslesen der Datenbasis
		- Traversierung: Beschreiben abstrakter Wege, Grundlage für komplexere Operationen
	- komplexe Operationen:
		- Erreichbarkeit: Pfade beliebiger und fester Länge, kürzeste Pfade
		- Mustersuche: exakt / inexakt (Unterscheidung in Isomorphismus und Subgraphisomorphismus / Subgraphhomomorphismus)
		- Aggregation als nutzdatenbasiertes Zusammenfassen: insbesondere für die analytische Anwendung interessant
		- Summierung als topologisches Zusammenfassen
		- Metriken (zur Analyse des gesamten Graphen) werden in den verglichenen Systmen nicht direkt unterstützt und müssen bei Bedarf hinzugefügt werden
		
% Funktionaler Vergleich

- Beschreibung des Forschungsvorhabens:
	- Integration von Unternehmensdaten aus verschiedenen Geschäftsinformationssystemen in Graph
	- anschließende Extraktion und Analyse von Teilgraphen
	- Projektziele:
		- (1) Integration
		- (2) Analyse
		- (3) Nutzbarkeit für Analysten
		-> (1) und (2) wichtig bei der Betrachtung von GDBMS
		
- Vorauswahl
	- grundlegende Anforderungen nach Kategorien geordnet
	- aus 22 Systemen wurden vier für die detaillierte Analyse ausgewählt
	- Auffälligkeiten:
		- wenig hauptspeicher-zentrierte GDBMS
		- Partitionierung des Graphen nur selten unterstützt
		- anwendungsseitige Schemaverwaltung

- funktionaler Vergleich
	- Neo4j, HyperGraphDB, OrientDB, Titan
	- der Vergleich hat ergeben, dass ich insbeondere Neo4j und Titan für den Einsatz im Forschungsvorhaben eigenen und wurden daher im nachfolgenden Benchmark evaluiert
	
% Benchmark
- hat ergeben, dass
- bei der Verwendung der Datensätze \texttt{p\_100} und \texttt{p\_1K} konnte kein auffällig schlechteres Leistungsverhalten des nicht-nativen GBDMS Titan festgestellt werden

% Fazit

Die vier Systemen wurden bereits am Ende von Kapitel \ref{cha:evaluation} verglichen,... Neo4j und Titan wurden auf Grundlage dieses Vergleichs für den Benchmark ausgewählt und werden im anschließenden Fazit bewertet

\paragraph*{Fazit}

- Neo4j
-------
	(1) Integration:
		- PGM, kein Schema, Speicherung semistrukturierter Daten, keine Beeinflussung bestehender Daten
		- Erweiterungen: 
			- Knotenbezeichner -> Schritt in Richtung Entkopplung von der Anwendung + Möglichkeiten zur Anfrageoptimierung

	(2) Analyse:
		- größter Funktionsumfang für die Verarbeitung des hinterlegten Graphen
		- Core API, Traversal Framework, Cypher und Gremlin
		- CRUD, Traversierung, Erreichbarkeit, Mustersuche, Aggregation	
		- eigene Algorithmen inkl. Filterkriterien -> z.B. shortestPath sehr gute Performance auch bei steigendem Datenvolumen (verwendbar in Core API und Cypher)
		- Cypher: 
			- steile Lernkurve
			- deutlicher Leistungsunterschied im Vergleich zu Gremlin innerhalb von Neo4j
			- Definition von Graphen innerhalb der Anfrage sehr intuitiv
			- für Nicht-Programmierer geeignet
			- Aggregation, Gruppierung, Projektion (+ Funktionen)
			- ermöglicht systemseitige Anfrageoptimierung
			- eventuell Grundlage für die Definition einer standardisierten Anfragesprache für GDBMS
	
	(3) Speichersystem / Cacheverwaltung
		- einziges natives System (Store-Konzept ermöglicht Trennung von Topologie und Nutzdaten)
		- indexfreie Adjazenz auch physisch umsetzbar
		- im Vergleich erzielte Neo4j in allen Datensätzen die niedrigsten Antwortzeiten
		- sehr gute Caching- und Persistenzarchitektur
		- skaliert linear bei topologischen Anfragen
		- Probleme beim Prüfen der Erreichbarkeit, Limitierung durch Hardware

	(4) Erweiterbarkeit:
		- Quelloffenheit ermöglicht generell das Erweitern der GDBMS
		- Implementierung eigener Algorithmen mittels Core API
		- Hinzufügen von Indexstrukturen
		
	(5) Verteilung / Skalierbarkeit
		- Replikation ermöglicht Skalierbarkeit von Lesezugriffen (vorteilhaft für analytische Anwendung)
		- keine Partitionierung: Datenmenge momentan durch Hardwareressourcen einzelner Rechner limitiert
	
	- objektive Faktoren
		- PGM-Erweiterung um Knotenlabel ist sinnvoll für Anfrageoptimierung und Anwendungsmodellierung
		- Cypher leistungsfähige, deklarative Anfragesprachen für die Analyse von Graphen
			- einfaches, intuitives Formulieren graphenbasierter Anfragen
			- Einbettung von Cypher im Quellcode -> hoher Wartungsaufwand (Holzschuher)
			- bei Performance-Problemen (Erreichbarkeit) -> Nutzung der nativen API
		- wenn Gremlin Neo4j 2.0 unterstützt, stellt dies ebenfalls eine positive Erweiterung dar (community-driven)
		- eigene Algorithmen / Operationen können mittels Core API hinzugefügt werden		-
		- graphenorientiertes Speichersystem und effiziente Caching-Mechanismen
		- bei Bedarf stehen mit Neo4j HA Verteilungsmechanismen zur Verfügung	
	- subjektive Faktoren
		- umfangreiche, detaillierte, aktuelle Dokumentation
		- große Nutzer- und Entwickler-Community -> viele Projekte, Rückwirkungen in das Projekt, sehr aktiv
		- offene, erweiterbare Architektur
		- lange Entwicklungsdauer -> fortgeschrittenes Projekt, aktive Community (Unterstützung)		
	
- Titan
-------
	(1) Datenmodell:
		- PGM, kein Schema, Speicherung semistrukturierter Daten, keine Beeinflussung bestehender Daten
		- Erweiterungen: 
			- typisierte Attributschlüssel und Kantenbezeichner (Integritätsbedingungen, Festlegung von Datentypen -> effizientere Speicherung + bessere Performance -> konnte im Benchmark nicht festgestellt werden)
			- knoten-zentrierte Indizes (Vorteil in umfangreichen Informationsnetzwerken mit eine Vielzahl von Beziehungsarten und Kantenattributen)
			- mehrfache Verwendung von Attributschlüsseln
	
	(2) Analyse:
		- Blueprints API, Gremlin
		- Gremlin
			- eignet sich sehr gut für das Formulieren abstrakter Wege
			- Mustersuche ist möglich, die Anfrage ist je nach Art des Musters deutlich komplexer als eine äquivalente Cypher-Anfrage
			- (noch) bessere Performance als Cypher
			- Implementierung beliebiger Seiteneffekte durch Java bzw. Groovy
			- imperativ: Performance ist stark von Anfrageformulierung abhängig
			
	(3) Speicherung
		- Entkopplung von Datenbankschicht und Speichersystem ist ein innovativer Ansatz und ermöglicht die Implementierung eigener, spezialisierter Speichersysteme bzw. die Bindung an solche
		- keine Trennung von Topologie und Nutzdaten, jedoch direkter Attributzugriff möglich -> Benchmark hat gezeigt, dass der direkte Zugriff auf Attribute dennoch sehr effizient erfolgt und kurze Antwortzeiten erreicht werden
		- physische indexfreie Adjazenz vom Speichersystem abhängig, BerkeleyDB -> logarithmisch
		- Verwendung von BerkeleyDB als Speichersystem führte bei steigender Datenmenge zu teilweise deutlichen Erhöhung der Antwortzeiten
		- skaliert linear bei topologischen Anfragen
		
	(4) Erweiterbarkeit
		- Implementierung eigener Algorithmen mittels Blueprints API
		
	(5) Verteilung / Skalierbarkeit
		- durch Verwendung von entsprechenden Speichersystemen kann sowohl Replikation als auch Partitionierung realsiert werden
		- Partitionierung in Cassandra per Hashfunktion, keine Erhaltung logischer Adjazenz garantiert
		
	- objektiv
		- gut strukturiert, aktuelle Dokumentation, fehlende Dokumentation der internen Abbildung des Graphen
		- Rückwirkung: die im Zusammenhang mit dem Datenmodell beschrieben Analogie zur Kardinalität in Bezug auf UNIQUE-Bedingungen an Kanten wurde in die offizielle Dokumentation übernommen

- beide
	- Projektziele:
		- (1) Integration -> - Verwaltung semistrukturierter Daten eignet sich im besonderen Maße für die Integration aus verschiedenen Geschäftsinformationssystemen
		- (2) graphenorientierte Analyse -> vielfältige Zugriffsmechanismen, Cypher und Gremlin für analytische Anfragen geeignet
	- analytische Anfragen möglich (Cypher, Gremlin)
	- Gremlin
		- höherer Aufwand bei der Anfrageformulierung
	- standardisierte Anfragesprache fehlt weiterhin
	- Gremlin/Blueprints bildet Quasi-Standard
		- Anpassung der GDBMS-Wrapper ist Community-driven (verzögert)
	- keine Bestrebungen hinsichtlich Standardisierung erkennbar
	- Cypher ist guter Kandidat für Standard
	
	
- Rückwirkung auf Dokumentationen (OrientDB Transaktionen, Titan Kardinalität. Neo4j Anfragebeispiele)

% Ausblick
\paragraph*{Ausblick}

- Neo4j:
	- In-Memory-Erweiterungen für Analyse
	- Query-Optimierung
	- formale Untersuchung und Standardisierung von Cypher im GDBMS-Sektor
	- ausführlicher Benchmark (parallele Queries, reale Unternehmensdaten)
	- Partitionierung
	- Ergebnis der Cypher-Anfragen ist Tabelle und kein Graph bzw. Graphmenge -> Änderungen?
	- Clustering im Speichersystem -> Abbildung einer logischen auf eine physische Adjazenz
	
- OrientDB
	- neues Speichersystem evaluieren
- HyperGraphDB
	- Implementierung Blueprints API
	
- quelloffene hauptspeicher-zentrierte Implementierung
- Eignung Graph Processing für Forschungsvorhaben
- Visualisierung für Analyseplattform

- Benchmark
	- Import: lesen und Schreiben von einer Platte (unrealistisch)
	- parallele Lesezugriffe
	- warmup-Prozedur verhindert Feststellen der Leistungsfähigkeit des Speichersystems
	-> weiterführende Benchmarks
	- Betrachtung ohne Caches sinnvoll?