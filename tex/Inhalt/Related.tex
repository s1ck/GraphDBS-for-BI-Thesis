\chapter{Verwandte Arbeiten}
\label{cha:relatedwork}

Das Forschungsinteresse an graphenbasierten Softwaresystemen im Allgemeinen und GDBMS im Speziellen war bereits zu Beginn der 1990er Jahre hoch, ließ jedoch bedingt durch die wachsende Bedeutung von XML-Datenbanken wieder nach \cite{Angles:2008}. Seit ca. 2008 ist ein erneuter Anstieg an Publikationen zum Thema graphenbasierter Softwaresysteme zu verzeichnen. Die Publikationen lassen sich dabei in drei Kategorien einteilen: Konzeptionelle Vergleiche von GDBMS, Benchmarks von GDBMS untereinander und Benchmarks von relationalen und graphenbasierten Datenbanksystemen. Im Folgenden wird eine Auswahl themenverwandter Publikationen der letzten fünf Jahre diskutiert. Dabei werden jeweils Ansatz und Ergebnisse kurz beschrieben und die Veröffentlichung anschließend kritisch betrachtet.

\section{Konzeptionelle Vergleiche von Graphdatenbanksystemen}

% A Comparison of Current Graph Database Models

Angles und Gutierrez\cite{Angles:2008} stellten bereits 2008 eine umfassende und dabei gleichzeitig detaillierte Übersicht über Datenmodelle für GDBMS vor. Die Autoren beziehen sich dabei auf die Modelle, welche zwischen 1975 und 2002 entstanden. Neben einem Vergleich mit anderen Datenmodellen beinhaltet der Artikel eine funktionale Gegenüberstellung graphenbasierter Datenmodelle. Die Autoren definieren ein Datenmodell auf Basis der verwendeten Datenstrukturen, der Anfragesprachen und der Integritätsbedingungen. Anhand dieser drei Kriterien werden die verschiedenen Modelle miteinander verglichen, diese Betrachtung folgt dabei ausschließlich einem theoretischen Interesse und widmet sich nicht der Bedeutung konkreter Implementierungen.

Einige der für die vorliegende Masterarbeit relevanten Implementierungen wurden 2012 von Angles\cite{Angles:2012} untersucht. Der Vergleich wendet erneut die oben genannten drei Kriterien an und ergänzt diese um die Art der Datenspeicherung. 
%Hierzu zählen AllegroGraph\footnote{\url{http://www.franz.com/agraph/allegrograph/}}, DEX\footnote{\url{http://www.sparsity-technologies.com/dex.php}}, Filament\footnote{\url{http://filament.sourceforge.net/}}, G-Store\footnote{\url{http://g-store.sourceforge.net/}}, HyperGraphDB\footnote{\url{http://www.hypergraphdb.org/index}}, InfiniteGraph\footnote{\url{http://www.objectivity.com/infinitegraph}}, Neo4j\footnote{\url{http://www.neo4j.org/}}, Sones GraphDB\footnote{\url{http://www.sones.de/}} und VertexDB\footnote{\url{https://github.com/stevedekorte/vertexdb}}. 
Zu Beginn stellt der Autor die Systeme bzgl. der Art der Datenspeicherung und der Möglichkeit zur Indexierung der Daten gegenüber. Der Großteil der verglichenen Systeme unterstützt die persistente Speicherung des Graphen und die Definition von Indizes.
Der Autor stellt weiter fest, dass im Vergleich zu den in \cite{Angles:2008} betrachteten Datenmodellen viele Systeme die Speicherung von Attributen direkt an Knoten und Kanten zulassen. 
%Diese als \textit{Attributed Graph} bezeichnete Datenstruktur wird in der vorliegenden Arbeit als \textit{Property-Graph-Datenmodell} vorgestellt (Abschnitt \ref{subsec:propgraph}).
Des Weiteren wird die Unterstützung graphenspezifischer Anfragen mittels Application Programming Interface (API) oder  Anfragesprache untersucht. Neben einfachen Anfragen wie der Selektion von Knoten und Kanten, werden die GDBMS hinsichtlich der Fähigkeit zur Ausführung verschiedener Pfadanfragen, Mustersuchen und Wertaggregation verglichen. Das Fehlen einer standardisierten Anfragesprache wird als ein wesentlicher Nachteil vorhandener Implementierungen ausgewiesen: Nur drei der neun verglichenen Systeme verfügen über eine Anfragesprache, davon sind zwei proprietär. Der Schwerpunkt wird laut Ansicht des Autors auf die Entwicklung von APIs für populäre Programmiersprachen gelegt.
In Bezug auf Integritätsbedingungen wird darauf hingewiesen, dass diese in den untersuchten Systemen nur ansatzweise umgesetzt sind, was ebenfalls als ein entscheidendes Defizit gewertet wird, da die Einhaltung der Konsistenz eine wesentliche Aufgabe eines Datenbanksystems darstellt.

\textbf{Diskussion} Der Artikel legt den Schwerpunkt auf einen funktionalen Vergleich. Implementierungsdetails, wie zum Beispiel die physische Repräsentation der Graphen, werden nicht betrachtet, diese sind jedoch für die vorliegende Arbeit von Interesse. Eine quantitative Analyse im Rahmen eines Benchmarks wird ebenfalls nicht vorgenommen. Der Autor verweist diesbezüglich auf zukünftige Arbeiten, zum aktuellen Zeitpunkt sind jedoch keine weiterführenden Veröffentlichungen verfügbar.
%Seit Erscheinen des Artikels wurden die untersuchten GDBMS teilweise weiterentwickelt. So werden die Anfragesprachen Cypher und Gremlin, welche in Neo4j verfügbar sind, nicht berücksichtigt. 
%Darüber hinaus werden weitere GDBMS, wie zum Beispiel ArangoDB\footnote{\url{http://www.arangodb.org/}}, Fallen-8\footnote{\url{http://www.fallen-8.com/}}, GraphBase\footnote{\url{http://graphbase.net/}} oder Titan\footnote{\url{http://thinkaurelius.github.io/titan/}} nicht betrachtet. 
In Abschnitt \ref{sec:anforderungen} werden verschiedene Anforderungen im Rahmen aktueller Forschungsvorhaben formuliert. Diese Anforderungen werden in \cite{Angles:2012} nur teilweise berücksichtigt. Ungeachtet dessen stellt der Artikel einen guten Ausgangspunkt für weitere, detailliertere Betrachtungen von Graphdatenbanksystemen dar.

% The Current State of Graph Databases

Buerli\cite{Buerli:2012} gab 2012 ebenfalls einen Überblick über Vertreter von Graphdatenbanksystemen, legte den Schwerpunkt jedoch auf Einsatzmöglichkeiten von GDBMS und kategorisiert die Systeme auf Grundlage des jeweiligen Datenmodells. Hervorzuheben ist, dass ebenfalls der Bereich der Geschäftsdaten als wichtiges Anwendungsgebiet beschrieben wird. Beispiele hierfür sind die Speicherung und Analyse von Produkthierarchien und Finanzdaten.
% Der Autor führt anschließend eine Kategorisierung verschiedener Vertreter durch. Die erste Kategorie umfasst native GDBMS wie AllegroGraph, DEX, Neo4j, HyperGraphDB und Sones GraphDB. Als eine zweite Kategorie werden verteilte GDBMS geführt zu denen stellvertretend Microsoft Horton\footnote{\url{http://research.microsoft.com/en-us/projects/ldg/}} und InfiniteGraph beschrieben werden. Die dritte Kategorie umfasst GDBMS, welche auf bestehenden Speicherlösungen aufsetzen oder diese erweitern. In Verbindung mit Key-Value-Stores, deren einfaches Datenmodell sich für eine horizontale Skalierbarkeit durch Partitionierung eignet, werden VertexDB\footnote{\url{http://www.dekorte.com/projects/opensource/vertexdb/}}, CloudGraph\footnote{\url{http://www.cloudgraph.com/}}, Redis Graph\footnote{\url{https://github.com/tblobaum/redis-graph}} sowie Microsoft Trinity\footnote{\url{http://research.microsoft.com/en-us/projects/trinity/}} kurz vorgestellt. OrientDB\footnote{\url{http://www.orientdb.org/}} ist eine Softwarelösung, welche als Document-GDBMS bezeichnet wird und durch die Vereinigung der Konzepte Document-Store und GDBMS die mögliche Komplexität der hinterlegten Informationen weiter erhöht. Als Erweiterungen relationaler Datenbanksysteme werden Filament und G-Store kurz beschrieben. Die vierte und letzte Kategorie stellen diejenigen GDBMS dar, welche MapReduce zur parallelen Verarbeitung umfangreicher Daten nutzen. Als Vertreter dieser Kategorie werden Google Pregel\cite{Malewicz:2010:PSL:1807167.1807184}, Phoebus\footnote{\url{https://github.com/xslogic/phoebus}} und Apache Giraph\footnote{\url{http://giraph.apache.org/}} genannt.
Bestehende Systeme werden in vier Kategorien eingeteilt: (1) native und (2) verteilte GDBMS, (3) GDBMS als Erweiterung bestehender Datenbanksysteme sowie (4) GDBMS auf Basis von MapReduce. Der Autor schließt mit einem kurzen Vergleich zwischen relationalen und Graphdatenbanksystemen, in dem u.a. die Ergebnisse aus  \cite{Vicknair:2010:CGD:1900008.1900067} zitiert werden. Es wird analog zu \cite{Angles:2012} auf fehlende Standardisierung als entscheidendes Defizit hingewiesen. Dies bezieht sich sowohl auf eine einheitliche Beschreibung der verschiedenen Datenmodelle, als auch auf eine standardisierte Anfragesprache.

\textbf{Diskussion} Der Artikel stellt eine Auflistung und kurze Beschreibung vorhandener Implementierungen dar und bietet somit einen guten Einstieg in das Thema. Der Autor erweitert die Menge der in \cite{Angles:2012} betrachteten Systeme, berücksichtigt jedoch ebenfalls nicht alle  relevanten GDBMS. Ein Vergleich erfolgt weder auf funktionaler Ebene noch auf der Grundlage eigener Leistungsmessungen. Bei genauerer Betrachtung der einzelnen Systeme zeigt sich außerdem, dass die Abgrenzung der Kategorien unscharf ist, so werden zum Beispiel Phoebus, Google Pregel und Apache Giraph als Datenbanksysteme deklariert. Wie in Abschnitt \ref{subsec:graph_processing} gezeigt werden wird, handelt es sich bei den genannten Systemen um \textit{Graph Processing Systems}, bei denen der Fokus auf der verteilten Analyse umfangreicher Graphen liegt. Sie weisen nicht die wesentlichen Eigenschaften von Datenbanksystemen, wie z.B. Datenintegrität, Fehlerbehandlung und Mehrbenutzerfähigkeit, auf. Darüber hinaus werden in der Kategorisierung hauptspeicherzentrierte GDBMS und Programme zur Visualisierung und Analyse einfacher Graphen nicht berücksichtigt.

% Managing and Mining Large Graphs: Systems and Implementations

Entwickler von Microsoft Trinity diskutierten 2012 in \cite{Shao:2012:MML:2213836.2213907} die Ursachen für die Ausprägung verschiedener graphenbasierter Softwaresysteme. Die Kernaussage ist, dass kein System existieren kann, in dem alle Graphalgorithmen optimal hinsichtlich ihrer Laufzeit implementiert werden können. Die Ursache hierfür liegt im wahlfreien Zugriff auf die Informationen innerhalb des Graphen. Verschiedene Algorithmen erfordern unterschiedliche physische Repräsentationen des Graphen um die jeweils optimale Laufzeit zu erreichen. Der Aufwand, den Graph zu konvertieren, steigt dabei mit seiner Größe. Aus dieser Tatsache leiten die Autoren die Entwicklung spezialisierter graphenbasierter Softwaresysteme ab und klassifizieren diese je nach Anwendungsfall in \textit{online query processing} und \textit{offline graph analytics} Systeme. %Neo4j wird beispielsweise als OLTP-GDBMS deklariert, da es auf kurze Antwortzeiten optimiert und die Größe des Graphen auf einen physischen Rechner beschränkt ist. Eine Partitionierung des Graphen wird von diesem System nicht unterstützt. Demgegenüber wird Google Pregel exemplarisch als rein analytisches System klassifiziert, da es für hohen Durchsatz und die parallele Verarbeitung umfangreicher Graphen, wie z.B. dem Web-Graph optimiert ist. 
Die Autoren zeigen weiter, dass Anwendungen existieren, an welche sowohl operationale als auch analytische Anforderungen gestellt werden. Um in solchen Szenarien den wahlfreien Zugriff in umfangreichen Graphen möglichst effizient durchzuführen, werden hauptspeicher-zentrierte Systeme wie Microsoft Trinity vorgeschlagen.

\textbf{Diskussion} Der Artikel beinhaltet eine interessante Diskussion über die Folgen des wahlfreien Zugriffs innerhalb von Graphen und der sich daraus ergebenden möglichen Klassifizierung graphenbasierter Softwaresysteme. In Abschnitt \ref{sec:graphsystems_classification} werden die Systeme ebenfalls klassifiziert, wobei analog die Unterscheidung zwischen operativen und analytischen Systemen erfolgt, operative Systeme jedoch noch weiter unterteilt werden. Der Einfluss der physischen Repräsentation des Graphen auf die Laufzeit der verwendeten Graphalgorithmen stützt die Entscheidung, die Implementierung der Persistenz in den zu vergleichenden Systemen genauer zu untersuchen (Abschnitt \ref{cha:evaluation}).

\section{Benchmarks in relationalen und Graphdatenbanksystemen}

% A Comparison of a Graph Database and a Relational Database - A Data Provenance Perspective

In \cite{Vicknair:2010:CGD:1900008.1900067} wurde 2010 das relationale Datenbanksystem MySQL mit dem GDBMS Neo4j verglichen. Der Vergleich erfolgt sowohl empirisch in Form eines Benchmarks, als auch auf Basis selbstdefinierter Systemeigenschaften. Der Benchmark stellt ein Szenario nach, in welchem Informationen zum Entstehungsprozess von Daten gespeichert und abgefragt werden. Solche Herkunftsinformationen\footnote{Hierzu zählen Informationen über alle Prozesse, die an der Entstehung des Datums mitgewirkt haben, sowie allen Eingabedaten und deren jeweilige Herkunftsinformationen. Ein Beispiel ist die Produktion komplexer, zusammengesetzter Produkte. Fehler in Teilen eines Produktes können durch die zusätzlichen Informationen schneller innerhalb der Produktionskette propagiert werden.} lassen sich als gerichteter, azyklischer Graph modellieren. Die Autoren erzeugen diese Graphen zufallsgesteuert, Knoten werden mit zusätzlichen Nutzdaten versehen. Die Skalierbarkeit der Systeme wird durch verschiedene Größen der Graphen getestet, wobei der größte Graph 100 Tsd. Knoten umfasst. Anfragen werden sowohl struktur-, als auch datenbezogen ausgeführt. Die strukturellen Anfragen berechnen die transitive Hülle\footnote{Def. transitive Hülle} ausgehend von zufällig ausgewählten Knoten und unterschiedlichen Abständen. Die Ergebnisse zeigen eine um bis zu Faktor 10 kürzere Ausführungszeit für Neo4j. Bei den datenbezogenen Anfragen wird in numerische und alphanumerische Nutzdaten unterschieden. Neo4j verwendet den Apache Lucene Volltext-Index, was sich bei numerischen Nutzdaten als Nachteil, bei alphanumerischen Nutzdaten jedoch als Vorteil gegenüber MySQL herausstellt.\\
Neben dem empirischen Vergleich stellen die Autoren die beiden Systeme bezüglich der Eigenschaften Anwendersupport/Reifegrad, Zugang/Einfachheit, Flexibilität und Sicherheit gegenüber. Aufgrund der weitaus längeren Entwicklungsdauer und größeren Verbreitung relationaler Datenbanksysteme wird diesen ein höherer Reifegrad und folglich ein besserer Anwendersupport zugesprochen. Der Support von Neo4j beschränkt sich nach Aussage der Autoren auf die Webpräsenz des Unternehmens und eine kleine Community. Das Fehlen einer einheitlichen Anfragesprache wird auch hier als Defizit von GDBMS aufgezeigt. Dies wird insbesondere beim Vergleich des Zugangs zu den Systemen deutlich: Neo4j und auch andere GDBMS bieten entweder nur systemspezifische APIs oder proprietäre Anfragesprachen an, während SQL eine standardisierte Anfragesprache für das relationale Datenmodell darstellt. Als ein wesentlicher Vorteil von Neo4j wird dessen Flexibilität hinsichtlich der Schemaevolution genannt. Durch den Verzicht auf eine Schemadefinition können Änderungen am Schema ohne Beeinflussung bestehender Instanzdaten durchgeführt werden. In Bezug auf Sicherheit geht Neo4j von einer vertrauten Umgebung aus und verzichtet im Gegensatz zu MySQL auf eine datenbankseitige Nutzerverwaltung und die Möglichkeit, Restriktionen in Form von z.B. Access Control Lists (ACL) zu definieren.

\textbf{Diskussion} Der durchgeführte Benchmark ist detailliert und nachvollziehbar beschrieben. Die Ergebnisse werden plausibel diskutiert und erfüllen unter Betrachtung des Szenarios die Erwartungen. Ein Punkt, auf den nicht hingewiesen wird, ist die fehlende Unterstützung rekursiver Anfragen in MySQL. Die Berechnung der transitiven Hülle erfolgt innerhalb der Anwendung mit Hilfe einer Breitensuche. Auf Verbundoperationen wird dabei bewusst verzichtet. Interessant ist, dass MySQL dennoch schlechtere Ergebnisse erzielt, obwohl ausschließlich Selektionen auf einer Relation ausgeführt werden. Eine mögliche Ursache hierfür ist die Formulierung der Anfragen in Neo4j unter Verwendung der nativen API: Die Verarbeitung einer Anfragesprache und die Kommunikation mit einem Datenbankserver für jede Selektion entfallen und wirken sich im Gegensatz zu MySQL nicht auf die Antwortzeit aus. Es werden darüber hinaus keine komplexeren Anfragen zur systematischen Analyse der Netzwerke untersucht. Der Beitrag erschien 2010, Neo4j bezeichnete sich aktuell als \textit{The World's Leading Graph Database}\cite{Neo4j_web:2013}. Interessant ist, wie sich Neo4j in Bezug auf die subjektiven Faktoren, aber auch in Bezug auf Anfragesprachen und Performance weiterentwickelt hat.

% Comparative Analysis of Relational And Graph Databases

%Die Autoren von \cite{Batra:2012} vergleichen ebenfalls das relationale Datenbanksystem MySQL mit dem GDBMS Neo4j. Auch hier werden die Systeme zunächst hinsichtlich der Kriterien Anwendersupport/Reifegrad, Sicherheit und Flexibilität gegenübergestellt. Die Ergebnisse sind analog zu \cite{Vicknair:2010:CGD:1900008.1900067}. Im zweiten Teil des Artikels werden die Systeme im Rahmen eines Benchmarks verglichen. Es werden Anfragen gestellt, die eine Berechnung der transitiven Hülle mit konstantem Abstand von einem Startknoten erfordern. Die Anfragen werden in SQL und Cypher formuliert. Durch die Notwendigkeit der Verkettung mehrerer Join-Operation resultieren die Anfragen in MySQL in höheren Antwortzeiten. Die Differenz zwischen den Antwortzeiten der Systeme steigt mit der Anzahl verketteter Join-Operationen.\\
%Der Vergleich von Datenbanksystemen im Rahmen eines Benchmarks muss nachvollziehbar sein. Die Autoren beschreiben zwar das zugrundeliegende Schema, verzichten aber auf eine genauere Beschreibung der Daten. Interessant wäre das Verhältnis zwischen Knoten- und Kantenanzahl, sowie die Verteilung der Knoten auf die einzelnen Klassen innerhalb des Schemas. Darüber hinaus werden keine Angaben zur Methodik des Benchmarks gemacht. Es ist nicht ersichtlich, ob die Caches befüllt oder ob Indizes im relationalen Datenbanksystem angelegt wurden. Als mögliche Einsatzszenarien für GDBMS werden von den Autoren Linkstrukturen zwischen Webseiten und soziale Netzwerke beschrieben. Die maximal verwendete Datenmenge von 500 Objekten spiegelt diese Szenarien jedoch nicht wider.

% Performance of Graph Query Languages

Holzschuher und Peinl\cite{Holzschuher:2013:PGQ:2457317.2457351} widmeten sich 2013 ebenfalls der Gegenüberstellung von Neo4j und MySQL. Die Autoren wählen ein soziales Netzwerk als Anwendungsfall. Der Benchmark basiert auf der Implementierung von relationalen bzw. graphenorientierten Persistenz-Backends für Apache Shinding\footnote{\url{http://shinding.apache.org}}, einem Framework zur Erstellung von Webanwendungen für soziale Netzwerke. Apache Shinding nutzt die Java Persistence API (JPA) in Kombination mit Hibernate für die Anbindung eines relationalen DBMS. Neben dem generellen Vergleich von relationaler und graphenorientierter Persistenz wendet sich der Beitrag dem detaillierten Vergleich der verschiedenen Anfragemöglichkeiten in Neo4j zu. Es werden die native Java-API, die deklarative Anfragesprache Cypher und die funktionale Anfragesprache Gremlin verglichen. Dabei wird zwischen eingebetteter und entfernter Nutzung der Datenbank unterschieden. Die Testanfragen sind vergleichbar zu \cite{Vicknair:2010:CGD:1900008.1900067} daten- und strukturbezogen. Beispiele sind das Abrufen aller Nutzerdaten einer einzelnen Person und das Abfragen der Freunde eines Nutzers bzw. der Freunde der Freunde eines Nutzers (Friend-of-a-Friend, FOAF). Die generierten Datensätze basieren auf den topologischen Eigenschaften realer sozialer Netzwerke und enthalten zwischen 2 Tsd. und 10 Tsd. Personen mit 25 Tsd. bzw. 137 Tsd. Beziehungen. 
Die Ergebnisse zeigen, dass der entfernte Zugriff via JPA, Cypher und Gremlin für datenbezogene Anfragen annähernd identische Antwortzeiten erzielt. Bei strukturbezogenen Anfragen ist JPA (MySQL) langsamer als Cypher und Gremlin. Die Differenz vergrößert sich dabei mit zunehmender Tiefe der FOAF-Anfragen. Die eingebettete Verwendung der Anfragetechniken ist erwartungsgemäß schneller, die native Java-API erzielt die besten Ergebnisse. Die eingebettete Verwendung von Cypher ist um ca. eine Größenordnung langsamer als die entfernte Verwendung. Generell zeigt sich, dass strukturbezogene Anfragen in MySQL bei steigender Datenmenge schlechter skalieren als in Neo4j.
%Es wird zunächst der entfernte Zugriff verglichen. Hierbei zeigt sich, dass die Zugriffszeiten via JPA, Cypher und Gremlin für datenbezogene Anfragen annähernd identisch sind. Bei der Abfrage der Freunde einer Person  sind die Antwortzeiten von JPA bereits um eine Größenordnung langsamer als von Cypher, welche wiederum eine Größenordnung langsamer sind als die mit Gremlin formulierten Anfragen. Bei steigender Datenmenge zeigt sich, dass die Antwortzeiten von MySQL wesentlich schlechter skalieren als die von Neo4j. Die native-Java API, Cypher und Gremlin werden außerdem hinsichtlich entfernter FOAF-Anfragen gegenübergestellt. Hierbei zeigt sich, dass Gremlin die niedrigsten Antwortzeiten erreicht. Die entfernte, native Java-API wird auf Grund von Softwarefehlern nicht betrachtet. Die eingebettete Verwendung der Anfragemöglichkeiten wird ebenfalls verglichen. Durch den Verzicht auf zusätzliche Netzwerkkommunikation sind die Antwortzeiten generell besser, die native Java-API erzielt die besten Ergebnisse. Interessant ist, dass Cypher bei einem Großteil der Anfragen trotz zusätzlicher Anfrageverarbeitung nur geringfügig höhere Antwortzeiten erreicht. Die eingebettete Verwendung von Cypher ist um etwa eine Größenordnung schneller als die entfernte Verwendung derselbigen, wobei die Anfragen nicht identisch sind sondern im Fall der entfernten Verwendung mehrere Anfragen gebündelt werden um den durch Kommunikation entstehenden Mehraufwand zu minimieren. 
Neben dem objektiven Benchmark werden die verschiedenen Anfragemöglichkeiten subjektiv hinsichtlich Lernaufwand, Lesbarkeit im Programmcode und Wartbarkeit verglichen. Deklarative Anfragesprachen wie SQL oder Cypher haben insbesondere in den Punkten Lernaufwand und Lesbarkeit Vorteile gegenüber imperativen Sprachen. Ihre Einbettung im Programmcode birgt jedoch einen höheren Wartungsaufwand. Gremlin eignet sich insbesondere für die Formulierung von Traversierungen innerhalb des Graphen, komplexere Funktionen wie Aggregation und Sortierung sind nach Ansicht der Autoren weniger intuitiv zu formulieren.

\textbf{Diskussion} Der Beitrag stellt einen detaillierten Bericht über die verschiedenen Anfragemöglichkeiten von Neo4j dar. Interessant ist die Diskussion einer möglichen Eignung von Cypher als standardisierte Anfragesprache für GDBMS. Der Benchmark basiert auf Neo4j 1.8, die inzwischen veröffentlichte Version 1.9 enthält laut Release Notes\cite{Neo4j_web_release_notes:2013} weitere Performance-Optimierungen und die sich aktuell in Entwicklung befindliche Version 2.0 widmet sich hauptsächlich der Optimierung von Cypher\cite{Neo4j_web_v2:2013}. Die Methodik des Benchmarks wird exakt beschrieben und kann als Grundlage für weiterführende objektive Untersuchungen genutzt werden. Sollte Neo4j den in Abschnitt \ref{sec:anforderungen} gestellten Anforderungen genügen, können viele der Erkenntnisse in \cite{Holzschuher:2013:PGQ:2457317.2457351} als Ausgangspunkt für weitere Betrachtungen Verwendung finden.

\section{Benchmarks in Graphdatenbanksystemen}

% Survey of Graph Database Performance on the HPC Scalable Graph Analysis Benchmark (2019)

Einige der für die vorliegende Arbeit relevanten GDBMS wurden 2010 erstmalig von DEX-Entwicklern in einem Benchmark gegenübergestellt\cite{Dominguez-Sal:2010:SGD:1927585.1927590}. Sie entschieden sich für die Implementierung des HPC Scalable Graph Analysis Benchmark\cite{bader:hpc_sgab2009}, welcher ein Gemeinschaftsprojekt von Forschern und Industriepartnern zum Vergleich graphenbasierter Softwaresysteme ist. Der Benchmark gliedert sich in vier Abschnitte, sog. Kernels: (1) Laden des Graphen in das GDBMS inklusive Anlegen aller systemspezifischen Indizes; (2) Iteration aller Kanten und Filterung jener, die einem definierten Prädikat entsprechen; (3) lokale Traversierung in Form der Berechnung der transitiven Hülle ausgehend von einer Teilmenge der Knoten; und (4) globale Traversierung im Rahmen der Berechnung der Betweenenness Centrality des Graphen. Als Datengrundlage werden drei skalenfreie Zufallsgraphen\footnote{Skalenfreie Graphen sind solche Graphen, in denen die Verteilung der Kanten einem Potenzgesetz folgt\cite{Newman:2010:NI:1809753}.} mit dem R-MAT-Algorithmus\cite{DBLP:conf/sdm/ChakrabartiZF04} erzeugt, der kleinste Graph umfasst 1 Tsd. Knoten und 10 Tsd. Kanten, der größte Graph 1 Mio. Knoten und 9,4 Mio. Kanten. Die verglichenen GDBMS sind DEX, Neo4j, Apache Jena\footnote{\url{http://jena.apache.org/index.html}} und HyperGraphDB. In neun von insgesamt zwölf durchgeführten Messungen erreicht DEX die besten Ergebnisse, Neo4j in den verbliebenen drei. Auffällig ist, dass DEX in Kernel 1, 2 und 4 mit zunehmender Größe des Graphen besser skaliert als Neo4j, beide Systeme eignen sich jedoch generell für die lokale und globale Traversierung. Apache Jena und HyperGraphDB eignen sich vorrangig für lokale Traversierung. Eine Evaluierung von HyperGraphDB erfolgt nur mit dem kleinsten Graph, da Kernel 1 für größere Graphen den festgelegten Maximalwert von 24 Stunden überschreitet.

\textbf{Diskussion} Die Autoren stellen interessante Ansätze bzgl. Methodik und Konzeption eines Benchmarks von GDBMS vor. Die verwendeten Versionen der Systeme sind allerdings nicht mehr aktuell. Insbesondere die von den Autoren diskutierten Defizite von Neo4j, wie das Fehlen einer Möglichkeit zur Iteration aller Kanten, sind zum aktuellen Zeitpunkt nicht mehr gültig. Die erzielten Messergebnisse liefern somit zwar erste Erkenntnisse für eine Beurteilung der Systeme, eine genauere Untersuchung ist jedoch weiterhin erforderlich. Der Benchmark selbst testet ausschließlich grundlegende Operationen wie das Laden von Knoten und deren Kanten, alle Algorithmen zur Ausführung der Kernels werden dabei unabhängig von den Systemen implementiert. Im Benchmark werden das Abfragen von Knoten- und Kanteninformationen und die damit verbundenen komplexeren Operationen, wie zum Beispiel Aggregation, Sortierung oder (eingeschränkte) Pfadsuchen, nicht berücksichtigt. Deren Performance ist für die vorliegende Arbeit jedoch ebenfalls von Interesse. 
%Zu hinterfragen ist darüber hinaus auch die Neutralität der Autoren bei der Durchführung der Messungen. 

% A Discussion on the Design of Graph Database Benchmarks (2011)

Dominguez-Sal et al. widmen sich in \cite{Dominguez-Sal2011} nicht der Gegenüberstellung konkreter Systeme, es werden vielmehr generelle Aspekte diskutiert, welche bei der Durchführung von GDBMS-Benchmarks zu berücksichtigen sind. Hierzu gehören die Charakteristika realer Graphen, typische Operationen in Graphen und die Ausführungsumgebung des Benchmarks. Es werden zunächst Wissenschaftszweige und Anwendungen betrachtet, in denen die Analyse umfangreicher Graphen eine wesentliche Rolle spielt.
% SNA, Proteomik und Semantic Web als auch konkrete Anwendungen, wie Reise- bzw. Routenplanung und Empfehlungssysteme. 
Es wird festgestellt, dass diese Anwendungen vorrangig das Property-Graph-Datenmodell erfordern. Eine der wichtigsten topologischen Eigenschaften der Graphen ist die bereits in \cite{Dominguez-Sal:2010:SGD:1927585.1927590} berücksichtigte Skalenfreiheit. 
%Daraus folgt, dass innerhalb des Graphen Gebiete existieren, welche bzgl. ihrer Kantenmenge dichter sind als andere Regionen. Der Durchmesser dieser Bereiche ist oft gering, wodurch der mittlere Abstand zwischen einem beliebigen Knoten zu einem Großteil der übrigen Knoten ebenfalls gering ist. Darüber hinaus handelt es sich oft um dünnbesetzte Graphen in denen der Anteil der Kanten weit unter der maximal möglichen Anzahl von Kanten liegt. 
Diese und weitere Eigenschaften sollen nach Ansicht der Autoren in der Datenauswahl und -generierung für GDBMS-Benchmarks berücksichtigt werden. Bezüglich der Operationen in Graphen wird eine Unterteilung in grundlegende und komplexere analytische Operationen vorgenommen. Grundlegende Operationen werden von allen Anwendungen gefordert. Hierzu zählt neben dem Erzeugen, Lesen, Aktualisieren und Löschen von Knoten und Kanten bzw. deren Informationen auch das Traversieren des Graphen. Komplexere Operationen variieren zwischen den verschiedenen Anwendungstypen.
%Neben den Operationen wird auch auf deren jeweilige Anfrageart eingegangen. Diese werden in analysierende und transformierende (lesend und schreibend), kaskadierende und nicht kaskadierende (lokale) in Bezug auf die Rekursionstiefe einer Anfrage, globale und nachbarschaftsbezogene bzw. attributbezogene Anfragen eingeteilt.
Die Operationen werden weiter in lokale, d.h. auf einen Teil des Graphen bezogene, und globale, d.h. auf den gesamten Graphen bezogene, Anfragen unterteilt. Eine Unterscheidung in analysierende (lesende) und transformierende (schreibende) Anfragen wird ebenfalls vorgenommen. Bei der Durchführung des Benchmarks soll eine ausgeglichene Verteilung der entsprechenden Arten berücksichtigt werden. Bei der Betrachtung der Ausführungsumgebung von GDBMS-Benchmarks wird in Konfiguration/Aufbau, Ausführung und Metriken unterschieden. Bei der Vorbereitung der verwendeten Datensätze wird die Angabe eines Skalierungsfaktors empfohlen. Mit Hilfe dessen wird der bestehende Datensatz vergrößert oder verkleinert, die topologischen Eigenschaften des Graphen bleiben dabei aber erhalten. Zum Aufbau des Benchmarks gehören weiter das Anlegen systemspezifischer Indizes, eventuelles Partitionieren und Replizieren der Daten und die Datenreorganisation unter Berücksichtigung optimierter Datenstrukturen innerhalb der Systeme. Die Ausführung gliedert sich in drei Phasen: (1) Eine Aufwärmphase zum Befüllen eventuell vorhandener Puffer, (2) die Festlegung einer Ausführungsreihenfolge der Anfragen und (3) die Durchführung der Messung. Die wichtigsten Metriken sind dabei die benötigte Ausführungszeit, die Zeit zum Laden des Graphen in das GDBMS aber auch der erreichte Durchsatz mit und ohne Verwendung der Puffer. Interessant sind außerdem abhängige Werte, wie zum Beispiel der Gesamtpreis oder der Stromverbrauch des Systems in Abhängigkeit zu den vorher genannten Metriken.

\textbf{Diskussion} Die Autoren führen eine sehr detailreiche, informative Diskussion über GDBMS-Benchmarks und geben dabei grundlegende Hinweise für deren Implementierung. Insbesondere die Auswahl der Daten und Operationen unterscheidet sich dabei von Benchmarks für andere Datenbanksysteme. Viele der genannten Hinweise werden in Kapitel \ref{cha:benchmark} berücksichtigt. Anzumerken ist, dass im Gegensatz zur Aussage der Autoren auch typische Operationen relationaler Datenbanken für die Analyse von Graphen interessant sein können. Hierzu zählen die Aggregation und das Sortieren von Ergebnismengen, diese sind vor allem für die Analyse von Geschäftsdaten relevant.

% Benchmarking traversal operations over graph databases (2012)

In \cite{Ciglan:2012} wird die Performance der GDBMS DEX, NativeSail, Neo4j, OrientDB und SGDB untersucht. Die Autoren bewerten die Traversierung des Graphen als Alleinstellungsmerkmal von GDBMS und legen den Fokus folglich auf diese Operation. Es werden die Dauer für das Laden der Graphen sowie die Ausführungszeit für lokale und globale Traversierung gemessen. Die lokale Traversierung wird durch das Berechnen transitiv erreichbarer Knoten realisiert, die globale Traversierung durch das Finden zusammenhängender Komponenten innerhalb des Graphen. Die verwendeten generierten Graphen weisen jene Eigenschaften realer Netzwerke auf, welche bereits in \cite{Dominguez-Sal2011} aufgezeigt wurden. Die Autoren diskutieren analog zu \cite{Shao:2012:MML:2213836.2213907} den wahlfreien Zugriff innerhalb des Graphen und untersuchen das Systemverhalten, für den Fall das der komplette Graph nicht mehr im Hauptspeicher aufgenommen werden kann. Darüber hinaus wird auch die fehlende Standardisierung als Defizit aktueller GDBMS genannt. Mit dem Ziel die Verzerrung durch proprietäre APIs zu minimieren, verwenden die Autoren die Blueprints API\footnote{\url{https://github.com/tinkerpop/blueprints/wiki}}, eine Schnittstellendefinition für das Property-Graph-Datenmodell. 
Die verwendeten Graphen beinhalten zwischen 1 Tsd. und 100 Tsd. Knoten mit einem durchschnittlichen Knotengrad von 16. Systemspezifische Funktionen zum effizienten Importieren der Daten werden nicht verwendet. Alle Systeme bis auf Neo4j weisen ein lineares Wachstum der benötigten Zeit in Abhängigkeit zur Datenmenge auf. Ab 1 Mio. eingefügter Kanten steigt die Ausführungszeit von Neo4j deutlich an. Bei der lokalen Traversierung weisen alle Systeme sublineares Verhalten auf. DEX, NativeSail, Neo4j und SGDB erreichen annähernd gleiche Werte, gefolgt von OrientDB. In der dritten Messung ist bei allen Systemen ein deutliches Wachstum der Ausführungszeit in Abhängigkeit zur Datenmenge festzustellen. SGDB erreicht hier zusammen mit DEX die besten, OrientDB die schlechtesten Werte.
% Zunächst werden die erzeugten Graphen in die Systeme geladen. Die Graphen beinhalten zwischen 1K und 100K Knoten mit einem mittleren Knotengrad von 16. Es wird festgestellt, dass die Zeit für das Laden des Graphen in NativeSail und SGDB linear mit der Größe des Graphen steigt. DEX weist ebenfalls lineares Wachstum auf, die maximale Anzahl an Objekten wird jedoch durch die verwendete Lizenz begrenzt, wodurch eine Messung mit größeren Graphen nicht möglich ist. Neo4j weist zunächst einen linearen Verlauf auf, die Zeit für das Laden steigt jedoch ab ca. 1 Mio. eingefügten Kanten deutlich an. OrientDB schneidet im Vergleich am schlechtesten ab, die Messung wird nach 1 Mio. eingefügten Kanten abgebrochen. Im zweiten Experiment wird die Performance der lokalen Traversierung gemessen. Hierbei zeigt sich, dass alle Systeme sublineares Wachstum in Abhängigkeit von der Größe des Graphen aufweisen. SGDB und Neo4j liefern annähernd gleiche Ergebniswerte gefolgt von DEX und NativeSail mit ebenfalls ähnlichen Werten. OrientDB ist auch in dieser Messung das langsamste System. Die dritte Messung widmet sich der globalen Traversierung. Hier ist bei allen Systemen ein deutliches Anwachsen der Ausführungszeit in Abhängigkeit zur Größe des Graphen zu verzeichnen. SDGB liefert auch hier die kürzesten Antwortzeiten gefolgt von DEX, Neo4j und NativeSail. 
Bei der Berechnung zusammenhängender Komponenten werden Zwischenergebnisse zum Vergleich im Hauptspeicher oder als zusätzliche Eigenschaften an den Knoten, somit in der Datenbank, hinterlegt. Letzteres weist den Vorteil auf, dass Berechnungen nicht durch die Größe des zur Verfügung stehenden Hauptspeichers beschränkt sind, führt jedoch zu einer Erhöhung der Ausführungszeit um eine Größenordnung. Die Autoren schließen mit der Feststellung, dass sich die verglichenen Systeme für Szenarien eignen in denen vorrangig lokale Traversierung durchgeführt wird und widersprechen damit den Erkenntnissen in \cite{Dominguez-Sal:2010:SGD:1927585.1927590}.

\textbf{Diskussion} Die Ergebnisse der durchgeführten Messungen werden von den Autoren als vorläufig bezeichnet, ein Ausblick wird jedoch nicht gegeben und bisher ist keine weiterführende Veröffentlichung erschienen. Unabhängig davon ist die Methodik bei der Durchführung stellenweise nicht nachvollziehbar. So stellen bspw. DEX, Neo4j und OrientDB spezielle Funktionen für das Importieren großer Datenmengen zur Verfügung. Eventuell wären bei deren Verwendung die Messungen in OrientDB auch auf größeren Graphen möglich gewesen. DEX bietet neben der verwendeten Testversion auch eine akademische Lizenz an, diese weist keine Beschränkung der maximalen Objektanzahl auf. Durch deren Verwendung wären auch hier Messungen auf größeren Graphen möglich gewesen. Die Autoren diskutieren den Einfluss des Externspeichers auf die Performance der Anfragen, weisen aber in den Ergebnissen nicht auf diesen Einfluss hin. Interessant wäre, ab welcher Größe der Graph in den Messungen nicht mehr vollständig im Hauptspeicher verwaltet werden kann. Des Weiteren werden alle Berechnungen außerhalb der GDBMS ausgeführt, eine Nutzung eventuell vorhandener Funktionen, wie das Berechnen von Pfaden wird nicht diskutiert. Die untersuchten Operationen sind rein strukturbezogen, das Auslesen von Informationen an Knoten und Kanten ist für viele graphenorientierte Anwendungen jedoch ebenfalls interessant. Es sollte angemerkt werden, dass es sich bei SGDB um einen von den Autoren entwickelten Prototypen handelt.

% Graphdatenbanksysteme Überblick und Benchmark

Gehrels führte 2013 in seiner Masterarbeit\cite{Gehrels:2013} einen funktionalen Vergleich und einen Benchmark der GDBMS Dex, FlockDB, Neo4j und HyperGraphDB durch. Im funktionalen Vergleich werden die Systeme hinsichtlich ihres Datenmodells, Persistenz, vorhandener Anfragemöglichkeiten, Skalierbarkeit, Transaktionen und Indexstrukturen untersucht. Neo4j stellt dabei das umfangreichste GDBMS in Hinblick auf die Funktionalität dar und bietet als einziges System eine graphenorientierte Persistenz, alle anderen Systeme nutzen hierfür eine Variante des B-Baumes. Eine Anfragesprache wird ebenfalls nur von Neo4j angeboten, HyperGraphDB, DEX und FlockDB verfügen ausschließlich über Programmierschnittstellen. FlockDB setzt auf einem MySQL Cluster auf und bietet somit als einziges System eine horizontale Skalierbarkeit für Lese- und Schreibanfragen. ACID-Transaktionen sind in keinem der untersuchten Systeme vollständig implementiert. Indexstrukturen für den effizienten Zugriff auf Knoten und Kanten sind jedoch in allen Systemen nutzbar.
Der Benchmark untersucht ähnlich zu \cite{Ciglan:2012} und \cite{Dominguez-Sal:2010:SGD:1927585.1927590} die Performance beim Laden der Datenbank. Hierbei werden im Gegensatz zu \cite{Ciglan:2012} systemspezifische Import-Funktionen verwendet. Weitere Messungen sind das Auslesen aller Kanten, das Abfragen aller transitiv erreichbaren Nachbarn mit Abstand drei, das Berechnen starker Zusammenhangskomponenten, das Finden eines Graphmusters und das Berechnen der Schnittmenge der Nachbarn zweier Knoten. Die verwendeten Graphen wurden wie in \cite{Dominguez-Sal:2010:SGD:1927585.1927590} mit dem R-MAT Algorithmus erzeugt und  beinhalten bis zu 1 Mio. Knoten und 10 Mio. Kanten, wobei nicht alle Messungen mit entsprechend großen Graphen ausgeführt wurden. DEX erreicht zusammenfassend die geringsten Antwortzeiten bzw. Laufzeiten, teils mit geringem, teils auch mit deutlichem Abstand zu Neo4j. Dies ist insofern interessant, als dass Neo4j das einzige System mit einer graphenorientierten Persistenz ist. HyperGraphDB schneidet generell schlechter ab als DEX und Neo4j. FlockDB liefert in allen Messungen die schlechtesten Ergebnisse. Hervorzuheben ist, dass für die Mustersuche in Neo4j die Anfragesprache Cypher verwendet wurde. Die erreichten Antwortzeiten sind dabei deutlich höher als bei den verglichenen Systemen, in welchen die jeweiligen Programmierschnittstellen verwendet wurden. Dies lässt auf fehlende oder zumindest unzureichende Anfrageoptimierung schließen.

\textbf{Diskussion} Die Arbeit untersucht wie die vorliegende Arbeit ebenfalls verschiedene funktionale Aspekte von GDBMS und stellt ausgewählte Systeme in einem Benchmark gegenüber. Die Anforderungen von Gehrels sind jedoch allgemeiner und auf keinen speziellen Anwendungsfall bezogen. So werden spezifische Anforderungen, wie zum Beispiel die Quelloffenheit der Systeme, nicht gestellt, wodurch in dieser Arbeit andere Systeme in den Fokus der Betrachtung rücken. Der Benchmark orientiert sich am einfachsten Datenmodell (FlockDB) und betrachtet keine Multigraphen, Knotenlabels und Knoten- bzw. Kanteninformationen. Die durchgeführten Messungen sind strukturbezogen, das Auslesen von Knoten- und Kantenattributen wird nicht berücksichtigt. Insbesondere die Betrachtung von Neo4j liefert jedoch wichtige Erkenntnisse für die vorliegende Arbeit, da dieses System die gestellten Anforderungen voraussichtlich erfüllen wird.

% The Berlin SPARQL Benchmark

Die bisher vorgestellten Benchmarks wurden unabhängig von konkreten Anwendungsfällen durchgeführt. Im Bereich des Semantic Web existiert jedoch auch eine Vielzahl von Benchmarks, welche sich auf den Vergleich von RDF-Datenbanken mit der Unterstützung von SPARQL als standardisierte Anfragesprache beziehen. Einer dieser Benchmarks ist der Berlin SPARQL Benchmark, welcher in \cite{DBLP:journals/ijswis/BizerS09} vorgestellt wurde. Die grundlegende Intention ist der Vergleich von nativen RDF-Datenbanken und Aufsätzen für relationale Datenbanken, welche SPARQL-Anfragen zunächst nach SQL übersetzen. Die Autoren modellieren ein e-Commerce-Szenario, in dem verschiedene Produkte von Händlern angeboten und von Kunden bewertet werden. 12 verschiedene Anfragen simulieren typische Such- und Navigationsmuster von Nutzern. Die Datenmenge lässt sich über die Produktanzahl skalieren, die Graphen umfassen in einer aktuellen Version des Benchmarks zwischen 10 Mio. und 150 Mrd. RDF-Tripel\cite{BSBM:2013}. Der Benchmark untersucht sowohl die benötigte Zeit für das Laden der Graphen als auch die Ausführungszeit einzelner Anfragen und von Anfragesequenzen verschiedener Länge. In \cite{BSBM:2013} werden die Systeme BigData, BigOwlim, Apache Jena (TDB) und Virtuoso 6 \& 7 verglichen. Es zeigt sich, dass Virtuoso zusammenfassend die besten Ergebnisse erzielt, gefolgt von Apache Jena. BigData und BigOwlim konnten nur bei einzelnen Anfragen die besten Ergebnisse erzielen. Interessant ist, dass 2009 in der ersten Version des Benchmarks auch relationale Systeme in die Vergleiche eingebunden wurden. Hierbei zeigte sich, dass diese in dem verwendeten, strukturierten Anwendungsfall deutlich bessere Ergebnisse erzielen.

\textbf{Diskussion} RDF-Datenbanken modellieren eine spezielle Form eines Graphen. Ein großer Vorteil der Systeme ist die Verwendung der standardisierten Anfragesprache SPARQL. In Abschnitt \ref{subsec:rdf} wird untersucht, inwieweit sich die Systeme für die Erfüllung der gestellten Anforderungen eignen.

In diesem Kapitel wurden verwandte Arbeiten vorgestellt und kurz diskutiert. Zusammenfassend lässt sich feststellen, dass keine einheitliche Kategorisierung graphenbasierter Softwaresysteme existiert. Darüber hinaus werden die Systeme in den betrachteten Benchmarks nur hinsichtlich grundlegender Operationen untersucht, ob die Systeme Funktionen zur Ausführung komplexerer Anfragen bereitstellen, wird nicht betrachtet. Die fehlende Standardisierung wird hingegen oft als entscheidendes Defizit von Graphdatenbanksystemen gewertet. Interessant ist, welches der Systeme diesbezüglich Fortschritte erzielt hat und ob generelle Bestrebungen hinsichtlich einer Standardisierung bestehen. Die Betrachtung der Arbeiten liefert erste Ansätze für die Auswahl konkreter Systeme und die Durchführung funktionaler und empirischer Vergleiche. Die Erkenntnisse reichen aber nicht aus um eine abschließende Auswahl für diese Arbeit treffen zu können.

Im nachfolgenden Kapitel werden die erforderlichen graphentheoretischen Begriffe erklärt, graphenbasierte Systeme kategorisiert und die für Graphdatenbanksysteme wesentlichen Datenmodelle und Operationen definiert.